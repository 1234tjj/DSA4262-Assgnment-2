{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fd8f6fa",
   "metadata": {},
   "source": [
    "## DSA4262 Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1bb3ad-df41-46f7-b9df-ccbc2816de7e",
   "metadata": {},
   "source": [
    "## Remark\n",
    "Due to the inherent randomness in model training, rerunning the experiments may produce slightly different results, which could cause discrepancies between the text descriptions and the numerical outputs. All experiments were genuinely conducted. \n",
    "\n",
    "Additionally, all code was run on Kaggle to leverage its free GPU. If the grader runs the code in a different environment, some errors may occur due to package or version differences, not because of issues with the code itself. I kindly ask for the professor’s and tutor’s understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb8ddad-196f-455f-b1a6-53ea3a7e8443",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T03:12:11.968367Z",
     "iopub.status.busy": "2026-02-25T03:12:11.967761Z",
     "iopub.status.idle": "2026-02-25T03:12:18.914164Z",
     "shell.execute_reply": "2026-02-25T03:12:18.913199Z",
     "shell.execute_reply.started": "2026-02-25T03:12:11.968333Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ded4f39-0f49-4250-bb69-9ee5048b6ffe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T03:13:56.888003Z",
     "iopub.status.busy": "2026-02-25T03:13:56.887657Z",
     "iopub.status.idle": "2026-02-25T03:13:57.332834Z",
     "shell.execute_reply": "2026-02-25T03:13:57.331978Z",
     "shell.execute_reply.started": "2026-02-25T03:13:56.887975Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n",
      "dreaddit\n",
      "dreaddit-test.csv  dreaddit-train.csv\n"
     ]
    }
   ],
   "source": [
    "!cp -r /kaggle/input/datasets/junjietian/dsa4262-assignment2-data/Assignment_2/dreaddit /kaggle/working/\n",
    "\n",
    "%cd /kaggle/working\n",
    "!ls /kaggle/working\n",
    "!ls /kaggle/working/dreaddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec42f755",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T03:13:59.984416Z",
     "iopub.status.busy": "2026-02-25T03:13:59.984034Z",
     "iopub.status.idle": "2026-02-25T03:14:02.082225Z",
     "shell.execute_reply": "2026-02-25T03:14:02.081481Z",
     "shell.execute_reply.started": "2026-02-25T03:13:59.984381Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab37230",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783e0cf6-f4ac-44e4-8157-8e1e20e25541",
   "metadata": {},
   "source": [
    "Stress and mental health concerns have become increasingly prominent, especially in online communities where individuals often seek advice and support. Automatically detecting stress from textual data can help clinicians, social workers, and support platforms identify individuals at risk and provide timely interventions.\n",
    "\n",
    "In this project, we explore a variety of machine learning approaches to predict stress from text data collected from multiple subreddits. The workflow begins with exploratory data analysis to understand patterns and distributions, followed by text preprocessing to standardize and clean the data. We then establish baseline models, including Logistic Regression and Random Forest, and experiment with FastText as a shallow text representation model. Finally, we implement BERT, a transformer-based deep learning model, to leverage contextual embeddings and capture complex linguistic patterns. Additional analyses, such as subreddit-wise performance and interpretability metrics, are conducted to better understand model behavior and practical implications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74484778",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce1a32d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T03:14:33.590267Z",
     "iopub.status.busy": "2026-02-25T03:14:33.589586Z",
     "iopub.status.idle": "2026-02-25T03:14:33.778229Z",
     "shell.execute_reply": "2026-02-25T03:14:33.777447Z",
     "shell.execute_reply.started": "2026-02-25T03:14:33.590235Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2838, 116)\n",
      "Test shape: (715, 116)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post_id</th>\n",
       "      <th>sentence_range</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>social_timestamp</th>\n",
       "      <th>social_karma</th>\n",
       "      <th>syntax_ari</th>\n",
       "      <th>lex_liwc_WC</th>\n",
       "      <th>lex_liwc_Analytic</th>\n",
       "      <th>lex_liwc_Clout</th>\n",
       "      <th>lex_liwc_Authentic</th>\n",
       "      <th>lex_liwc_Tone</th>\n",
       "      <th>lex_liwc_WPS</th>\n",
       "      <th>lex_liwc_Sixltr</th>\n",
       "      <th>lex_liwc_Dic</th>\n",
       "      <th>lex_liwc_function</th>\n",
       "      <th>lex_liwc_pronoun</th>\n",
       "      <th>lex_liwc_ppron</th>\n",
       "      <th>lex_liwc_i</th>\n",
       "      <th>lex_liwc_we</th>\n",
       "      <th>lex_liwc_you</th>\n",
       "      <th>lex_liwc_shehe</th>\n",
       "      <th>lex_liwc_they</th>\n",
       "      <th>lex_liwc_ipron</th>\n",
       "      <th>lex_liwc_article</th>\n",
       "      <th>lex_liwc_prep</th>\n",
       "      <th>lex_liwc_auxverb</th>\n",
       "      <th>lex_liwc_adverb</th>\n",
       "      <th>lex_liwc_conj</th>\n",
       "      <th>lex_liwc_negate</th>\n",
       "      <th>lex_liwc_verb</th>\n",
       "      <th>lex_liwc_adj</th>\n",
       "      <th>lex_liwc_compare</th>\n",
       "      <th>lex_liwc_interrog</th>\n",
       "      <th>lex_liwc_number</th>\n",
       "      <th>lex_liwc_quant</th>\n",
       "      <th>lex_liwc_affect</th>\n",
       "      <th>lex_liwc_posemo</th>\n",
       "      <th>lex_liwc_negemo</th>\n",
       "      <th>lex_liwc_anx</th>\n",
       "      <th>lex_liwc_anger</th>\n",
       "      <th>lex_liwc_sad</th>\n",
       "      <th>lex_liwc_social</th>\n",
       "      <th>lex_liwc_family</th>\n",
       "      <th>lex_liwc_friend</th>\n",
       "      <th>lex_liwc_female</th>\n",
       "      <th>lex_liwc_male</th>\n",
       "      <th>lex_liwc_cogproc</th>\n",
       "      <th>lex_liwc_insight</th>\n",
       "      <th>lex_liwc_cause</th>\n",
       "      <th>lex_liwc_discrep</th>\n",
       "      <th>lex_liwc_tentat</th>\n",
       "      <th>lex_liwc_certain</th>\n",
       "      <th>lex_liwc_differ</th>\n",
       "      <th>lex_liwc_percept</th>\n",
       "      <th>lex_liwc_see</th>\n",
       "      <th>lex_liwc_hear</th>\n",
       "      <th>lex_liwc_feel</th>\n",
       "      <th>lex_liwc_bio</th>\n",
       "      <th>lex_liwc_body</th>\n",
       "      <th>lex_liwc_health</th>\n",
       "      <th>lex_liwc_sexual</th>\n",
       "      <th>lex_liwc_ingest</th>\n",
       "      <th>lex_liwc_drives</th>\n",
       "      <th>lex_liwc_affiliation</th>\n",
       "      <th>lex_liwc_achieve</th>\n",
       "      <th>lex_liwc_power</th>\n",
       "      <th>lex_liwc_reward</th>\n",
       "      <th>lex_liwc_risk</th>\n",
       "      <th>lex_liwc_focuspast</th>\n",
       "      <th>lex_liwc_focuspresent</th>\n",
       "      <th>lex_liwc_focusfuture</th>\n",
       "      <th>lex_liwc_relativ</th>\n",
       "      <th>lex_liwc_motion</th>\n",
       "      <th>lex_liwc_space</th>\n",
       "      <th>lex_liwc_time</th>\n",
       "      <th>lex_liwc_work</th>\n",
       "      <th>lex_liwc_leisure</th>\n",
       "      <th>lex_liwc_home</th>\n",
       "      <th>lex_liwc_money</th>\n",
       "      <th>lex_liwc_relig</th>\n",
       "      <th>lex_liwc_death</th>\n",
       "      <th>lex_liwc_informal</th>\n",
       "      <th>lex_liwc_swear</th>\n",
       "      <th>lex_liwc_netspeak</th>\n",
       "      <th>lex_liwc_assent</th>\n",
       "      <th>lex_liwc_nonflu</th>\n",
       "      <th>lex_liwc_filler</th>\n",
       "      <th>lex_liwc_AllPunc</th>\n",
       "      <th>lex_liwc_Period</th>\n",
       "      <th>lex_liwc_Comma</th>\n",
       "      <th>lex_liwc_Colon</th>\n",
       "      <th>lex_liwc_SemiC</th>\n",
       "      <th>lex_liwc_QMark</th>\n",
       "      <th>lex_liwc_Exclam</th>\n",
       "      <th>lex_liwc_Dash</th>\n",
       "      <th>lex_liwc_Quote</th>\n",
       "      <th>lex_liwc_Apostro</th>\n",
       "      <th>lex_liwc_Parenth</th>\n",
       "      <th>lex_liwc_OtherP</th>\n",
       "      <th>lex_dal_max_pleasantness</th>\n",
       "      <th>lex_dal_max_activation</th>\n",
       "      <th>lex_dal_max_imagery</th>\n",
       "      <th>lex_dal_min_pleasantness</th>\n",
       "      <th>lex_dal_min_activation</th>\n",
       "      <th>lex_dal_min_imagery</th>\n",
       "      <th>lex_dal_avg_activation</th>\n",
       "      <th>lex_dal_avg_imagery</th>\n",
       "      <th>lex_dal_avg_pleasantness</th>\n",
       "      <th>social_upvote_ratio</th>\n",
       "      <th>social_num_comments</th>\n",
       "      <th>syntax_fk_grade</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>8601tu</td>\n",
       "      <td>(15, 20)</td>\n",
       "      <td>He said he had not felt that way before, sugge...</td>\n",
       "      <td>33181</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1521614353</td>\n",
       "      <td>5</td>\n",
       "      <td>1.806818</td>\n",
       "      <td>116</td>\n",
       "      <td>72.64</td>\n",
       "      <td>15.04</td>\n",
       "      <td>89.26</td>\n",
       "      <td>1.00</td>\n",
       "      <td>29.00</td>\n",
       "      <td>12.93</td>\n",
       "      <td>87.07</td>\n",
       "      <td>56.03</td>\n",
       "      <td>16.38</td>\n",
       "      <td>12.07</td>\n",
       "      <td>9.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.31</td>\n",
       "      <td>3.45</td>\n",
       "      <td>19.83</td>\n",
       "      <td>7.76</td>\n",
       "      <td>5.17</td>\n",
       "      <td>4.31</td>\n",
       "      <td>1.72</td>\n",
       "      <td>16.38</td>\n",
       "      <td>6.03</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.72</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1.72</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.86</td>\n",
       "      <td>2.59</td>\n",
       "      <td>3.45</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.72</td>\n",
       "      <td>11.21</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.86</td>\n",
       "      <td>2.59</td>\n",
       "      <td>5.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.59</td>\n",
       "      <td>6.03</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.72</td>\n",
       "      <td>2.59</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.72</td>\n",
       "      <td>4.31</td>\n",
       "      <td>0.86</td>\n",
       "      <td>2.59</td>\n",
       "      <td>4.31</td>\n",
       "      <td>11.21</td>\n",
       "      <td>0.86</td>\n",
       "      <td>17.24</td>\n",
       "      <td>0.86</td>\n",
       "      <td>10.34</td>\n",
       "      <td>6.03</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.55</td>\n",
       "      <td>9.48</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.17</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.8571</td>\n",
       "      <td>2.6250</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.1250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.77000</td>\n",
       "      <td>1.52211</td>\n",
       "      <td>1.89556</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1</td>\n",
       "      <td>3.253573</td>\n",
       "      <td>-0.002742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>assistance</td>\n",
       "      <td>8lbrx9</td>\n",
       "      <td>(0, 5)</td>\n",
       "      <td>Hey there r/assistance, Not sure if this is th...</td>\n",
       "      <td>2606</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1527009817</td>\n",
       "      <td>4</td>\n",
       "      <td>9.429737</td>\n",
       "      <td>109</td>\n",
       "      <td>79.08</td>\n",
       "      <td>76.85</td>\n",
       "      <td>56.75</td>\n",
       "      <td>98.18</td>\n",
       "      <td>27.25</td>\n",
       "      <td>21.10</td>\n",
       "      <td>87.16</td>\n",
       "      <td>48.62</td>\n",
       "      <td>11.93</td>\n",
       "      <td>7.34</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.59</td>\n",
       "      <td>8.26</td>\n",
       "      <td>13.76</td>\n",
       "      <td>6.42</td>\n",
       "      <td>3.67</td>\n",
       "      <td>8.26</td>\n",
       "      <td>0.92</td>\n",
       "      <td>15.60</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.92</td>\n",
       "      <td>5.50</td>\n",
       "      <td>5.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.93</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.67</td>\n",
       "      <td>5.50</td>\n",
       "      <td>1.83</td>\n",
       "      <td>6.42</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.60</td>\n",
       "      <td>5.50</td>\n",
       "      <td>3.67</td>\n",
       "      <td>7.34</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>13.76</td>\n",
       "      <td>0.92</td>\n",
       "      <td>15.60</td>\n",
       "      <td>2.75</td>\n",
       "      <td>10.09</td>\n",
       "      <td>1.83</td>\n",
       "      <td>11.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.68</td>\n",
       "      <td>4.59</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>2.8889</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.125</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.69586</td>\n",
       "      <td>1.62045</td>\n",
       "      <td>1.88919</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2</td>\n",
       "      <td>8.828316</td>\n",
       "      <td>0.292857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>9ch1zh</td>\n",
       "      <td>(15, 20)</td>\n",
       "      <td>My mom then hit me with the newspaper and it s...</td>\n",
       "      <td>38816</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1535935605</td>\n",
       "      <td>2</td>\n",
       "      <td>7.769821</td>\n",
       "      <td>167</td>\n",
       "      <td>33.80</td>\n",
       "      <td>76.38</td>\n",
       "      <td>86.24</td>\n",
       "      <td>25.77</td>\n",
       "      <td>33.40</td>\n",
       "      <td>17.37</td>\n",
       "      <td>91.02</td>\n",
       "      <td>61.68</td>\n",
       "      <td>25.15</td>\n",
       "      <td>16.17</td>\n",
       "      <td>8.98</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8.98</td>\n",
       "      <td>5.39</td>\n",
       "      <td>12.57</td>\n",
       "      <td>10.18</td>\n",
       "      <td>1.80</td>\n",
       "      <td>5.99</td>\n",
       "      <td>1.20</td>\n",
       "      <td>20.96</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.57</td>\n",
       "      <td>0.60</td>\n",
       "      <td>3.59</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.40</td>\n",
       "      <td>10.18</td>\n",
       "      <td>4.19</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.98</td>\n",
       "      <td>5.39</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.20</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.59</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.80</td>\n",
       "      <td>16.17</td>\n",
       "      <td>4.79</td>\n",
       "      <td>5.99</td>\n",
       "      <td>5.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.78</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.7143</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.1429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.83088</td>\n",
       "      <td>1.58108</td>\n",
       "      <td>1.85828</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0</td>\n",
       "      <td>7.841667</td>\n",
       "      <td>0.011894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relationships</td>\n",
       "      <td>7rorpp</td>\n",
       "      <td>[5, 10]</td>\n",
       "      <td>until i met my new boyfriend, he is amazing, h...</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1516429555</td>\n",
       "      <td>0</td>\n",
       "      <td>2.667798</td>\n",
       "      <td>273</td>\n",
       "      <td>2.98</td>\n",
       "      <td>15.25</td>\n",
       "      <td>95.42</td>\n",
       "      <td>79.26</td>\n",
       "      <td>54.60</td>\n",
       "      <td>8.06</td>\n",
       "      <td>98.90</td>\n",
       "      <td>65.57</td>\n",
       "      <td>30.40</td>\n",
       "      <td>23.44</td>\n",
       "      <td>16.12</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.37</td>\n",
       "      <td>6.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.96</td>\n",
       "      <td>3.30</td>\n",
       "      <td>9.16</td>\n",
       "      <td>8.79</td>\n",
       "      <td>6.59</td>\n",
       "      <td>9.89</td>\n",
       "      <td>3.66</td>\n",
       "      <td>20.88</td>\n",
       "      <td>3.66</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.10</td>\n",
       "      <td>8.79</td>\n",
       "      <td>5.86</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.73</td>\n",
       "      <td>13.55</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>8.06</td>\n",
       "      <td>16.85</td>\n",
       "      <td>7.69</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.47</td>\n",
       "      <td>4.76</td>\n",
       "      <td>7.33</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.49</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.37</td>\n",
       "      <td>6.59</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.73</td>\n",
       "      <td>7.69</td>\n",
       "      <td>13.19</td>\n",
       "      <td>1.10</td>\n",
       "      <td>10.99</td>\n",
       "      <td>1.83</td>\n",
       "      <td>3.30</td>\n",
       "      <td>6.23</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.09</td>\n",
       "      <td>2.56</td>\n",
       "      <td>7.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>2.6364</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.1250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.75356</td>\n",
       "      <td>1.52114</td>\n",
       "      <td>1.98848</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "      <td>4.104027</td>\n",
       "      <td>0.141671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>survivorsofabuse</td>\n",
       "      <td>9p2gbc</td>\n",
       "      <td>[0, 5]</td>\n",
       "      <td>October is Domestic Violence Awareness Month a...</td>\n",
       "      <td>1421</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1539809005</td>\n",
       "      <td>24</td>\n",
       "      <td>7.554238</td>\n",
       "      <td>89</td>\n",
       "      <td>32.22</td>\n",
       "      <td>28.71</td>\n",
       "      <td>84.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>17.80</td>\n",
       "      <td>31.46</td>\n",
       "      <td>88.76</td>\n",
       "      <td>52.81</td>\n",
       "      <td>15.73</td>\n",
       "      <td>11.24</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.49</td>\n",
       "      <td>4.49</td>\n",
       "      <td>8.99</td>\n",
       "      <td>13.48</td>\n",
       "      <td>4.49</td>\n",
       "      <td>4.49</td>\n",
       "      <td>2.25</td>\n",
       "      <td>13.48</td>\n",
       "      <td>4.49</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.12</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.87</td>\n",
       "      <td>1.12</td>\n",
       "      <td>4.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.49</td>\n",
       "      <td>11.24</td>\n",
       "      <td>3.37</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.12</td>\n",
       "      <td>4.49</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>4.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.12</td>\n",
       "      <td>5.62</td>\n",
       "      <td>6.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.61</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>10.11</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.85</td>\n",
       "      <td>5.62</td>\n",
       "      <td>6.74</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.12</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.1250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.77644</td>\n",
       "      <td>1.64872</td>\n",
       "      <td>1.81456</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>7.910952</td>\n",
       "      <td>-0.204167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subreddit post_id sentence_range  \\\n",
       "0              ptsd  8601tu       (15, 20)   \n",
       "1        assistance  8lbrx9         (0, 5)   \n",
       "2              ptsd  9ch1zh       (15, 20)   \n",
       "3     relationships  7rorpp        [5, 10]   \n",
       "4  survivorsofabuse  9p2gbc         [0, 5]   \n",
       "\n",
       "                                                text     id  label  \\\n",
       "0  He said he had not felt that way before, sugge...  33181      1   \n",
       "1  Hey there r/assistance, Not sure if this is th...   2606      0   \n",
       "2  My mom then hit me with the newspaper and it s...  38816      1   \n",
       "3  until i met my new boyfriend, he is amazing, h...    239      1   \n",
       "4  October is Domestic Violence Awareness Month a...   1421      1   \n",
       "\n",
       "   confidence  social_timestamp  social_karma  syntax_ari  lex_liwc_WC  \\\n",
       "0         0.8        1521614353             5    1.806818          116   \n",
       "1         1.0        1527009817             4    9.429737          109   \n",
       "2         0.8        1535935605             2    7.769821          167   \n",
       "3         0.6        1516429555             0    2.667798          273   \n",
       "4         0.8        1539809005            24    7.554238           89   \n",
       "\n",
       "   lex_liwc_Analytic  lex_liwc_Clout  lex_liwc_Authentic  lex_liwc_Tone  \\\n",
       "0              72.64           15.04               89.26           1.00   \n",
       "1              79.08           76.85               56.75          98.18   \n",
       "2              33.80           76.38               86.24          25.77   \n",
       "3               2.98           15.25               95.42          79.26   \n",
       "4              32.22           28.71               84.01           1.00   \n",
       "\n",
       "   lex_liwc_WPS  lex_liwc_Sixltr  lex_liwc_Dic  lex_liwc_function  \\\n",
       "0         29.00            12.93         87.07              56.03   \n",
       "1         27.25            21.10         87.16              48.62   \n",
       "2         33.40            17.37         91.02              61.68   \n",
       "3         54.60             8.06         98.90              65.57   \n",
       "4         17.80            31.46         88.76              52.81   \n",
       "\n",
       "   lex_liwc_pronoun  lex_liwc_ppron  lex_liwc_i  lex_liwc_we  lex_liwc_you  \\\n",
       "0             16.38           12.07        9.48         0.00          0.86   \n",
       "1             11.93            7.34        1.83         2.75          2.75   \n",
       "2             25.15           16.17        8.98         1.80          1.80   \n",
       "3             30.40           23.44       16.12         0.37          0.37   \n",
       "4             15.73           11.24        7.87         0.00          0.00   \n",
       "\n",
       "   lex_liwc_shehe  lex_liwc_they  lex_liwc_ipron  lex_liwc_article  \\\n",
       "0            1.72            0.0            4.31              3.45   \n",
       "1            0.00            0.0            4.59              8.26   \n",
       "2            2.99            0.6            8.98              5.39   \n",
       "3            6.59            0.0            6.96              3.30   \n",
       "4            3.37            0.0            4.49              4.49   \n",
       "\n",
       "   lex_liwc_prep  lex_liwc_auxverb  lex_liwc_adverb  lex_liwc_conj  \\\n",
       "0          19.83              7.76             5.17           4.31   \n",
       "1          13.76              6.42             3.67           8.26   \n",
       "2          12.57             10.18             1.80           5.99   \n",
       "3           9.16              8.79             6.59           9.89   \n",
       "4           8.99             13.48             4.49           4.49   \n",
       "\n",
       "   lex_liwc_negate  lex_liwc_verb  lex_liwc_adj  lex_liwc_compare  \\\n",
       "0             1.72          16.38          6.03              3.45   \n",
       "1             0.92          15.60          2.75              0.92   \n",
       "2             1.20          20.96          1.20              0.60   \n",
       "3             3.66          20.88          3.66              1.83   \n",
       "4             2.25          13.48          4.49              2.25   \n",
       "\n",
       "   lex_liwc_interrog  lex_liwc_number  lex_liwc_quant  lex_liwc_affect  \\\n",
       "0               0.86             1.72            1.72             8.62   \n",
       "1               0.92             2.75            0.92             5.50   \n",
       "2               0.60             1.20            1.80             2.40   \n",
       "3               1.10             0.00            1.10             8.79   \n",
       "4               1.12             1.12            1.12             7.87   \n",
       "\n",
       "   lex_liwc_posemo  lex_liwc_negemo  lex_liwc_anx  lex_liwc_anger  \\\n",
       "0             1.72             6.90          0.86            2.59   \n",
       "1             5.50             0.00          0.00            0.00   \n",
       "2             1.20             1.20          0.00            0.00   \n",
       "3             5.86             2.93          0.00            0.37   \n",
       "4             0.00             7.87          1.12            4.49   \n",
       "\n",
       "   lex_liwc_sad  lex_liwc_social  lex_liwc_family  lex_liwc_friend  \\\n",
       "0          3.45             3.45             0.00             0.00   \n",
       "1          0.00            11.01             0.00             0.00   \n",
       "2          0.00            15.57             0.60             3.59   \n",
       "3          0.73            13.55             0.37             1.10   \n",
       "4          0.00             8.99             0.00             0.00   \n",
       "\n",
       "   lex_liwc_female  lex_liwc_male  lex_liwc_cogproc  lex_liwc_insight  \\\n",
       "0             0.00           1.72             11.21              3.45   \n",
       "1             0.00           0.00             11.93              1.83   \n",
       "2             1.80           2.40             10.18              4.19   \n",
       "3             0.37           8.06             16.85              7.69   \n",
       "4             0.00           4.49             11.24              3.37   \n",
       "\n",
       "   lex_liwc_cause  lex_liwc_discrep  lex_liwc_tentat  lex_liwc_certain  \\\n",
       "0            0.86              2.59             5.17              0.00   \n",
       "1            0.00              3.67             5.50              1.83   \n",
       "2            1.20              0.60             2.99              0.00   \n",
       "3            0.73              1.83             1.83              1.47   \n",
       "4            2.25              0.00             0.00              1.12   \n",
       "\n",
       "   lex_liwc_differ  lex_liwc_percept  lex_liwc_see  lex_liwc_hear  \\\n",
       "0             2.59              6.03          1.72           1.72   \n",
       "1             6.42              0.92          0.92           0.00   \n",
       "2             1.80              0.00          0.00           0.00   \n",
       "3             4.76              7.33          1.10           0.00   \n",
       "4             4.49              2.25          0.00           0.00   \n",
       "\n",
       "   lex_liwc_feel  lex_liwc_bio  lex_liwc_body  lex_liwc_health  \\\n",
       "0           1.72          2.59           0.86             1.72   \n",
       "1           0.00          0.00           0.00             0.00   \n",
       "2           0.00          0.60           0.60             0.00   \n",
       "3           5.49          2.20           0.00             0.00   \n",
       "4           2.25          2.25           0.00             1.12   \n",
       "\n",
       "   lex_liwc_sexual  lex_liwc_ingest  lex_liwc_drives  lex_liwc_affiliation  \\\n",
       "0             0.00             0.00             8.62                  0.00   \n",
       "1             0.00             0.00            15.60                  5.50   \n",
       "2             0.00             0.00             8.98                  5.39   \n",
       "3             0.37             0.37             6.59                  4.03   \n",
       "4             1.12             0.00             7.87                  0.00   \n",
       "\n",
       "   lex_liwc_achieve  lex_liwc_power  lex_liwc_reward  lex_liwc_risk  \\\n",
       "0              1.72            4.31             0.86           2.59   \n",
       "1              3.67            7.34             2.75           0.00   \n",
       "2              0.60            1.20             2.40           0.00   \n",
       "3              0.00            0.73             1.10           0.73   \n",
       "4              2.25            4.49             0.00           1.12   \n",
       "\n",
       "   lex_liwc_focuspast  lex_liwc_focuspresent  lex_liwc_focusfuture  \\\n",
       "0                4.31                  11.21                  0.86   \n",
       "1                0.92                  13.76                  0.92   \n",
       "2                3.59                  14.37                  1.80   \n",
       "3                7.69                  13.19                  1.10   \n",
       "4                5.62                   6.74                  0.00   \n",
       "\n",
       "   lex_liwc_relativ  lex_liwc_motion  lex_liwc_space  lex_liwc_time  \\\n",
       "0             17.24             0.86           10.34           6.03   \n",
       "1             15.60             2.75           10.09           1.83   \n",
       "2             16.17             4.79            5.99           5.39   \n",
       "3             10.99             1.83            3.30           6.23   \n",
       "4             14.61             2.25            2.25          10.11   \n",
       "\n",
       "   lex_liwc_work  lex_liwc_leisure  lex_liwc_home  lex_liwc_money  \\\n",
       "0           0.86              0.00           0.00            0.00   \n",
       "1          11.01              0.00           0.00            0.92   \n",
       "2           0.00              1.20           0.60            0.00   \n",
       "3           0.73              0.37           0.37            0.00   \n",
       "4           1.12              0.00           2.25            1.12   \n",
       "\n",
       "   lex_liwc_relig  lex_liwc_death  lex_liwc_informal  lex_liwc_swear  \\\n",
       "0            2.59             0.0               0.86            0.86   \n",
       "1            0.00             0.0               1.83            0.00   \n",
       "2            0.00             0.0               0.00            0.00   \n",
       "3            0.00             0.0               2.56            0.00   \n",
       "4            0.00             0.0               1.12            0.00   \n",
       "\n",
       "   lex_liwc_netspeak  lex_liwc_assent  lex_liwc_nonflu  lex_liwc_filler  \\\n",
       "0               0.00             0.00              0.0              0.0   \n",
       "1               0.92             0.00              0.0              0.0   \n",
       "2               0.00             0.00              0.0              0.0   \n",
       "3               0.73             0.73              0.0              0.0   \n",
       "4               0.00             0.00              0.0              0.0   \n",
       "\n",
       "   lex_liwc_AllPunc  lex_liwc_Period  lex_liwc_Comma  lex_liwc_Colon  \\\n",
       "0             21.55             9.48            3.45            0.86   \n",
       "1             14.68             4.59            2.75            0.00   \n",
       "2             10.78             2.40            3.59            0.00   \n",
       "3             12.09             2.56            7.33            0.00   \n",
       "4             16.85             5.62            6.74            1.12   \n",
       "\n",
       "   lex_liwc_SemiC  lex_liwc_QMark  lex_liwc_Exclam  lex_liwc_Dash  \\\n",
       "0            0.86             0.0              0.0            0.0   \n",
       "1            0.00             0.0              0.0            0.0   \n",
       "2            0.00             0.6              0.0            0.0   \n",
       "3            0.00             0.0              0.0            0.0   \n",
       "4            0.00             0.0              0.0            0.0   \n",
       "\n",
       "   lex_liwc_Quote  lex_liwc_Apostro  lex_liwc_Parenth  lex_liwc_OtherP  \\\n",
       "0            5.17              1.72              0.00             0.00   \n",
       "1            0.00              2.75              0.92             3.67   \n",
       "2            2.40              1.80              0.00             0.00   \n",
       "3            1.47              0.00              0.73             0.00   \n",
       "4            0.00              1.12              2.25             0.00   \n",
       "\n",
       "   lex_dal_max_pleasantness  lex_dal_max_activation  lex_dal_max_imagery  \\\n",
       "0                    2.8571                  2.6250                  3.0   \n",
       "1                    3.0000                  2.8889                  3.0   \n",
       "2                    2.7143                  3.0000                  3.0   \n",
       "3                    3.0000                  2.6364                  3.0   \n",
       "4                    3.0000                  3.0000                  3.0   \n",
       "\n",
       "   lex_dal_min_pleasantness  lex_dal_min_activation  lex_dal_min_imagery  \\\n",
       "0                     1.000                  1.1250                  1.0   \n",
       "1                     1.125                  1.0000                  1.0   \n",
       "2                     1.000                  1.1429                  1.0   \n",
       "3                     1.000                  1.1250                  1.0   \n",
       "4                     1.000                  1.1250                  1.0   \n",
       "\n",
       "   lex_dal_avg_activation  lex_dal_avg_imagery  lex_dal_avg_pleasantness  \\\n",
       "0                 1.77000              1.52211                   1.89556   \n",
       "1                 1.69586              1.62045                   1.88919   \n",
       "2                 1.83088              1.58108                   1.85828   \n",
       "3                 1.75356              1.52114                   1.98848   \n",
       "4                 1.77644              1.64872                   1.81456   \n",
       "\n",
       "   social_upvote_ratio  social_num_comments  syntax_fk_grade  sentiment  \n",
       "0                 0.86                    1         3.253573  -0.002742  \n",
       "1                 0.65                    2         8.828316   0.292857  \n",
       "2                 0.67                    0         7.841667   0.011894  \n",
       "3                 0.50                    5         4.104027   0.141671  \n",
       "4                 1.00                    1         7.910952  -0.204167  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For display\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# File path\n",
    "train_path = \"./dreaddit/dreaddit-train.csv\"\n",
    "test_path = \"./dreaddit/dreaddit-test.csv\"\n",
    "\n",
    "# Load dataset\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test = pd.read_csv(test_path)\n",
    "\n",
    "# Check shape\n",
    "print(\"Train shape:\", df_train.shape)\n",
    "print(\"Test shape:\", df_test.shape)\n",
    "\n",
    "# Preview\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f762911d",
   "metadata": {},
   "source": [
    "The dataset contains a large number of pre-computed linguistic features. \n",
    "\n",
    "Many variables are derived from LIWC (psycholinguistic categories such as pronouns, emotions, and cognitive processes) and DAL (affective dimensions such as pleasantness, activation, and imagery). \n",
    "\n",
    "These structured features will be useful for traditional machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1db43edf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T03:14:37.254866Z",
     "iopub.status.busy": "2026-02-25T03:14:37.254372Z",
     "iopub.status.idle": "2026-02-25T03:14:37.462492Z",
     "shell.execute_reply": "2026-02-25T03:14:37.461922Z",
     "shell.execute_reply.started": "2026-02-25T03:14:37.254838Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2838 entries, 0 to 2837\n",
      "Columns: 116 entries, subreddit to sentiment\n",
      "dtypes: float64(106), int64(6), object(4)\n",
      "memory usage: 2.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>social_timestamp</th>\n",
       "      <th>social_karma</th>\n",
       "      <th>syntax_ari</th>\n",
       "      <th>lex_liwc_WC</th>\n",
       "      <th>lex_liwc_Analytic</th>\n",
       "      <th>lex_liwc_Clout</th>\n",
       "      <th>lex_liwc_Authentic</th>\n",
       "      <th>lex_liwc_Tone</th>\n",
       "      <th>lex_liwc_WPS</th>\n",
       "      <th>lex_liwc_Sixltr</th>\n",
       "      <th>lex_liwc_Dic</th>\n",
       "      <th>lex_liwc_function</th>\n",
       "      <th>lex_liwc_pronoun</th>\n",
       "      <th>lex_liwc_ppron</th>\n",
       "      <th>lex_liwc_i</th>\n",
       "      <th>lex_liwc_we</th>\n",
       "      <th>lex_liwc_you</th>\n",
       "      <th>lex_liwc_shehe</th>\n",
       "      <th>lex_liwc_they</th>\n",
       "      <th>lex_liwc_ipron</th>\n",
       "      <th>lex_liwc_article</th>\n",
       "      <th>lex_liwc_prep</th>\n",
       "      <th>lex_liwc_auxverb</th>\n",
       "      <th>lex_liwc_adverb</th>\n",
       "      <th>lex_liwc_conj</th>\n",
       "      <th>lex_liwc_negate</th>\n",
       "      <th>lex_liwc_verb</th>\n",
       "      <th>lex_liwc_adj</th>\n",
       "      <th>lex_liwc_compare</th>\n",
       "      <th>lex_liwc_interrog</th>\n",
       "      <th>lex_liwc_number</th>\n",
       "      <th>lex_liwc_quant</th>\n",
       "      <th>lex_liwc_affect</th>\n",
       "      <th>lex_liwc_posemo</th>\n",
       "      <th>lex_liwc_negemo</th>\n",
       "      <th>lex_liwc_anx</th>\n",
       "      <th>lex_liwc_anger</th>\n",
       "      <th>lex_liwc_sad</th>\n",
       "      <th>lex_liwc_social</th>\n",
       "      <th>lex_liwc_family</th>\n",
       "      <th>lex_liwc_friend</th>\n",
       "      <th>lex_liwc_female</th>\n",
       "      <th>lex_liwc_male</th>\n",
       "      <th>lex_liwc_cogproc</th>\n",
       "      <th>lex_liwc_insight</th>\n",
       "      <th>lex_liwc_cause</th>\n",
       "      <th>lex_liwc_discrep</th>\n",
       "      <th>lex_liwc_tentat</th>\n",
       "      <th>lex_liwc_certain</th>\n",
       "      <th>lex_liwc_differ</th>\n",
       "      <th>lex_liwc_percept</th>\n",
       "      <th>lex_liwc_see</th>\n",
       "      <th>lex_liwc_hear</th>\n",
       "      <th>lex_liwc_feel</th>\n",
       "      <th>lex_liwc_bio</th>\n",
       "      <th>lex_liwc_body</th>\n",
       "      <th>lex_liwc_health</th>\n",
       "      <th>lex_liwc_sexual</th>\n",
       "      <th>lex_liwc_ingest</th>\n",
       "      <th>lex_liwc_drives</th>\n",
       "      <th>lex_liwc_affiliation</th>\n",
       "      <th>lex_liwc_achieve</th>\n",
       "      <th>lex_liwc_power</th>\n",
       "      <th>lex_liwc_reward</th>\n",
       "      <th>lex_liwc_risk</th>\n",
       "      <th>lex_liwc_focuspast</th>\n",
       "      <th>lex_liwc_focuspresent</th>\n",
       "      <th>lex_liwc_focusfuture</th>\n",
       "      <th>lex_liwc_relativ</th>\n",
       "      <th>lex_liwc_motion</th>\n",
       "      <th>lex_liwc_space</th>\n",
       "      <th>lex_liwc_time</th>\n",
       "      <th>lex_liwc_work</th>\n",
       "      <th>lex_liwc_leisure</th>\n",
       "      <th>lex_liwc_home</th>\n",
       "      <th>lex_liwc_money</th>\n",
       "      <th>lex_liwc_relig</th>\n",
       "      <th>lex_liwc_death</th>\n",
       "      <th>lex_liwc_informal</th>\n",
       "      <th>lex_liwc_swear</th>\n",
       "      <th>lex_liwc_netspeak</th>\n",
       "      <th>lex_liwc_assent</th>\n",
       "      <th>lex_liwc_nonflu</th>\n",
       "      <th>lex_liwc_filler</th>\n",
       "      <th>lex_liwc_AllPunc</th>\n",
       "      <th>lex_liwc_Period</th>\n",
       "      <th>lex_liwc_Comma</th>\n",
       "      <th>lex_liwc_Colon</th>\n",
       "      <th>lex_liwc_SemiC</th>\n",
       "      <th>lex_liwc_QMark</th>\n",
       "      <th>lex_liwc_Exclam</th>\n",
       "      <th>lex_liwc_Dash</th>\n",
       "      <th>lex_liwc_Quote</th>\n",
       "      <th>lex_liwc_Apostro</th>\n",
       "      <th>lex_liwc_Parenth</th>\n",
       "      <th>lex_liwc_OtherP</th>\n",
       "      <th>lex_dal_max_pleasantness</th>\n",
       "      <th>lex_dal_max_activation</th>\n",
       "      <th>lex_dal_max_imagery</th>\n",
       "      <th>lex_dal_min_pleasantness</th>\n",
       "      <th>lex_dal_min_activation</th>\n",
       "      <th>lex_dal_min_imagery</th>\n",
       "      <th>lex_dal_avg_activation</th>\n",
       "      <th>lex_dal_avg_imagery</th>\n",
       "      <th>lex_dal_avg_pleasantness</th>\n",
       "      <th>social_upvote_ratio</th>\n",
       "      <th>social_num_comments</th>\n",
       "      <th>syntax_fk_grade</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2.838000e+03</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.00000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13751.999295</td>\n",
       "      <td>0.524313</td>\n",
       "      <td>0.808972</td>\n",
       "      <td>1.518107e+09</td>\n",
       "      <td>18.262156</td>\n",
       "      <td>4.684272</td>\n",
       "      <td>85.996124</td>\n",
       "      <td>35.240941</td>\n",
       "      <td>40.948231</td>\n",
       "      <td>67.044249</td>\n",
       "      <td>33.428157</td>\n",
       "      <td>18.189475</td>\n",
       "      <td>14.858157</td>\n",
       "      <td>92.349292</td>\n",
       "      <td>58.598887</td>\n",
       "      <td>19.767699</td>\n",
       "      <td>13.987530</td>\n",
       "      <td>9.066254</td>\n",
       "      <td>0.764679</td>\n",
       "      <td>0.865772</td>\n",
       "      <td>2.708076</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>5.76902</td>\n",
       "      <td>4.937636</td>\n",
       "      <td>13.356656</td>\n",
       "      <td>10.306311</td>\n",
       "      <td>6.045853</td>\n",
       "      <td>7.599056</td>\n",
       "      <td>2.262903</td>\n",
       "      <td>19.431293</td>\n",
       "      <td>4.362734</td>\n",
       "      <td>2.287287</td>\n",
       "      <td>1.608217</td>\n",
       "      <td>1.444151</td>\n",
       "      <td>2.246406</td>\n",
       "      <td>6.097400</td>\n",
       "      <td>2.697861</td>\n",
       "      <td>3.304732</td>\n",
       "      <td>0.914197</td>\n",
       "      <td>0.928534</td>\n",
       "      <td>0.598453</td>\n",
       "      <td>10.827523</td>\n",
       "      <td>0.745211</td>\n",
       "      <td>0.555233</td>\n",
       "      <td>1.576614</td>\n",
       "      <td>1.976875</td>\n",
       "      <td>13.594961</td>\n",
       "      <td>2.855109</td>\n",
       "      <td>1.726441</td>\n",
       "      <td>1.947185</td>\n",
       "      <td>3.324757</td>\n",
       "      <td>1.544271</td>\n",
       "      <td>3.971931</td>\n",
       "      <td>2.246959</td>\n",
       "      <td>0.573115</td>\n",
       "      <td>0.613629</td>\n",
       "      <td>0.912163</td>\n",
       "      <td>2.610677</td>\n",
       "      <td>0.708584</td>\n",
       "      <td>1.246801</td>\n",
       "      <td>0.214109</td>\n",
       "      <td>0.405447</td>\n",
       "      <td>7.885211</td>\n",
       "      <td>2.737364</td>\n",
       "      <td>1.372812</td>\n",
       "      <td>2.414334</td>\n",
       "      <td>1.368855</td>\n",
       "      <td>0.720137</td>\n",
       "      <td>5.058562</td>\n",
       "      <td>12.324027</td>\n",
       "      <td>1.183273</td>\n",
       "      <td>14.254221</td>\n",
       "      <td>2.004397</td>\n",
       "      <td>6.295144</td>\n",
       "      <td>6.199316</td>\n",
       "      <td>1.875694</td>\n",
       "      <td>0.785134</td>\n",
       "      <td>0.635113</td>\n",
       "      <td>0.786226</td>\n",
       "      <td>0.115662</td>\n",
       "      <td>0.141811</td>\n",
       "      <td>0.825655</td>\n",
       "      <td>0.246483</td>\n",
       "      <td>0.255201</td>\n",
       "      <td>0.119112</td>\n",
       "      <td>0.124767</td>\n",
       "      <td>0.049856</td>\n",
       "      <td>17.053650</td>\n",
       "      <td>6.066293</td>\n",
       "      <td>3.573312</td>\n",
       "      <td>0.218788</td>\n",
       "      <td>0.123428</td>\n",
       "      <td>0.519066</td>\n",
       "      <td>0.192491</td>\n",
       "      <td>0.486801</td>\n",
       "      <td>0.473513</td>\n",
       "      <td>3.176459</td>\n",
       "      <td>0.778961</td>\n",
       "      <td>1.444264</td>\n",
       "      <td>2.796964</td>\n",
       "      <td>2.704940</td>\n",
       "      <td>2.948414</td>\n",
       "      <td>1.088001</td>\n",
       "      <td>1.120099</td>\n",
       "      <td>1.000211</td>\n",
       "      <td>1.722759</td>\n",
       "      <td>1.536400</td>\n",
       "      <td>1.879385</td>\n",
       "      <td>0.843517</td>\n",
       "      <td>9.948555</td>\n",
       "      <td>5.448836</td>\n",
       "      <td>0.040740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17340.161897</td>\n",
       "      <td>0.499497</td>\n",
       "      <td>0.177038</td>\n",
       "      <td>1.552209e+07</td>\n",
       "      <td>79.419166</td>\n",
       "      <td>3.316435</td>\n",
       "      <td>32.334887</td>\n",
       "      <td>26.486189</td>\n",
       "      <td>31.587117</td>\n",
       "      <td>32.880644</td>\n",
       "      <td>35.334770</td>\n",
       "      <td>9.516060</td>\n",
       "      <td>5.531303</td>\n",
       "      <td>5.301902</td>\n",
       "      <td>6.852503</td>\n",
       "      <td>5.577772</td>\n",
       "      <td>4.792445</td>\n",
       "      <td>4.653986</td>\n",
       "      <td>1.564468</td>\n",
       "      <td>2.095719</td>\n",
       "      <td>3.611687</td>\n",
       "      <td>1.265140</td>\n",
       "      <td>3.22379</td>\n",
       "      <td>2.611391</td>\n",
       "      <td>3.649962</td>\n",
       "      <td>3.649751</td>\n",
       "      <td>3.182057</td>\n",
       "      <td>2.813245</td>\n",
       "      <td>1.894125</td>\n",
       "      <td>4.769641</td>\n",
       "      <td>2.688372</td>\n",
       "      <td>1.990455</td>\n",
       "      <td>1.540092</td>\n",
       "      <td>1.910695</td>\n",
       "      <td>1.790213</td>\n",
       "      <td>3.530977</td>\n",
       "      <td>2.541304</td>\n",
       "      <td>3.021693</td>\n",
       "      <td>1.468605</td>\n",
       "      <td>1.447357</td>\n",
       "      <td>1.093827</td>\n",
       "      <td>6.513339</td>\n",
       "      <td>1.492164</td>\n",
       "      <td>1.049493</td>\n",
       "      <td>2.885097</td>\n",
       "      <td>3.110801</td>\n",
       "      <td>5.331449</td>\n",
       "      <td>2.249446</td>\n",
       "      <td>1.658240</td>\n",
       "      <td>1.940629</td>\n",
       "      <td>2.545349</td>\n",
       "      <td>1.589927</td>\n",
       "      <td>2.539887</td>\n",
       "      <td>2.170752</td>\n",
       "      <td>1.099521</td>\n",
       "      <td>1.125806</td>\n",
       "      <td>1.455630</td>\n",
       "      <td>2.831603</td>\n",
       "      <td>1.454079</td>\n",
       "      <td>1.776315</td>\n",
       "      <td>0.685605</td>\n",
       "      <td>1.350559</td>\n",
       "      <td>3.884363</td>\n",
       "      <td>2.901506</td>\n",
       "      <td>1.578779</td>\n",
       "      <td>1.955585</td>\n",
       "      <td>1.427618</td>\n",
       "      <td>1.190053</td>\n",
       "      <td>4.066357</td>\n",
       "      <td>5.633890</td>\n",
       "      <td>1.454198</td>\n",
       "      <td>5.499219</td>\n",
       "      <td>1.796235</td>\n",
       "      <td>3.261277</td>\n",
       "      <td>3.781227</td>\n",
       "      <td>2.455234</td>\n",
       "      <td>1.352407</td>\n",
       "      <td>1.217066</td>\n",
       "      <td>1.716934</td>\n",
       "      <td>0.528442</td>\n",
       "      <td>0.555553</td>\n",
       "      <td>1.319571</td>\n",
       "      <td>0.743807</td>\n",
       "      <td>0.730756</td>\n",
       "      <td>0.484504</td>\n",
       "      <td>0.415866</td>\n",
       "      <td>0.328158</td>\n",
       "      <td>12.335859</td>\n",
       "      <td>3.219358</td>\n",
       "      <td>2.870731</td>\n",
       "      <td>0.807024</td>\n",
       "      <td>0.500141</td>\n",
       "      <td>2.342935</td>\n",
       "      <td>1.029934</td>\n",
       "      <td>1.805352</td>\n",
       "      <td>1.295909</td>\n",
       "      <td>2.723686</td>\n",
       "      <td>1.728138</td>\n",
       "      <td>10.057253</td>\n",
       "      <td>0.162649</td>\n",
       "      <td>0.174462</td>\n",
       "      <td>0.125843</td>\n",
       "      <td>0.117159</td>\n",
       "      <td>0.085227</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.047835</td>\n",
       "      <td>0.102971</td>\n",
       "      <td>0.058932</td>\n",
       "      <td>0.174794</td>\n",
       "      <td>21.798032</td>\n",
       "      <td>2.535829</td>\n",
       "      <td>0.195490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.483274e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.620000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.910000</td>\n",
       "      <td>4.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.857100</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.485400</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.561150</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.918000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>926.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.509698e+09</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.464243</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>12.410000</td>\n",
       "      <td>12.135000</td>\n",
       "      <td>41.070000</td>\n",
       "      <td>1.420000</td>\n",
       "      <td>13.400000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>90.090000</td>\n",
       "      <td>54.840000</td>\n",
       "      <td>16.050000</td>\n",
       "      <td>10.717500</td>\n",
       "      <td>6.060000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.33000</td>\n",
       "      <td>3.120000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>7.810000</td>\n",
       "      <td>3.850000</td>\n",
       "      <td>5.770000</td>\n",
       "      <td>0.972500</td>\n",
       "      <td>16.280000</td>\n",
       "      <td>2.505000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>3.570000</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>1.140000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.815000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.840000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.170000</td>\n",
       "      <td>0.742500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.175000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.740000</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.450000</td>\n",
       "      <td>0.642500</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.050000</td>\n",
       "      <td>4.210000</td>\n",
       "      <td>1.430000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.714300</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.691430</td>\n",
       "      <td>1.469745</td>\n",
       "      <td>1.841782</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.729973</td>\n",
       "      <td>-0.072222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1891.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.517066e+09</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.321886</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>29.420000</td>\n",
       "      <td>33.520000</td>\n",
       "      <td>80.710000</td>\n",
       "      <td>25.770000</td>\n",
       "      <td>16.775000</td>\n",
       "      <td>14.290000</td>\n",
       "      <td>93.430000</td>\n",
       "      <td>59.260000</td>\n",
       "      <td>19.835000</td>\n",
       "      <td>13.790000</td>\n",
       "      <td>9.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.36000</td>\n",
       "      <td>4.760000</td>\n",
       "      <td>13.450000</td>\n",
       "      <td>10.065000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>7.660000</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>19.320000</td>\n",
       "      <td>4.080000</td>\n",
       "      <td>1.890000</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>1.030000</td>\n",
       "      <td>1.960000</td>\n",
       "      <td>5.560000</td>\n",
       "      <td>2.170000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.285000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.270000</td>\n",
       "      <td>2.480000</td>\n",
       "      <td>1.430000</td>\n",
       "      <td>1.520000</td>\n",
       "      <td>2.930000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>3.730000</td>\n",
       "      <td>1.720000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.960000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.410000</td>\n",
       "      <td>1.915000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>2.130000</td>\n",
       "      <td>1.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.245000</td>\n",
       "      <td>12.365000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>14.010000</td>\n",
       "      <td>1.690000</td>\n",
       "      <td>5.970000</td>\n",
       "      <td>5.680000</td>\n",
       "      <td>1.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.520000</td>\n",
       "      <td>5.590000</td>\n",
       "      <td>3.265000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.725000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.142900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.721430</td>\n",
       "      <td>1.530295</td>\n",
       "      <td>1.878250</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.210000</td>\n",
       "      <td>0.044821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25473.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.530898e+09</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.505657</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>55.057500</td>\n",
       "      <td>69.320000</td>\n",
       "      <td>96.180000</td>\n",
       "      <td>61.550000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>18.022500</td>\n",
       "      <td>95.770000</td>\n",
       "      <td>63.025000</td>\n",
       "      <td>23.522500</td>\n",
       "      <td>17.185000</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>1.047500</td>\n",
       "      <td>0.797500</td>\n",
       "      <td>4.760000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>7.77750</td>\n",
       "      <td>6.590000</td>\n",
       "      <td>15.790000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.380000</td>\n",
       "      <td>3.370000</td>\n",
       "      <td>22.410000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>3.390000</td>\n",
       "      <td>2.440000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>4.840000</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>15.127500</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>1.890000</td>\n",
       "      <td>3.030000</td>\n",
       "      <td>17.042500</td>\n",
       "      <td>4.137500</td>\n",
       "      <td>2.680000</td>\n",
       "      <td>2.940000</td>\n",
       "      <td>4.760000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>5.470000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>1.030000</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>1.430000</td>\n",
       "      <td>3.757500</td>\n",
       "      <td>1.087500</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.197500</td>\n",
       "      <td>4.050000</td>\n",
       "      <td>2.040000</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>2.110000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>7.545000</td>\n",
       "      <td>16.070000</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>17.860000</td>\n",
       "      <td>3.030000</td>\n",
       "      <td>8.275000</td>\n",
       "      <td>8.470000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>1.230000</td>\n",
       "      <td>1.075000</td>\n",
       "      <td>1.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.330000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.727500</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.760000</td>\n",
       "      <td>1.410000</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.857100</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.142900</td>\n",
       "      <td>1.142900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.751760</td>\n",
       "      <td>1.596030</td>\n",
       "      <td>1.916243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.855217</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>55757.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.542592e+09</td>\n",
       "      <td>1435.000000</td>\n",
       "      <td>24.074231</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>65.120000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>77.780000</td>\n",
       "      <td>44.440000</td>\n",
       "      <td>30.770000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>12.960000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>23.470000</td>\n",
       "      <td>12.860000</td>\n",
       "      <td>21.43000</td>\n",
       "      <td>15.530000</td>\n",
       "      <td>29.630000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>21.430000</td>\n",
       "      <td>20.690000</td>\n",
       "      <td>12.900000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>15.150000</td>\n",
       "      <td>17.860000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>11.630000</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>15.790000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>37.760000</td>\n",
       "      <td>17.950000</td>\n",
       "      <td>10.280000</td>\n",
       "      <td>18.060000</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>13.240000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>16.670000</td>\n",
       "      <td>11.860000</td>\n",
       "      <td>18.420000</td>\n",
       "      <td>22.220000</td>\n",
       "      <td>10.870000</td>\n",
       "      <td>9.430000</td>\n",
       "      <td>22.220000</td>\n",
       "      <td>44.440000</td>\n",
       "      <td>21.110000</td>\n",
       "      <td>13.110000</td>\n",
       "      <td>7.340000</td>\n",
       "      <td>33.330000</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>23.080000</td>\n",
       "      <td>16.670000</td>\n",
       "      <td>13.330000</td>\n",
       "      <td>7.550000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>26.320000</td>\n",
       "      <td>35.710000</td>\n",
       "      <td>11.860000</td>\n",
       "      <td>39.290000</td>\n",
       "      <td>14.550000</td>\n",
       "      <td>21.430000</td>\n",
       "      <td>27.270000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>13.330000</td>\n",
       "      <td>13.790000</td>\n",
       "      <td>14.930000</td>\n",
       "      <td>8.240000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>13.040000</td>\n",
       "      <td>8.330000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>3.850000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>420.410000</td>\n",
       "      <td>47.060000</td>\n",
       "      <td>41.860000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.530000</td>\n",
       "      <td>105.410000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>55.560000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>41.940000</td>\n",
       "      <td>391.840000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>2.007400</td>\n",
       "      <td>2.066670</td>\n",
       "      <td>2.158490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>416.000000</td>\n",
       "      <td>21.198919</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id        label   confidence  social_timestamp  social_karma  \\\n",
       "count   2838.000000  2838.000000  2838.000000      2.838000e+03   2838.000000   \n",
       "mean   13751.999295     0.524313     0.808972      1.518107e+09     18.262156   \n",
       "std    17340.161897     0.499497     0.177038      1.552209e+07     79.419166   \n",
       "min        4.000000     0.000000     0.428571      1.483274e+09      0.000000   \n",
       "25%      926.250000     0.000000     0.600000      1.509698e+09      2.000000   \n",
       "50%     1891.500000     1.000000     0.800000      1.517066e+09      5.000000   \n",
       "75%    25473.750000     1.000000     1.000000      1.530898e+09     10.000000   \n",
       "max    55757.000000     1.000000     1.000000      1.542592e+09   1435.000000   \n",
       "\n",
       "        syntax_ari  lex_liwc_WC  lex_liwc_Analytic  lex_liwc_Clout  \\\n",
       "count  2838.000000  2838.000000        2838.000000     2838.000000   \n",
       "mean      4.684272    85.996124          35.240941       40.948231   \n",
       "std       3.316435    32.334887          26.486189       31.587117   \n",
       "min      -6.620000     5.000000           1.000000        1.000000   \n",
       "25%       2.464243    65.000000          12.410000       12.135000   \n",
       "50%       4.321886    81.000000          29.420000       33.520000   \n",
       "75%       6.505657   101.000000          55.057500       69.320000   \n",
       "max      24.074231   310.000000          99.000000       99.000000   \n",
       "\n",
       "       lex_liwc_Authentic  lex_liwc_Tone  lex_liwc_WPS  lex_liwc_Sixltr  \\\n",
       "count         2838.000000    2838.000000   2838.000000      2838.000000   \n",
       "mean            67.044249      33.428157     18.189475        14.858157   \n",
       "std             32.880644      35.334770      9.516060         5.531303   \n",
       "min              1.000000       1.000000      2.400000         0.000000   \n",
       "25%             41.070000       1.420000     13.400000        11.110000   \n",
       "50%             80.710000      25.770000     16.775000        14.290000   \n",
       "75%             96.180000      61.550000     21.000000        18.022500   \n",
       "max             99.000000      99.000000    233.000000        65.120000   \n",
       "\n",
       "       lex_liwc_Dic  lex_liwc_function  lex_liwc_pronoun  lex_liwc_ppron  \\\n",
       "count   2838.000000        2838.000000       2838.000000     2838.000000   \n",
       "mean      92.349292          58.598887         19.767699       13.987530   \n",
       "std        5.301902           6.852503          5.577772        4.792445   \n",
       "min       27.910000           4.170000          0.000000        0.000000   \n",
       "25%       90.090000          54.840000         16.050000       10.717500   \n",
       "50%       93.430000          59.260000         19.835000       13.790000   \n",
       "75%       95.770000          63.025000         23.522500       17.185000   \n",
       "max      100.000000          77.780000         44.440000       30.770000   \n",
       "\n",
       "        lex_liwc_i  lex_liwc_we  lex_liwc_you  lex_liwc_shehe  lex_liwc_they  \\\n",
       "count  2838.000000  2838.000000   2838.000000     2838.000000    2838.000000   \n",
       "mean      9.066254     0.764679      0.865772        2.708076       0.582667   \n",
       "std       4.653986     1.564468      2.095719        3.611687       1.265140   \n",
       "min       0.000000     0.000000      0.000000        0.000000       0.000000   \n",
       "25%       6.060000     0.000000      0.000000        0.000000       0.000000   \n",
       "50%       9.380000     0.000000      0.000000        0.950000       0.000000   \n",
       "75%      12.200000     1.047500      0.797500        4.760000       0.880000   \n",
       "max      30.000000    12.960000     25.000000       23.470000      12.860000   \n",
       "\n",
       "       lex_liwc_ipron  lex_liwc_article  lex_liwc_prep  lex_liwc_auxverb  \\\n",
       "count      2838.00000       2838.000000    2838.000000       2838.000000   \n",
       "mean          5.76902          4.937636      13.356656         10.306311   \n",
       "std           3.22379          2.611391       3.649962          3.649751   \n",
       "min           0.00000          0.000000       0.000000          0.000000   \n",
       "25%           3.33000          3.120000      11.000000          7.810000   \n",
       "50%           5.36000          4.760000      13.450000         10.065000   \n",
       "75%           7.77750          6.590000      15.790000         12.500000   \n",
       "max          21.43000         15.530000      29.630000         25.000000   \n",
       "\n",
       "       lex_liwc_adverb  lex_liwc_conj  lex_liwc_negate  lex_liwc_verb  \\\n",
       "count      2838.000000    2838.000000      2838.000000    2838.000000   \n",
       "mean          6.045853       7.599056         2.262903      19.431293   \n",
       "std           3.182057       2.813245         1.894125       4.769641   \n",
       "min           0.000000       0.000000         0.000000       0.000000   \n",
       "25%           3.850000       5.770000         0.972500      16.280000   \n",
       "50%           5.800000       7.660000         1.950000      19.320000   \n",
       "75%           8.000000       9.380000         3.370000      22.410000   \n",
       "max          21.430000      20.690000        12.900000      40.000000   \n",
       "\n",
       "       lex_liwc_adj  lex_liwc_compare  lex_liwc_interrog  lex_liwc_number  \\\n",
       "count   2838.000000       2838.000000        2838.000000      2838.000000   \n",
       "mean       4.362734          2.287287           1.608217         1.444151   \n",
       "std        2.688372          1.990455           1.540092         1.910695   \n",
       "min        0.000000          0.000000           0.000000         0.000000   \n",
       "25%        2.505000          0.930000           0.000000         0.000000   \n",
       "50%        4.080000          1.890000           1.390000         1.030000   \n",
       "75%        5.880000          3.390000           2.440000         2.200000   \n",
       "max       18.180000         15.150000          17.860000        25.000000   \n",
       "\n",
       "       lex_liwc_quant  lex_liwc_affect  lex_liwc_posemo  lex_liwc_negemo  \\\n",
       "count     2838.000000      2838.000000      2838.000000      2838.000000   \n",
       "mean         2.246406         6.097400         2.697861         3.304732   \n",
       "std          1.790213         3.530977         2.541304         3.021693   \n",
       "min          0.000000         0.000000         0.000000         0.000000   \n",
       "25%          1.080000         3.570000         0.962500         1.140000   \n",
       "50%          1.960000         5.560000         2.170000         2.700000   \n",
       "75%          3.200000         8.000000         3.900000         4.840000   \n",
       "max         11.630000        37.500000        20.000000        37.500000   \n",
       "\n",
       "       lex_liwc_anx  lex_liwc_anger  lex_liwc_sad  lex_liwc_social  \\\n",
       "count   2838.000000     2838.000000   2838.000000      2838.000000   \n",
       "mean       0.914197        0.928534      0.598453        10.827523   \n",
       "std        1.468605        1.447357      1.093827         6.513339   \n",
       "min        0.000000        0.000000      0.000000         0.000000   \n",
       "25%        0.000000        0.000000      0.000000         5.815000   \n",
       "50%        0.000000        0.000000      0.000000        10.285000   \n",
       "75%        1.450000        1.470000      1.050000        15.127500   \n",
       "max       25.000000       15.790000     12.500000        37.760000   \n",
       "\n",
       "       lex_liwc_family  lex_liwc_friend  lex_liwc_female  lex_liwc_male  \\\n",
       "count      2838.000000      2838.000000      2838.000000    2838.000000   \n",
       "mean          0.745211         0.555233         1.576614       1.976875   \n",
       "std           1.492164         1.049493         2.885097       3.110801   \n",
       "min           0.000000         0.000000         0.000000       0.000000   \n",
       "25%           0.000000         0.000000         0.000000       0.000000   \n",
       "50%           0.000000         0.000000         0.000000       0.000000   \n",
       "75%           1.100000         0.990000         1.890000       3.030000   \n",
       "max          17.950000        10.280000        18.060000      19.400000   \n",
       "\n",
       "       lex_liwc_cogproc  lex_liwc_insight  lex_liwc_cause  lex_liwc_discrep  \\\n",
       "count       2838.000000       2838.000000     2838.000000       2838.000000   \n",
       "mean          13.594961          2.855109        1.726441          1.947185   \n",
       "std            5.331449          2.249446        1.658240          1.940629   \n",
       "min            0.000000          0.000000        0.000000          0.000000   \n",
       "25%            9.840000          1.250000        0.000000          0.000000   \n",
       "50%           13.270000          2.480000        1.430000          1.520000   \n",
       "75%           17.042500          4.137500        2.680000          2.940000   \n",
       "max           37.500000         13.240000       12.500000         12.500000   \n",
       "\n",
       "       lex_liwc_tentat  lex_liwc_certain  lex_liwc_differ  lex_liwc_percept  \\\n",
       "count      2838.000000       2838.000000      2838.000000       2838.000000   \n",
       "mean          3.324757          1.544271         3.971931          2.246959   \n",
       "std           2.545349          1.589927         2.539887          2.170752   \n",
       "min           0.000000          0.000000         0.000000          0.000000   \n",
       "25%           1.450000          0.000000         2.170000          0.742500   \n",
       "50%           2.930000          1.280000         3.730000          1.720000   \n",
       "75%           4.760000          2.400000         5.470000          3.230000   \n",
       "max          16.670000         11.860000        18.420000         22.220000   \n",
       "\n",
       "       lex_liwc_see  lex_liwc_hear  lex_liwc_feel  lex_liwc_bio  \\\n",
       "count   2838.000000    2838.000000    2838.000000   2838.000000   \n",
       "mean       0.573115       0.613629       0.912163      2.610677   \n",
       "std        1.099521       1.125806       1.455630      2.831603   \n",
       "min        0.000000       0.000000       0.000000      0.000000   \n",
       "25%        0.000000       0.000000       0.000000      0.690000   \n",
       "50%        0.000000       0.000000       0.000000      1.960000   \n",
       "75%        1.030000       1.050000       1.430000      3.757500   \n",
       "max       10.870000       9.430000      22.220000     44.440000   \n",
       "\n",
       "       lex_liwc_body  lex_liwc_health  lex_liwc_sexual  lex_liwc_ingest  \\\n",
       "count    2838.000000      2838.000000      2838.000000      2838.000000   \n",
       "mean        0.708584         1.246801         0.214109         0.405447   \n",
       "std         1.454079         1.776315         0.685605         1.350559   \n",
       "min         0.000000         0.000000         0.000000         0.000000   \n",
       "25%         0.000000         0.000000         0.000000         0.000000   \n",
       "50%         0.000000         0.700000         0.000000         0.000000   \n",
       "75%         1.087500         1.820000         0.000000         0.000000   \n",
       "max        21.110000        13.110000         7.340000        33.330000   \n",
       "\n",
       "       lex_liwc_drives  lex_liwc_affiliation  lex_liwc_achieve  \\\n",
       "count      2838.000000           2838.000000       2838.000000   \n",
       "mean          7.885211              2.737364          1.372812   \n",
       "std           3.884363              2.901506          1.578779   \n",
       "min           0.000000              0.000000          0.000000   \n",
       "25%           5.175000              0.000000          0.000000   \n",
       "50%           7.410000              1.915000          1.120000   \n",
       "75%          10.197500              4.050000          2.040000   \n",
       "max          37.500000             23.080000         16.670000   \n",
       "\n",
       "       lex_liwc_power  lex_liwc_reward  lex_liwc_risk  lex_liwc_focuspast  \\\n",
       "count     2838.000000      2838.000000    2838.000000         2838.000000   \n",
       "mean         2.414334         1.368855       0.720137            5.058562   \n",
       "std          1.955585         1.427618       1.190053            4.066357   \n",
       "min          0.000000         0.000000       0.000000            0.000000   \n",
       "25%          1.065000         0.000000       0.000000            1.740000   \n",
       "50%          2.130000         1.170000       0.000000            4.245000   \n",
       "75%          3.450000         2.110000       1.280000            7.545000   \n",
       "max         13.330000         7.550000      25.000000           26.320000   \n",
       "\n",
       "       lex_liwc_focuspresent  lex_liwc_focusfuture  lex_liwc_relativ  \\\n",
       "count            2838.000000           2838.000000       2838.000000   \n",
       "mean               12.324027              1.183273         14.254221   \n",
       "std                 5.633890              1.454198          5.499219   \n",
       "min                 0.000000              0.000000          0.000000   \n",
       "25%                 8.200000              0.000000         10.450000   \n",
       "50%                12.365000              0.940000         14.010000   \n",
       "75%                16.070000              1.790000         17.860000   \n",
       "max                35.710000             11.860000         39.290000   \n",
       "\n",
       "       lex_liwc_motion  lex_liwc_space  lex_liwc_time  lex_liwc_work  \\\n",
       "count      2838.000000     2838.000000    2838.000000    2838.000000   \n",
       "mean          2.004397        6.295144       6.199316       1.875694   \n",
       "std           1.796235        3.261277       3.781227       2.455234   \n",
       "min           0.000000        0.000000       0.000000       0.000000   \n",
       "25%           0.642500        3.960000       3.450000       0.000000   \n",
       "50%           1.690000        5.970000       5.680000       1.160000   \n",
       "75%           3.030000        8.275000       8.470000       2.780000   \n",
       "max          14.550000       21.430000      27.270000      20.000000   \n",
       "\n",
       "       lex_liwc_leisure  lex_liwc_home  lex_liwc_money  lex_liwc_relig  \\\n",
       "count       2838.000000    2838.000000     2838.000000     2838.000000   \n",
       "mean           0.785134       0.635113        0.786226        0.115662   \n",
       "std            1.352407       1.217066        1.716934        0.528442   \n",
       "min            0.000000       0.000000        0.000000        0.000000   \n",
       "25%            0.000000       0.000000        0.000000        0.000000   \n",
       "50%            0.000000       0.000000        0.000000        0.000000   \n",
       "75%            1.230000       1.075000        1.020000        0.000000   \n",
       "max           13.330000      13.790000       14.930000        8.240000   \n",
       "\n",
       "       lex_liwc_death  lex_liwc_informal  lex_liwc_swear  lex_liwc_netspeak  \\\n",
       "count     2838.000000        2838.000000     2838.000000        2838.000000   \n",
       "mean         0.141811           0.825655        0.246483           0.255201   \n",
       "std          0.555553           1.319571        0.743807           0.730756   \n",
       "min          0.000000           0.000000        0.000000           0.000000   \n",
       "25%          0.000000           0.000000        0.000000           0.000000   \n",
       "50%          0.000000           0.000000        0.000000           0.000000   \n",
       "75%          0.000000           1.330000        0.000000           0.000000   \n",
       "max         11.110000          13.040000        8.330000          11.110000   \n",
       "\n",
       "       lex_liwc_assent  lex_liwc_nonflu  lex_liwc_filler  lex_liwc_AllPunc  \\\n",
       "count      2838.000000      2838.000000      2838.000000       2838.000000   \n",
       "mean          0.119112         0.124767         0.049856         17.053650   \n",
       "std           0.484504         0.415866         0.328158         12.335859   \n",
       "min           0.000000         0.000000         0.000000          3.120000   \n",
       "25%           0.000000         0.000000         0.000000         12.050000   \n",
       "50%           0.000000         0.000000         0.000000         15.520000   \n",
       "75%           0.000000         0.000000         0.000000         19.727500   \n",
       "max           8.700000         3.850000        11.110000        420.410000   \n",
       "\n",
       "       lex_liwc_Period  lex_liwc_Comma  lex_liwc_Colon  lex_liwc_SemiC  \\\n",
       "count      2838.000000     2838.000000     2838.000000     2838.000000   \n",
       "mean          6.066293        3.573312        0.218788        0.123428   \n",
       "std           3.219358        2.870731        0.807024        0.500141   \n",
       "min           0.000000        0.000000        0.000000        0.000000   \n",
       "25%           4.210000        1.430000        0.000000        0.000000   \n",
       "50%           5.590000        3.265000        0.000000        0.000000   \n",
       "75%           7.250000        5.190000        0.000000        0.000000   \n",
       "max          47.060000       41.860000       20.000000       10.530000   \n",
       "\n",
       "       lex_liwc_QMark  lex_liwc_Exclam  lex_liwc_Dash  lex_liwc_Quote  \\\n",
       "count     2838.000000      2838.000000    2838.000000     2838.000000   \n",
       "mean         0.519066         0.192491       0.486801        0.473513   \n",
       "std          2.342935         1.029934       1.805352        1.295909   \n",
       "min          0.000000         0.000000       0.000000        0.000000   \n",
       "25%          0.000000         0.000000       0.000000        0.000000   \n",
       "50%          0.000000         0.000000       0.000000        0.000000   \n",
       "75%          0.000000         0.000000       0.000000        0.000000   \n",
       "max        105.410000        40.000000      55.560000       12.500000   \n",
       "\n",
       "       lex_liwc_Apostro  lex_liwc_Parenth  lex_liwc_OtherP  \\\n",
       "count       2838.000000       2838.000000      2838.000000   \n",
       "mean           3.176459          0.778961         1.444264   \n",
       "std            2.723686          1.728138        10.057253   \n",
       "min            0.000000          0.000000         0.000000   \n",
       "25%            1.150000          0.000000         0.000000   \n",
       "50%            2.725000          0.000000         0.000000   \n",
       "75%            4.760000          1.410000         0.907500   \n",
       "max           25.000000         41.940000       391.840000   \n",
       "\n",
       "       lex_dal_max_pleasantness  lex_dal_max_activation  lex_dal_max_imagery  \\\n",
       "count               2838.000000             2838.000000          2838.000000   \n",
       "mean                   2.796964                2.704940             2.948414   \n",
       "std                    0.162649                0.174462             0.125843   \n",
       "min                    2.000000                1.857100             2.000000   \n",
       "25%                    2.714300                2.625000             3.000000   \n",
       "50%                    2.800000                2.700000             3.000000   \n",
       "75%                    3.000000                2.857100             3.000000   \n",
       "max                    3.000000                3.000000             3.000000   \n",
       "\n",
       "       lex_dal_min_pleasantness  lex_dal_min_activation  lex_dal_min_imagery  \\\n",
       "count               2838.000000             2838.000000          2838.000000   \n",
       "mean                   1.088001                1.120099             1.000211   \n",
       "std                    0.117159                0.085227             0.006500   \n",
       "min                    1.000000                1.000000             1.000000   \n",
       "25%                    1.000000                1.000000             1.000000   \n",
       "50%                    1.000000                1.142900             1.000000   \n",
       "75%                    1.142900                1.142900             1.000000   \n",
       "max                    1.900000                1.500000             1.200000   \n",
       "\n",
       "       lex_dal_avg_activation  lex_dal_avg_imagery  lex_dal_avg_pleasantness  \\\n",
       "count             2838.000000          2838.000000               2838.000000   \n",
       "mean                 1.722759             1.536400                  1.879385   \n",
       "std                  0.047835             0.102971                  0.058932   \n",
       "min                  1.485400             1.200000                  1.561150   \n",
       "25%                  1.691430             1.469745                  1.841782   \n",
       "50%                  1.721430             1.530295                  1.878250   \n",
       "75%                  1.751760             1.596030                  1.916243   \n",
       "max                  2.007400             2.066670                  2.158490   \n",
       "\n",
       "       social_upvote_ratio  social_num_comments  syntax_fk_grade    sentiment  \n",
       "count          2838.000000          2838.000000      2838.000000  2838.000000  \n",
       "mean              0.843517             9.948555         5.448836     0.040740  \n",
       "std               0.174794            21.798032         2.535829     0.195490  \n",
       "min               0.140000             0.000000        -1.918000    -1.000000  \n",
       "25%               0.750000             2.000000         3.729973    -0.072222  \n",
       "50%               0.890000             5.000000         5.210000     0.044821  \n",
       "75%               1.000000            10.000000         6.855217     0.166667  \n",
       "max               1.000000           416.000000        21.198919     1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.info()\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74033903",
   "metadata": {},
   "source": [
    "All numerical features are properly loaded with no missing values observed in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112be2ab",
   "metadata": {},
   "source": [
    "### Class Distribution in Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5de2ce21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='label', data=df_train)\n",
    "plt.title(\"Label Distribution (Train)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379b0860",
   "metadata": {},
   "source": [
    "The visualization shows the distribution of the two labels in the training dataset. \n",
    "\n",
    "Label 1 (Stressed) appears slightly more frequent than label 0 (Non-stressed), but the difference is small. Both classes contain roughly around 1,400 samples, indicating a relatively balanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41efc48c",
   "metadata": {},
   "source": [
    "### Distribution of Posts Across Subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d15a80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.countplot(y='subreddit', data=df_train, order=df_train['subreddit'].value_counts().index)\n",
    "plt.title(\"Subreddit Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dbf44a",
   "metadata": {},
   "source": [
    "The training dataset contains posts from 10 different subreddits.\n",
    "\n",
    "The number of posts varies substantially across communities. For example, \"ptsd\" has close to 600 samples, while smaller subreddits such as \"food_pantry\" and \"stress\" contain fewer than 100 posts. This imbalance across subreddits may affect model performance and should be considered when building and evaluating the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce2530a",
   "metadata": {},
   "source": [
    "### Text Length Distribution by Stress Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c21d143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train['text_length'] = df_train['text'].apply(len)\n",
    "\n",
    "sns.boxplot(x='label', y='text_length', data=df_train)\n",
    "plt.title(\"Text Length vs Stress\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0825026e",
   "metadata": {},
   "source": [
    "The boxplot shows some differences in text length between stressed and non-stressed posts. \n",
    "While the lower whisker, lower quartile, and median are relatively similar for both groups, stressed posts (label 1) exhibit a noticeably higher upper quartile and upper whisker compared to non-stressed posts. \n",
    "\n",
    "Both categories contain several upper outliers, representing unusually long posts. However, since these are natural user-generated posts, we do not necessarily remove these outliers during preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b1af4c",
   "metadata": {},
   "source": [
    "### EDA Summary\n",
    "Through the exploratory data analysis, we observed the following key points:\n",
    "- The dataset contains posts from multiple subreddits, with some subreddits having significantly more posts than others. This imbalance might influence model performance.\n",
    "- There is a slight difference in text length between stressed and non-stressed posts, with stressed posts generally having longer texts. \n",
    "- The LIWC and DAL features provide structured linguistic and emotional attributes, which will be crucial for feature selection and modeling.\n",
    "\n",
    "Now, we move on to the preprocessing step, where we will clean the dataset and perform dimensionality reduction to improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e5317d",
   "metadata": {},
   "source": [
    "## 3. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30646cdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T03:14:43.710462Z",
     "iopub.status.busy": "2026-02-25T03:14:43.710154Z",
     "iopub.status.idle": "2026-02-25T03:14:43.716078Z",
     "shell.execute_reply": "2026-02-25T03:14:43.715430Z",
     "shell.execute_reply.started": "2026-02-25T03:14:43.710435Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['subreddit',\n",
       " 'post_id',\n",
       " 'sentence_range',\n",
       " 'text',\n",
       " 'id',\n",
       " 'label',\n",
       " 'confidence',\n",
       " 'social_timestamp',\n",
       " 'social_karma',\n",
       " 'syntax_ari',\n",
       " 'lex_liwc_WC',\n",
       " 'lex_liwc_Analytic',\n",
       " 'lex_liwc_Clout',\n",
       " 'lex_liwc_Authentic',\n",
       " 'lex_liwc_Tone',\n",
       " 'lex_liwc_WPS',\n",
       " 'lex_liwc_Sixltr',\n",
       " 'lex_liwc_Dic',\n",
       " 'lex_liwc_function',\n",
       " 'lex_liwc_pronoun',\n",
       " 'lex_liwc_ppron',\n",
       " 'lex_liwc_i',\n",
       " 'lex_liwc_we',\n",
       " 'lex_liwc_you',\n",
       " 'lex_liwc_shehe',\n",
       " 'lex_liwc_they',\n",
       " 'lex_liwc_ipron',\n",
       " 'lex_liwc_article',\n",
       " 'lex_liwc_prep',\n",
       " 'lex_liwc_auxverb',\n",
       " 'lex_liwc_adverb',\n",
       " 'lex_liwc_conj',\n",
       " 'lex_liwc_negate',\n",
       " 'lex_liwc_verb',\n",
       " 'lex_liwc_adj',\n",
       " 'lex_liwc_compare',\n",
       " 'lex_liwc_interrog',\n",
       " 'lex_liwc_number',\n",
       " 'lex_liwc_quant',\n",
       " 'lex_liwc_affect',\n",
       " 'lex_liwc_posemo',\n",
       " 'lex_liwc_negemo',\n",
       " 'lex_liwc_anx',\n",
       " 'lex_liwc_anger',\n",
       " 'lex_liwc_sad',\n",
       " 'lex_liwc_social',\n",
       " 'lex_liwc_family',\n",
       " 'lex_liwc_friend',\n",
       " 'lex_liwc_female',\n",
       " 'lex_liwc_male',\n",
       " 'lex_liwc_cogproc',\n",
       " 'lex_liwc_insight',\n",
       " 'lex_liwc_cause',\n",
       " 'lex_liwc_discrep',\n",
       " 'lex_liwc_tentat',\n",
       " 'lex_liwc_certain',\n",
       " 'lex_liwc_differ',\n",
       " 'lex_liwc_percept',\n",
       " 'lex_liwc_see',\n",
       " 'lex_liwc_hear',\n",
       " 'lex_liwc_feel',\n",
       " 'lex_liwc_bio',\n",
       " 'lex_liwc_body',\n",
       " 'lex_liwc_health',\n",
       " 'lex_liwc_sexual',\n",
       " 'lex_liwc_ingest',\n",
       " 'lex_liwc_drives',\n",
       " 'lex_liwc_affiliation',\n",
       " 'lex_liwc_achieve',\n",
       " 'lex_liwc_power',\n",
       " 'lex_liwc_reward',\n",
       " 'lex_liwc_risk',\n",
       " 'lex_liwc_focuspast',\n",
       " 'lex_liwc_focuspresent',\n",
       " 'lex_liwc_focusfuture',\n",
       " 'lex_liwc_relativ',\n",
       " 'lex_liwc_motion',\n",
       " 'lex_liwc_space',\n",
       " 'lex_liwc_time',\n",
       " 'lex_liwc_work',\n",
       " 'lex_liwc_leisure',\n",
       " 'lex_liwc_home',\n",
       " 'lex_liwc_money',\n",
       " 'lex_liwc_relig',\n",
       " 'lex_liwc_death',\n",
       " 'lex_liwc_informal',\n",
       " 'lex_liwc_swear',\n",
       " 'lex_liwc_netspeak',\n",
       " 'lex_liwc_assent',\n",
       " 'lex_liwc_nonflu',\n",
       " 'lex_liwc_filler',\n",
       " 'lex_liwc_AllPunc',\n",
       " 'lex_liwc_Period',\n",
       " 'lex_liwc_Comma',\n",
       " 'lex_liwc_Colon',\n",
       " 'lex_liwc_SemiC',\n",
       " 'lex_liwc_QMark',\n",
       " 'lex_liwc_Exclam',\n",
       " 'lex_liwc_Dash',\n",
       " 'lex_liwc_Quote',\n",
       " 'lex_liwc_Apostro',\n",
       " 'lex_liwc_Parenth',\n",
       " 'lex_liwc_OtherP',\n",
       " 'lex_dal_max_pleasantness',\n",
       " 'lex_dal_max_activation',\n",
       " 'lex_dal_max_imagery',\n",
       " 'lex_dal_min_pleasantness',\n",
       " 'lex_dal_min_activation',\n",
       " 'lex_dal_min_imagery',\n",
       " 'lex_dal_avg_activation',\n",
       " 'lex_dal_avg_imagery',\n",
       " 'lex_dal_avg_pleasantness',\n",
       " 'social_upvote_ratio',\n",
       " 'social_num_comments',\n",
       " 'syntax_fk_grade',\n",
       " 'sentiment']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print all column names to check which variables are irrelevant\n",
    "df_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df49920",
   "metadata": {},
   "source": [
    "### Data Cleaning & Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a3cd8bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T03:14:47.069262Z",
     "iopub.status.busy": "2026-02-25T03:14:47.068924Z",
     "iopub.status.idle": "2026-02-25T03:14:47.161752Z",
     "shell.execute_reply": "2026-02-25T03:14:47.161050Z",
     "shell.execute_reply.started": "2026-02-25T03:14:47.069233Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>sentence_range</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>social_karma</th>\n",
       "      <th>syntax_ari</th>\n",
       "      <th>lex_liwc_WC</th>\n",
       "      <th>lex_liwc_Analytic</th>\n",
       "      <th>lex_liwc_Clout</th>\n",
       "      <th>lex_liwc_Authentic</th>\n",
       "      <th>lex_liwc_Tone</th>\n",
       "      <th>lex_liwc_WPS</th>\n",
       "      <th>lex_liwc_Sixltr</th>\n",
       "      <th>lex_liwc_Dic</th>\n",
       "      <th>lex_liwc_function</th>\n",
       "      <th>lex_liwc_pronoun</th>\n",
       "      <th>lex_liwc_ppron</th>\n",
       "      <th>lex_liwc_i</th>\n",
       "      <th>lex_liwc_we</th>\n",
       "      <th>lex_liwc_you</th>\n",
       "      <th>lex_liwc_shehe</th>\n",
       "      <th>lex_liwc_they</th>\n",
       "      <th>lex_liwc_ipron</th>\n",
       "      <th>lex_liwc_article</th>\n",
       "      <th>lex_liwc_prep</th>\n",
       "      <th>lex_liwc_auxverb</th>\n",
       "      <th>lex_liwc_adverb</th>\n",
       "      <th>lex_liwc_conj</th>\n",
       "      <th>lex_liwc_negate</th>\n",
       "      <th>lex_liwc_verb</th>\n",
       "      <th>lex_liwc_adj</th>\n",
       "      <th>lex_liwc_compare</th>\n",
       "      <th>lex_liwc_interrog</th>\n",
       "      <th>lex_liwc_number</th>\n",
       "      <th>lex_liwc_quant</th>\n",
       "      <th>lex_liwc_affect</th>\n",
       "      <th>lex_liwc_posemo</th>\n",
       "      <th>lex_liwc_negemo</th>\n",
       "      <th>lex_liwc_anx</th>\n",
       "      <th>lex_liwc_anger</th>\n",
       "      <th>lex_liwc_sad</th>\n",
       "      <th>lex_liwc_social</th>\n",
       "      <th>lex_liwc_family</th>\n",
       "      <th>lex_liwc_friend</th>\n",
       "      <th>lex_liwc_female</th>\n",
       "      <th>lex_liwc_male</th>\n",
       "      <th>lex_liwc_cogproc</th>\n",
       "      <th>lex_liwc_insight</th>\n",
       "      <th>lex_liwc_cause</th>\n",
       "      <th>lex_liwc_discrep</th>\n",
       "      <th>lex_liwc_tentat</th>\n",
       "      <th>lex_liwc_certain</th>\n",
       "      <th>lex_liwc_differ</th>\n",
       "      <th>lex_liwc_percept</th>\n",
       "      <th>lex_liwc_see</th>\n",
       "      <th>lex_liwc_hear</th>\n",
       "      <th>lex_liwc_feel</th>\n",
       "      <th>lex_liwc_bio</th>\n",
       "      <th>lex_liwc_body</th>\n",
       "      <th>lex_liwc_health</th>\n",
       "      <th>lex_liwc_sexual</th>\n",
       "      <th>lex_liwc_ingest</th>\n",
       "      <th>lex_liwc_drives</th>\n",
       "      <th>lex_liwc_affiliation</th>\n",
       "      <th>lex_liwc_achieve</th>\n",
       "      <th>lex_liwc_power</th>\n",
       "      <th>lex_liwc_reward</th>\n",
       "      <th>lex_liwc_risk</th>\n",
       "      <th>lex_liwc_focuspast</th>\n",
       "      <th>lex_liwc_focuspresent</th>\n",
       "      <th>lex_liwc_focusfuture</th>\n",
       "      <th>lex_liwc_relativ</th>\n",
       "      <th>lex_liwc_motion</th>\n",
       "      <th>lex_liwc_space</th>\n",
       "      <th>lex_liwc_time</th>\n",
       "      <th>lex_liwc_work</th>\n",
       "      <th>lex_liwc_leisure</th>\n",
       "      <th>lex_liwc_home</th>\n",
       "      <th>lex_liwc_money</th>\n",
       "      <th>lex_liwc_relig</th>\n",
       "      <th>lex_liwc_death</th>\n",
       "      <th>lex_liwc_informal</th>\n",
       "      <th>lex_liwc_swear</th>\n",
       "      <th>lex_liwc_netspeak</th>\n",
       "      <th>lex_liwc_assent</th>\n",
       "      <th>lex_liwc_nonflu</th>\n",
       "      <th>lex_liwc_filler</th>\n",
       "      <th>lex_liwc_AllPunc</th>\n",
       "      <th>lex_liwc_Period</th>\n",
       "      <th>lex_liwc_Comma</th>\n",
       "      <th>lex_liwc_Colon</th>\n",
       "      <th>lex_liwc_SemiC</th>\n",
       "      <th>lex_liwc_QMark</th>\n",
       "      <th>lex_liwc_Exclam</th>\n",
       "      <th>lex_liwc_Dash</th>\n",
       "      <th>lex_liwc_Quote</th>\n",
       "      <th>lex_liwc_Apostro</th>\n",
       "      <th>lex_liwc_Parenth</th>\n",
       "      <th>lex_liwc_OtherP</th>\n",
       "      <th>lex_dal_max_pleasantness</th>\n",
       "      <th>lex_dal_max_activation</th>\n",
       "      <th>lex_dal_max_imagery</th>\n",
       "      <th>lex_dal_min_pleasantness</th>\n",
       "      <th>lex_dal_min_activation</th>\n",
       "      <th>lex_dal_min_imagery</th>\n",
       "      <th>lex_dal_avg_activation</th>\n",
       "      <th>lex_dal_avg_imagery</th>\n",
       "      <th>lex_dal_avg_pleasantness</th>\n",
       "      <th>social_upvote_ratio</th>\n",
       "      <th>social_num_comments</th>\n",
       "      <th>syntax_fk_grade</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>(15, 20)</td>\n",
       "      <td>1.120660</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.167019</td>\n",
       "      <td>-0.867788</td>\n",
       "      <td>0.928074</td>\n",
       "      <td>1.412270</td>\n",
       "      <td>-0.820360</td>\n",
       "      <td>0.675767</td>\n",
       "      <td>-0.917902</td>\n",
       "      <td>1.136230</td>\n",
       "      <td>-0.348651</td>\n",
       "      <td>-0.995911</td>\n",
       "      <td>-0.374949</td>\n",
       "      <td>-0.607464</td>\n",
       "      <td>-0.400186</td>\n",
       "      <td>0.088917</td>\n",
       "      <td>-0.488865</td>\n",
       "      <td>-0.002755</td>\n",
       "      <td>-0.273626</td>\n",
       "      <td>-0.460637</td>\n",
       "      <td>-0.452659</td>\n",
       "      <td>-0.569772</td>\n",
       "      <td>1.773850</td>\n",
       "      <td>-0.697790</td>\n",
       "      <td>-0.275296</td>\n",
       "      <td>-1.169338</td>\n",
       "      <td>-0.286675</td>\n",
       "      <td>-0.639845</td>\n",
       "      <td>0.620286</td>\n",
       "      <td>0.584247</td>\n",
       "      <td>-0.485912</td>\n",
       "      <td>0.144397</td>\n",
       "      <td>-0.294098</td>\n",
       "      <td>0.714546</td>\n",
       "      <td>-0.384855</td>\n",
       "      <td>1.190029</td>\n",
       "      <td>-0.036910</td>\n",
       "      <td>1.148133</td>\n",
       "      <td>2.607404</td>\n",
       "      <td>-1.132879</td>\n",
       "      <td>-0.499505</td>\n",
       "      <td>-0.529142</td>\n",
       "      <td>-0.546564</td>\n",
       "      <td>-0.082590</td>\n",
       "      <td>-0.447417</td>\n",
       "      <td>0.264508</td>\n",
       "      <td>-0.522599</td>\n",
       "      <td>0.331299</td>\n",
       "      <td>0.725075</td>\n",
       "      <td>-0.971455</td>\n",
       "      <td>-0.544187</td>\n",
       "      <td>1.743040</td>\n",
       "      <td>1.043261</td>\n",
       "      <td>0.982910</td>\n",
       "      <td>0.555072</td>\n",
       "      <td>-0.007303</td>\n",
       "      <td>0.104151</td>\n",
       "      <td>0.266441</td>\n",
       "      <td>-0.312346</td>\n",
       "      <td>-0.300260</td>\n",
       "      <td>0.189199</td>\n",
       "      <td>-0.943595</td>\n",
       "      <td>0.219948</td>\n",
       "      <td>0.969531</td>\n",
       "      <td>-0.356499</td>\n",
       "      <td>1.571520</td>\n",
       "      <td>-0.184119</td>\n",
       "      <td>-0.197772</td>\n",
       "      <td>-0.222343</td>\n",
       "      <td>0.543042</td>\n",
       "      <td>-0.637221</td>\n",
       "      <td>1.240486</td>\n",
       "      <td>-0.044786</td>\n",
       "      <td>-0.413758</td>\n",
       "      <td>-0.580648</td>\n",
       "      <td>-0.521931</td>\n",
       "      <td>-0.458005</td>\n",
       "      <td>4.683149</td>\n",
       "      <td>-0.255306</td>\n",
       "      <td>0.026032</td>\n",
       "      <td>0.824978</td>\n",
       "      <td>-0.349290</td>\n",
       "      <td>-0.245887</td>\n",
       "      <td>-0.300071</td>\n",
       "      <td>-0.151952</td>\n",
       "      <td>0.364558</td>\n",
       "      <td>1.060556</td>\n",
       "      <td>-0.042963</td>\n",
       "      <td>0.794679</td>\n",
       "      <td>1.472988</td>\n",
       "      <td>-0.221584</td>\n",
       "      <td>-0.18693</td>\n",
       "      <td>-0.26969</td>\n",
       "      <td>3.624725</td>\n",
       "      <td>-0.534832</td>\n",
       "      <td>-0.450831</td>\n",
       "      <td>-0.143629</td>\n",
       "      <td>0.369794</td>\n",
       "      <td>-0.458292</td>\n",
       "      <td>0.409994</td>\n",
       "      <td>-0.751256</td>\n",
       "      <td>0.057521</td>\n",
       "      <td>-0.03253</td>\n",
       "      <td>0.987748</td>\n",
       "      <td>-0.138799</td>\n",
       "      <td>0.274512</td>\n",
       "      <td>0.094319</td>\n",
       "      <td>-0.410594</td>\n",
       "      <td>-0.865851</td>\n",
       "      <td>-0.222464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>assistance</td>\n",
       "      <td>(0, 5)</td>\n",
       "      <td>-0.642898</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.179612</td>\n",
       "      <td>1.431146</td>\n",
       "      <td>0.711551</td>\n",
       "      <td>1.655458</td>\n",
       "      <td>1.136796</td>\n",
       "      <td>-0.313134</td>\n",
       "      <td>1.832848</td>\n",
       "      <td>0.952298</td>\n",
       "      <td>1.128657</td>\n",
       "      <td>-0.978933</td>\n",
       "      <td>-1.456496</td>\n",
       "      <td>-1.405414</td>\n",
       "      <td>-1.387330</td>\n",
       "      <td>-1.555125</td>\n",
       "      <td>1.269230</td>\n",
       "      <td>0.899243</td>\n",
       "      <td>-0.749941</td>\n",
       "      <td>-0.460637</td>\n",
       "      <td>-0.365789</td>\n",
       "      <td>1.272483</td>\n",
       "      <td>0.110526</td>\n",
       "      <td>-1.065003</td>\n",
       "      <td>-0.746772</td>\n",
       "      <td>0.234982</td>\n",
       "      <td>-0.709108</td>\n",
       "      <td>-0.803408</td>\n",
       "      <td>-0.599998</td>\n",
       "      <td>-0.687043</td>\n",
       "      <td>-0.446946</td>\n",
       "      <td>0.683562</td>\n",
       "      <td>-0.741052</td>\n",
       "      <td>-0.169218</td>\n",
       "      <td>1.102833</td>\n",
       "      <td>-1.093862</td>\n",
       "      <td>-0.622603</td>\n",
       "      <td>-0.641651</td>\n",
       "      <td>-0.547215</td>\n",
       "      <td>0.028021</td>\n",
       "      <td>-0.499505</td>\n",
       "      <td>-0.529142</td>\n",
       "      <td>-0.546564</td>\n",
       "      <td>-0.635599</td>\n",
       "      <td>-0.312346</td>\n",
       "      <td>-0.455797</td>\n",
       "      <td>-1.041312</td>\n",
       "      <td>0.887918</td>\n",
       "      <td>0.854746</td>\n",
       "      <td>0.179744</td>\n",
       "      <td>0.964019</td>\n",
       "      <td>-0.611398</td>\n",
       "      <td>0.315543</td>\n",
       "      <td>-0.545154</td>\n",
       "      <td>-0.626756</td>\n",
       "      <td>-0.922141</td>\n",
       "      <td>-0.487393</td>\n",
       "      <td>-0.702027</td>\n",
       "      <td>-0.312346</td>\n",
       "      <td>-0.300260</td>\n",
       "      <td>1.986464</td>\n",
       "      <td>0.952306</td>\n",
       "      <td>1.455298</td>\n",
       "      <td>2.519212</td>\n",
       "      <td>0.967618</td>\n",
       "      <td>-0.605237</td>\n",
       "      <td>-1.017936</td>\n",
       "      <td>0.254926</td>\n",
       "      <td>-0.181076</td>\n",
       "      <td>0.244765</td>\n",
       "      <td>0.415165</td>\n",
       "      <td>1.163815</td>\n",
       "      <td>-1.155732</td>\n",
       "      <td>3.720996</td>\n",
       "      <td>-0.580648</td>\n",
       "      <td>-0.521931</td>\n",
       "      <td>0.077928</td>\n",
       "      <td>-0.218913</td>\n",
       "      <td>-0.255306</td>\n",
       "      <td>0.761249</td>\n",
       "      <td>-0.331439</td>\n",
       "      <td>0.909902</td>\n",
       "      <td>-0.245887</td>\n",
       "      <td>-0.300071</td>\n",
       "      <td>-0.151952</td>\n",
       "      <td>-0.192453</td>\n",
       "      <td>-0.458648</td>\n",
       "      <td>-0.286846</td>\n",
       "      <td>-0.271152</td>\n",
       "      <td>-0.246831</td>\n",
       "      <td>-0.221584</td>\n",
       "      <td>-0.18693</td>\n",
       "      <td>-0.26969</td>\n",
       "      <td>-0.365455</td>\n",
       "      <td>-0.156602</td>\n",
       "      <td>0.081628</td>\n",
       "      <td>0.221346</td>\n",
       "      <td>1.248526</td>\n",
       "      <td>1.054629</td>\n",
       "      <td>0.409994</td>\n",
       "      <td>0.315859</td>\n",
       "      <td>-1.409415</td>\n",
       "      <td>-0.03253</td>\n",
       "      <td>-0.562426</td>\n",
       "      <td>0.816392</td>\n",
       "      <td>0.166402</td>\n",
       "      <td>-1.107307</td>\n",
       "      <td>-0.364710</td>\n",
       "      <td>1.332927</td>\n",
       "      <td>1.289893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>(15, 20)</td>\n",
       "      <td>1.445685</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.204800</td>\n",
       "      <td>0.930545</td>\n",
       "      <td>2.505596</td>\n",
       "      <td>-0.054413</td>\n",
       "      <td>1.121913</td>\n",
       "      <td>0.583904</td>\n",
       "      <td>-0.216770</td>\n",
       "      <td>1.598687</td>\n",
       "      <td>0.454194</td>\n",
       "      <td>-0.250764</td>\n",
       "      <td>0.449713</td>\n",
       "      <td>0.965125</td>\n",
       "      <td>0.455478</td>\n",
       "      <td>-0.018537</td>\n",
       "      <td>0.661888</td>\n",
       "      <td>0.445858</td>\n",
       "      <td>0.078073</td>\n",
       "      <td>0.013703</td>\n",
       "      <td>0.996202</td>\n",
       "      <td>0.173258</td>\n",
       "      <td>-0.215562</td>\n",
       "      <td>-0.034614</td>\n",
       "      <td>-1.334546</td>\n",
       "      <td>-0.572058</td>\n",
       "      <td>-0.561257</td>\n",
       "      <td>0.320564</td>\n",
       "      <td>-1.176657</td>\n",
       "      <td>-0.847838</td>\n",
       "      <td>-0.654763</td>\n",
       "      <td>-0.127804</td>\n",
       "      <td>-0.249403</td>\n",
       "      <td>-1.047317</td>\n",
       "      <td>-0.589510</td>\n",
       "      <td>-0.696663</td>\n",
       "      <td>-0.622603</td>\n",
       "      <td>-0.641651</td>\n",
       "      <td>-0.547215</td>\n",
       "      <td>0.728246</td>\n",
       "      <td>-0.097333</td>\n",
       "      <td>2.892162</td>\n",
       "      <td>0.077441</td>\n",
       "      <td>0.136042</td>\n",
       "      <td>-0.640644</td>\n",
       "      <td>0.593535</td>\n",
       "      <td>-0.317526</td>\n",
       "      <td>-0.694322</td>\n",
       "      <td>-0.131540</td>\n",
       "      <td>-0.971455</td>\n",
       "      <td>-0.855280</td>\n",
       "      <td>-1.035289</td>\n",
       "      <td>-0.521332</td>\n",
       "      <td>-0.545154</td>\n",
       "      <td>-0.626756</td>\n",
       "      <td>-0.710209</td>\n",
       "      <td>-0.074688</td>\n",
       "      <td>-0.702027</td>\n",
       "      <td>-0.312346</td>\n",
       "      <td>-0.300260</td>\n",
       "      <td>0.281895</td>\n",
       "      <td>0.914388</td>\n",
       "      <td>-0.489586</td>\n",
       "      <td>-0.621066</td>\n",
       "      <td>0.722411</td>\n",
       "      <td>-0.605237</td>\n",
       "      <td>-0.361213</td>\n",
       "      <td>0.363218</td>\n",
       "      <td>0.424176</td>\n",
       "      <td>0.348434</td>\n",
       "      <td>1.551074</td>\n",
       "      <td>-0.093582</td>\n",
       "      <td>-0.214073</td>\n",
       "      <td>-0.764092</td>\n",
       "      <td>0.306815</td>\n",
       "      <td>-0.028855</td>\n",
       "      <td>-0.458005</td>\n",
       "      <td>-0.218913</td>\n",
       "      <td>-0.255306</td>\n",
       "      <td>-0.625810</td>\n",
       "      <td>-0.331439</td>\n",
       "      <td>-0.349290</td>\n",
       "      <td>-0.245887</td>\n",
       "      <td>-0.300071</td>\n",
       "      <td>-0.151952</td>\n",
       "      <td>-0.508660</td>\n",
       "      <td>-1.139028</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>-0.271152</td>\n",
       "      <td>-0.246831</td>\n",
       "      <td>0.034550</td>\n",
       "      <td>-0.18693</td>\n",
       "      <td>-0.26969</td>\n",
       "      <td>1.486853</td>\n",
       "      <td>-0.505455</td>\n",
       "      <td>-0.450831</td>\n",
       "      <td>-0.143629</td>\n",
       "      <td>-0.508323</td>\n",
       "      <td>1.691558</td>\n",
       "      <td>0.409994</td>\n",
       "      <td>-0.751256</td>\n",
       "      <td>0.267587</td>\n",
       "      <td>-0.03253</td>\n",
       "      <td>2.260672</td>\n",
       "      <td>0.433986</td>\n",
       "      <td>-0.358196</td>\n",
       "      <td>-0.992867</td>\n",
       "      <td>-0.456477</td>\n",
       "      <td>0.943775</td>\n",
       "      <td>-0.147585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relationships</td>\n",
       "      <td>[5, 10]</td>\n",
       "      <td>-0.779426</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.229987</td>\n",
       "      <td>-0.608132</td>\n",
       "      <td>5.784366</td>\n",
       "      <td>-1.218243</td>\n",
       "      <td>-0.813710</td>\n",
       "      <td>0.863145</td>\n",
       "      <td>1.297303</td>\n",
       "      <td>3.826893</td>\n",
       "      <td>-1.229250</td>\n",
       "      <td>1.235757</td>\n",
       "      <td>1.017488</td>\n",
       "      <td>1.906527</td>\n",
       "      <td>1.972717</td>\n",
       "      <td>1.515902</td>\n",
       "      <td>-0.252321</td>\n",
       "      <td>-0.236606</td>\n",
       "      <td>1.075012</td>\n",
       "      <td>-0.460637</td>\n",
       "      <td>0.369500</td>\n",
       "      <td>-0.627223</td>\n",
       "      <td>-1.149984</td>\n",
       "      <td>-0.415529</td>\n",
       "      <td>0.171035</td>\n",
       "      <td>0.814486</td>\n",
       "      <td>0.737725</td>\n",
       "      <td>0.303788</td>\n",
       "      <td>-0.261444</td>\n",
       "      <td>-0.229780</td>\n",
       "      <td>-0.330049</td>\n",
       "      <td>-0.755958</td>\n",
       "      <td>-0.640487</td>\n",
       "      <td>0.762700</td>\n",
       "      <td>1.244517</td>\n",
       "      <td>-0.124036</td>\n",
       "      <td>-0.622603</td>\n",
       "      <td>-0.385967</td>\n",
       "      <td>0.120284</td>\n",
       "      <td>0.418059</td>\n",
       "      <td>-0.251499</td>\n",
       "      <td>0.519168</td>\n",
       "      <td>-0.418297</td>\n",
       "      <td>1.955830</td>\n",
       "      <td>0.610643</td>\n",
       "      <td>2.149748</td>\n",
       "      <td>-0.601009</td>\n",
       "      <td>-0.060396</td>\n",
       "      <td>-0.587354</td>\n",
       "      <td>-0.046721</td>\n",
       "      <td>0.310332</td>\n",
       "      <td>2.342017</td>\n",
       "      <td>0.479280</td>\n",
       "      <td>-0.545154</td>\n",
       "      <td>3.145472</td>\n",
       "      <td>-0.145059</td>\n",
       "      <td>-0.487393</td>\n",
       "      <td>-0.702027</td>\n",
       "      <td>0.227418</td>\n",
       "      <td>-0.026251</td>\n",
       "      <td>-0.333501</td>\n",
       "      <td>0.445584</td>\n",
       "      <td>-0.869694</td>\n",
       "      <td>-0.861446</td>\n",
       "      <td>-0.188357</td>\n",
       "      <td>0.008289</td>\n",
       "      <td>0.647238</td>\n",
       "      <td>0.153735</td>\n",
       "      <td>-0.057274</td>\n",
       "      <td>-0.593684</td>\n",
       "      <td>-0.097108</td>\n",
       "      <td>-0.918558</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>-0.466716</td>\n",
       "      <td>-0.307013</td>\n",
       "      <td>-0.217868</td>\n",
       "      <td>-0.458005</td>\n",
       "      <td>-0.218913</td>\n",
       "      <td>-0.255306</td>\n",
       "      <td>1.314556</td>\n",
       "      <td>-0.331439</td>\n",
       "      <td>0.649852</td>\n",
       "      <td>1.261074</td>\n",
       "      <td>-0.300071</td>\n",
       "      <td>-0.151952</td>\n",
       "      <td>-0.402447</td>\n",
       "      <td>-1.089320</td>\n",
       "      <td>1.308848</td>\n",
       "      <td>-0.271152</td>\n",
       "      <td>-0.246831</td>\n",
       "      <td>-0.221584</td>\n",
       "      <td>-0.18693</td>\n",
       "      <td>-0.26969</td>\n",
       "      <td>0.769084</td>\n",
       "      <td>-1.166441</td>\n",
       "      <td>-0.028336</td>\n",
       "      <td>-0.143629</td>\n",
       "      <td>1.248526</td>\n",
       "      <td>-0.392936</td>\n",
       "      <td>0.409994</td>\n",
       "      <td>-0.751256</td>\n",
       "      <td>0.057521</td>\n",
       "      <td>-0.03253</td>\n",
       "      <td>0.644008</td>\n",
       "      <td>-0.148220</td>\n",
       "      <td>1.851531</td>\n",
       "      <td>-1.965611</td>\n",
       "      <td>-0.227058</td>\n",
       "      <td>-0.530417</td>\n",
       "      <td>0.516386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>survivorsofabuse</td>\n",
       "      <td>[0, 5]</td>\n",
       "      <td>-0.711249</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.072260</td>\n",
       "      <td>0.865529</td>\n",
       "      <td>0.092915</td>\n",
       "      <td>-0.114077</td>\n",
       "      <td>-0.387512</td>\n",
       "      <td>0.516071</td>\n",
       "      <td>-0.917902</td>\n",
       "      <td>-0.040935</td>\n",
       "      <td>3.001963</td>\n",
       "      <td>-0.677101</td>\n",
       "      <td>-0.844933</td>\n",
       "      <td>-0.724019</td>\n",
       "      <td>-0.573406</td>\n",
       "      <td>-0.257084</td>\n",
       "      <td>-0.488865</td>\n",
       "      <td>-0.413187</td>\n",
       "      <td>0.183305</td>\n",
       "      <td>-0.460637</td>\n",
       "      <td>-0.396814</td>\n",
       "      <td>-0.171447</td>\n",
       "      <td>-1.196568</td>\n",
       "      <td>0.869717</td>\n",
       "      <td>-0.489032</td>\n",
       "      <td>-1.105344</td>\n",
       "      <td>-0.006814</td>\n",
       "      <td>-1.247964</td>\n",
       "      <td>0.047348</td>\n",
       "      <td>-0.018736</td>\n",
       "      <td>-0.317061</td>\n",
       "      <td>-0.169681</td>\n",
       "      <td>-0.629313</td>\n",
       "      <td>0.502103</td>\n",
       "      <td>-1.061792</td>\n",
       "      <td>1.511097</td>\n",
       "      <td>0.140160</td>\n",
       "      <td>2.461102</td>\n",
       "      <td>-0.547215</td>\n",
       "      <td>-0.282167</td>\n",
       "      <td>-0.499505</td>\n",
       "      <td>-0.529142</td>\n",
       "      <td>-0.546564</td>\n",
       "      <td>0.808013</td>\n",
       "      <td>-0.441789</td>\n",
       "      <td>0.228937</td>\n",
       "      <td>0.315787</td>\n",
       "      <td>-1.003555</td>\n",
       "      <td>-1.306439</td>\n",
       "      <td>-0.266896</td>\n",
       "      <td>0.204009</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>-0.521332</td>\n",
       "      <td>-0.545154</td>\n",
       "      <td>0.919239</td>\n",
       "      <td>-0.127398</td>\n",
       "      <td>-0.487393</td>\n",
       "      <td>-0.071397</td>\n",
       "      <td>1.321535</td>\n",
       "      <td>-0.300260</td>\n",
       "      <td>-0.003917</td>\n",
       "      <td>-0.943595</td>\n",
       "      <td>0.555710</td>\n",
       "      <td>1.061591</td>\n",
       "      <td>-0.959007</td>\n",
       "      <td>0.336063</td>\n",
       "      <td>0.138093</td>\n",
       "      <td>-0.991324</td>\n",
       "      <td>-0.813838</td>\n",
       "      <td>0.064708</td>\n",
       "      <td>0.136756</td>\n",
       "      <td>-1.240575</td>\n",
       "      <td>1.034419</td>\n",
       "      <td>-0.307843</td>\n",
       "      <td>-0.580648</td>\n",
       "      <td>1.327103</td>\n",
       "      <td>0.194435</td>\n",
       "      <td>-0.218913</td>\n",
       "      <td>-0.255306</td>\n",
       "      <td>0.223100</td>\n",
       "      <td>-0.331439</td>\n",
       "      <td>-0.349290</td>\n",
       "      <td>-0.245887</td>\n",
       "      <td>-0.300071</td>\n",
       "      <td>-0.151952</td>\n",
       "      <td>-0.016512</td>\n",
       "      <td>-0.138652</td>\n",
       "      <td>1.103289</td>\n",
       "      <td>1.116908</td>\n",
       "      <td>-0.246831</td>\n",
       "      <td>-0.221584</td>\n",
       "      <td>-0.18693</td>\n",
       "      <td>-0.26969</td>\n",
       "      <td>-0.365455</td>\n",
       "      <td>-0.755161</td>\n",
       "      <td>0.851378</td>\n",
       "      <td>-0.143629</td>\n",
       "      <td>1.248526</td>\n",
       "      <td>1.691558</td>\n",
       "      <td>0.409994</td>\n",
       "      <td>-0.751256</td>\n",
       "      <td>0.057521</td>\n",
       "      <td>-0.03253</td>\n",
       "      <td>1.122400</td>\n",
       "      <td>1.090983</td>\n",
       "      <td>-1.100203</td>\n",
       "      <td>0.895403</td>\n",
       "      <td>-0.410594</td>\n",
       "      <td>0.971103</td>\n",
       "      <td>-1.253005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subreddit sentence_range        id  label  confidence  social_karma  \\\n",
       "0              ptsd       (15, 20)  1.120660      1         0.8     -0.167019   \n",
       "1        assistance         (0, 5) -0.642898      0         1.0     -0.179612   \n",
       "2              ptsd       (15, 20)  1.445685      1         0.8     -0.204800   \n",
       "3     relationships        [5, 10] -0.779426      1         0.6     -0.229987   \n",
       "4  survivorsofabuse         [0, 5] -0.711249      1         0.8      0.072260   \n",
       "\n",
       "   syntax_ari  lex_liwc_WC  lex_liwc_Analytic  lex_liwc_Clout  \\\n",
       "0   -0.867788     0.928074           1.412270       -0.820360   \n",
       "1    1.431146     0.711551           1.655458        1.136796   \n",
       "2    0.930545     2.505596          -0.054413        1.121913   \n",
       "3   -0.608132     5.784366          -1.218243       -0.813710   \n",
       "4    0.865529     0.092915          -0.114077       -0.387512   \n",
       "\n",
       "   lex_liwc_Authentic  lex_liwc_Tone  lex_liwc_WPS  lex_liwc_Sixltr  \\\n",
       "0            0.675767      -0.917902      1.136230        -0.348651   \n",
       "1           -0.313134       1.832848      0.952298         1.128657   \n",
       "2            0.583904      -0.216770      1.598687         0.454194   \n",
       "3            0.863145       1.297303      3.826893        -1.229250   \n",
       "4            0.516071      -0.917902     -0.040935         3.001963   \n",
       "\n",
       "   lex_liwc_Dic  lex_liwc_function  lex_liwc_pronoun  lex_liwc_ppron  \\\n",
       "0     -0.995911          -0.374949         -0.607464       -0.400186   \n",
       "1     -0.978933          -1.456496         -1.405414       -1.387330   \n",
       "2     -0.250764           0.449713          0.965125        0.455478   \n",
       "3      1.235757           1.017488          1.906527        1.972717   \n",
       "4     -0.677101          -0.844933         -0.724019       -0.573406   \n",
       "\n",
       "   lex_liwc_i  lex_liwc_we  lex_liwc_you  lex_liwc_shehe  lex_liwc_they  \\\n",
       "0    0.088917    -0.488865     -0.002755       -0.273626      -0.460637   \n",
       "1   -1.555125     1.269230      0.899243       -0.749941      -0.460637   \n",
       "2   -0.018537     0.661888      0.445858        0.078073       0.013703   \n",
       "3    1.515902    -0.252321     -0.236606        1.075012      -0.460637   \n",
       "4   -0.257084    -0.488865     -0.413187        0.183305      -0.460637   \n",
       "\n",
       "   lex_liwc_ipron  lex_liwc_article  lex_liwc_prep  lex_liwc_auxverb  \\\n",
       "0       -0.452659         -0.569772       1.773850         -0.697790   \n",
       "1       -0.365789          1.272483       0.110526         -1.065003   \n",
       "2        0.996202          0.173258      -0.215562         -0.034614   \n",
       "3        0.369500         -0.627223      -1.149984         -0.415529   \n",
       "4       -0.396814         -0.171447      -1.196568          0.869717   \n",
       "\n",
       "   lex_liwc_adverb  lex_liwc_conj  lex_liwc_negate  lex_liwc_verb  \\\n",
       "0        -0.275296      -1.169338        -0.286675      -0.639845   \n",
       "1        -0.746772       0.234982        -0.709108      -0.803408   \n",
       "2        -1.334546      -0.572058        -0.561257       0.320564   \n",
       "3         0.171035       0.814486         0.737725       0.303788   \n",
       "4        -0.489032      -1.105344        -0.006814      -1.247964   \n",
       "\n",
       "   lex_liwc_adj  lex_liwc_compare  lex_liwc_interrog  lex_liwc_number  \\\n",
       "0      0.620286          0.584247          -0.485912         0.144397   \n",
       "1     -0.599998         -0.687043          -0.446946         0.683562   \n",
       "2     -1.176657         -0.847838          -0.654763        -0.127804   \n",
       "3     -0.261444         -0.229780          -0.330049        -0.755958   \n",
       "4      0.047348         -0.018736          -0.317061        -0.169681   \n",
       "\n",
       "   lex_liwc_quant  lex_liwc_affect  lex_liwc_posemo  lex_liwc_negemo  \\\n",
       "0       -0.294098         0.714546        -0.384855         1.190029   \n",
       "1       -0.741052        -0.169218         1.102833        -1.093862   \n",
       "2       -0.249403        -1.047317        -0.589510        -0.696663   \n",
       "3       -0.640487         0.762700         1.244517        -0.124036   \n",
       "4       -0.629313         0.502103        -1.061792         1.511097   \n",
       "\n",
       "   lex_liwc_anx  lex_liwc_anger  lex_liwc_sad  lex_liwc_social  \\\n",
       "0     -0.036910        1.148133      2.607404        -1.132879   \n",
       "1     -0.622603       -0.641651     -0.547215         0.028021   \n",
       "2     -0.622603       -0.641651     -0.547215         0.728246   \n",
       "3     -0.622603       -0.385967      0.120284         0.418059   \n",
       "4      0.140160        2.461102     -0.547215        -0.282167   \n",
       "\n",
       "   lex_liwc_family  lex_liwc_friend  lex_liwc_female  lex_liwc_male  \\\n",
       "0        -0.499505        -0.529142        -0.546564      -0.082590   \n",
       "1        -0.499505        -0.529142        -0.546564      -0.635599   \n",
       "2        -0.097333         2.892162         0.077441       0.136042   \n",
       "3        -0.251499         0.519168        -0.418297       1.955830   \n",
       "4        -0.499505        -0.529142        -0.546564       0.808013   \n",
       "\n",
       "   lex_liwc_cogproc  lex_liwc_insight  lex_liwc_cause  lex_liwc_discrep  \\\n",
       "0         -0.447417          0.264508       -0.522599          0.331299   \n",
       "1         -0.312346         -0.455797       -1.041312          0.887918   \n",
       "2         -0.640644          0.593535       -0.317526         -0.694322   \n",
       "3          0.610643          2.149748       -0.601009         -0.060396   \n",
       "4         -0.441789          0.228937        0.315787         -1.003555   \n",
       "\n",
       "   lex_liwc_tentat  lex_liwc_certain  lex_liwc_differ  lex_liwc_percept  \\\n",
       "0         0.725075         -0.971455        -0.544187          1.743040   \n",
       "1         0.854746          0.179744         0.964019         -0.611398   \n",
       "2        -0.131540         -0.971455        -0.855280         -1.035289   \n",
       "3        -0.587354         -0.046721         0.310332          2.342017   \n",
       "4        -1.306439         -0.266896         0.204009          0.001401   \n",
       "\n",
       "   lex_liwc_see  lex_liwc_hear  lex_liwc_feel  lex_liwc_bio  lex_liwc_body  \\\n",
       "0      1.043261       0.982910       0.555072     -0.007303       0.104151   \n",
       "1      0.315543      -0.545154      -0.626756     -0.922141      -0.487393   \n",
       "2     -0.521332      -0.545154      -0.626756     -0.710209      -0.074688   \n",
       "3      0.479280      -0.545154       3.145472     -0.145059      -0.487393   \n",
       "4     -0.521332      -0.545154       0.919239     -0.127398      -0.487393   \n",
       "\n",
       "   lex_liwc_health  lex_liwc_sexual  lex_liwc_ingest  lex_liwc_drives  \\\n",
       "0         0.266441        -0.312346        -0.300260         0.189199   \n",
       "1        -0.702027        -0.312346        -0.300260         1.986464   \n",
       "2        -0.702027        -0.312346        -0.300260         0.281895   \n",
       "3        -0.702027         0.227418        -0.026251        -0.333501   \n",
       "4        -0.071397         1.321535        -0.300260        -0.003917   \n",
       "\n",
       "   lex_liwc_affiliation  lex_liwc_achieve  lex_liwc_power  lex_liwc_reward  \\\n",
       "0             -0.943595          0.219948        0.969531        -0.356499   \n",
       "1              0.952306          1.455298        2.519212         0.967618   \n",
       "2              0.914388         -0.489586       -0.621066         0.722411   \n",
       "3              0.445584         -0.869694       -0.861446        -0.188357   \n",
       "4             -0.943595          0.555710        1.061591        -0.959007   \n",
       "\n",
       "   lex_liwc_risk  lex_liwc_focuspast  lex_liwc_focuspresent  \\\n",
       "0       1.571520           -0.184119              -0.197772   \n",
       "1      -0.605237           -1.017936               0.254926   \n",
       "2      -0.605237           -0.361213               0.363218   \n",
       "3       0.008289            0.647238               0.153735   \n",
       "4       0.336063            0.138093              -0.991324   \n",
       "\n",
       "   lex_liwc_focusfuture  lex_liwc_relativ  lex_liwc_motion  lex_liwc_space  \\\n",
       "0             -0.222343          0.543042        -0.637221        1.240486   \n",
       "1             -0.181076          0.244765         0.415165        1.163815   \n",
       "2              0.424176          0.348434         1.551074       -0.093582   \n",
       "3             -0.057274         -0.593684        -0.097108       -0.918558   \n",
       "4             -0.813838          0.064708         0.136756       -1.240575   \n",
       "\n",
       "   lex_liwc_time  lex_liwc_work  lex_liwc_leisure  lex_liwc_home  \\\n",
       "0      -0.044786      -0.413758         -0.580648      -0.521931   \n",
       "1      -1.155732       3.720996         -0.580648      -0.521931   \n",
       "2      -0.214073      -0.764092          0.306815      -0.028855   \n",
       "3       0.008116      -0.466716         -0.307013      -0.217868   \n",
       "4       1.034419      -0.307843         -0.580648       1.327103   \n",
       "\n",
       "   lex_liwc_money  lex_liwc_relig  lex_liwc_death  lex_liwc_informal  \\\n",
       "0       -0.458005        4.683149       -0.255306           0.026032   \n",
       "1        0.077928       -0.218913       -0.255306           0.761249   \n",
       "2       -0.458005       -0.218913       -0.255306          -0.625810   \n",
       "3       -0.458005       -0.218913       -0.255306           1.314556   \n",
       "4        0.194435       -0.218913       -0.255306           0.223100   \n",
       "\n",
       "   lex_liwc_swear  lex_liwc_netspeak  lex_liwc_assent  lex_liwc_nonflu  \\\n",
       "0        0.824978          -0.349290        -0.245887        -0.300071   \n",
       "1       -0.331439           0.909902        -0.245887        -0.300071   \n",
       "2       -0.331439          -0.349290        -0.245887        -0.300071   \n",
       "3       -0.331439           0.649852         1.261074        -0.300071   \n",
       "4       -0.331439          -0.349290        -0.245887        -0.300071   \n",
       "\n",
       "   lex_liwc_filler  lex_liwc_AllPunc  lex_liwc_Period  lex_liwc_Comma  \\\n",
       "0        -0.151952          0.364558         1.060556       -0.042963   \n",
       "1        -0.151952         -0.192453        -0.458648       -0.286846   \n",
       "2        -0.151952         -0.508660        -1.139028        0.005814   \n",
       "3        -0.151952         -0.402447        -1.089320        1.308848   \n",
       "4        -0.151952         -0.016512        -0.138652        1.103289   \n",
       "\n",
       "   lex_liwc_Colon  lex_liwc_SemiC  lex_liwc_QMark  lex_liwc_Exclam  \\\n",
       "0        0.794679        1.472988       -0.221584         -0.18693   \n",
       "1       -0.271152       -0.246831       -0.221584         -0.18693   \n",
       "2       -0.271152       -0.246831        0.034550         -0.18693   \n",
       "3       -0.271152       -0.246831       -0.221584         -0.18693   \n",
       "4        1.116908       -0.246831       -0.221584         -0.18693   \n",
       "\n",
       "   lex_liwc_Dash  lex_liwc_Quote  lex_liwc_Apostro  lex_liwc_Parenth  \\\n",
       "0       -0.26969        3.624725         -0.534832         -0.450831   \n",
       "1       -0.26969       -0.365455         -0.156602          0.081628   \n",
       "2       -0.26969        1.486853         -0.505455         -0.450831   \n",
       "3       -0.26969        0.769084         -1.166441         -0.028336   \n",
       "4       -0.26969       -0.365455         -0.755161          0.851378   \n",
       "\n",
       "   lex_liwc_OtherP  lex_dal_max_pleasantness  lex_dal_max_activation  \\\n",
       "0        -0.143629                  0.369794               -0.458292   \n",
       "1         0.221346                  1.248526                1.054629   \n",
       "2        -0.143629                 -0.508323                1.691558   \n",
       "3        -0.143629                  1.248526               -0.392936   \n",
       "4        -0.143629                  1.248526                1.691558   \n",
       "\n",
       "   lex_dal_max_imagery  lex_dal_min_pleasantness  lex_dal_min_activation  \\\n",
       "0             0.409994                 -0.751256                0.057521   \n",
       "1             0.409994                  0.315859               -1.409415   \n",
       "2             0.409994                 -0.751256                0.267587   \n",
       "3             0.409994                 -0.751256                0.057521   \n",
       "4             0.409994                 -0.751256                0.057521   \n",
       "\n",
       "   lex_dal_min_imagery  lex_dal_avg_activation  lex_dal_avg_imagery  \\\n",
       "0             -0.03253                0.987748            -0.138799   \n",
       "1             -0.03253               -0.562426             0.816392   \n",
       "2             -0.03253                2.260672             0.433986   \n",
       "3             -0.03253                0.644008            -0.148220   \n",
       "4             -0.03253                1.122400             1.090983   \n",
       "\n",
       "   lex_dal_avg_pleasantness  social_upvote_ratio  social_num_comments  \\\n",
       "0                  0.274512             0.094319            -0.410594   \n",
       "1                  0.166402            -1.107307            -0.364710   \n",
       "2                 -0.358196            -0.992867            -0.456477   \n",
       "3                  1.851531            -1.965611            -0.227058   \n",
       "4                 -1.100203             0.895403            -0.410594   \n",
       "\n",
       "   syntax_fk_grade  sentiment  \n",
       "0        -0.865851  -0.222464  \n",
       "1         1.332927   1.289893  \n",
       "2         0.943775  -0.147585  \n",
       "3        -0.530417   0.516386  \n",
       "4         0.971103  -1.253005  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Drop irrelevant columns\n",
    "df_train_cleaned = df_train.drop(columns=['post_id', 'text', 'social_timestamp'])\n",
    "\n",
    "# Step 2: Identify numerical columns for normalization (exclude label, subreddit, text_length, sentiment, confidence)\n",
    "numerical_columns = df_train_cleaned.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "numerical_columns.remove('label')  # Exclude the target variable\n",
    "numerical_columns.remove('confidence')  # Exclude confidence from normalization\n",
    "\n",
    "# Step 3: Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "df_train_cleaned[numerical_columns] = scaler.fit_transform(df_train_cleaned[numerical_columns])\n",
    "\n",
    "# Step 4: Check for missing values\n",
    "missing_values = df_train_cleaned.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Check the cleaned and normalized data\n",
    "df_train_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58283683",
   "metadata": {},
   "source": [
    "## 4. Baseline Model - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167cbba9",
   "metadata": {},
   "source": [
    "As a baseline model, we implemented a simple Logistic Regression classifier due to its interpretability, efficiency, and strong performance in structured feature-based classification tasks. \n",
    "\n",
    "Before model training, we performed basic preprocessing to ensure consistency between the training and test sets. In particular, we engineered a new variable, text_length, computed from the raw text field, so that both datasets contain identical feature spaces. This prevents feature mismatch issues during scaling and model inference. We also removed the confidence variable from normalization because it represents an auxiliary score rather than a core linguistic feature, and scaling it together with other numerical variables may distort its original meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ce45807",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T03:14:50.359786Z",
     "iopub.status.busy": "2026-02-25T03:14:50.359046Z",
     "iopub.status.idle": "2026-02-25T03:14:50.365159Z",
     "shell.execute_reply": "2026-02-25T03:14:50.364263Z",
     "shell.execute_reply.started": "2026-02-25T03:14:50.359747Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea140ddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T03:14:52.775985Z",
     "iopub.status.busy": "2026-02-25T03:14:52.775243Z",
     "iopub.status.idle": "2026-02-25T03:14:52.782777Z",
     "shell.execute_reply": "2026-02-25T03:14:52.781839Z",
     "shell.execute_reply.started": "2026-02-25T03:14:52.775954Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 0. Add text_length feature\n",
    "# --------------------------\n",
    "# Compute text length for train and test\n",
    "df_train['text_length'] = df_train['text'].apply(len)\n",
    "df_test['text_length'] = df_test['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91894e60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T03:14:55.178217Z",
     "iopub.status.busy": "2026-02-25T03:14:55.177669Z",
     "iopub.status.idle": "2026-02-25T03:14:55.224013Z",
     "shell.execute_reply": "2026-02-25T03:14:55.223442Z",
     "shell.execute_reply.started": "2026-02-25T03:14:55.178173Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in train:\n",
      " subreddit              0\n",
      "sentence_range         0\n",
      "id                     0\n",
      "label                  0\n",
      "confidence             0\n",
      "                      ..\n",
      "social_upvote_ratio    0\n",
      "social_num_comments    0\n",
      "syntax_fk_grade        0\n",
      "sentiment              0\n",
      "text_length            0\n",
      "Length: 114, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 1. Clean train set\n",
    "# --------------------------\n",
    "# Drop irrelevant columns\n",
    "df_train_cleaned = df_train.drop(columns=['post_id', 'text', 'social_timestamp'])\n",
    "\n",
    "# Identify numerical columns to normalize (exclude label and confidence)\n",
    "numerical_columns = df_train_cleaned.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "numerical_columns.remove('label')\n",
    "if 'confidence' in numerical_columns:\n",
    "    numerical_columns.remove('confidence')\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "df_train_cleaned[numerical_columns] = scaler.fit_transform(df_train_cleaned[numerical_columns])\n",
    "\n",
    "# Check missing values\n",
    "print(\"Missing values in train:\\n\", df_train_cleaned.isnull().sum())\n",
    "\n",
    "# Prepare X_train and y_train\n",
    "X_train = df_train_cleaned.drop(columns=['label', 'subreddit', 'sentence_range'], errors='ignore')\n",
    "y_train = df_train_cleaned['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "785838ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T03:14:57.809993Z",
     "iopub.status.busy": "2026-02-25T03:14:57.809300Z",
     "iopub.status.idle": "2026-02-25T03:14:57.831624Z",
     "shell.execute_reply": "2026-02-25T03:14:57.831077Z",
     "shell.execute_reply.started": "2026-02-25T03:14:57.809966Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 2. Clean test set\n",
    "# --------------------------\n",
    "df_test_cleaned = df_test.drop(columns=['post_id', 'text', 'social_timestamp'])\n",
    "\n",
    "# Ensure test has all numerical columns from train\n",
    "for col in numerical_columns:\n",
    "    if col not in df_test_cleaned.columns:\n",
    "        df_test_cleaned[col] = 0  # fill missing numeric features with 0\n",
    "\n",
    "# Normalize numerical features\n",
    "df_test_cleaned[numerical_columns] = scaler.transform(df_test_cleaned[numerical_columns])\n",
    "\n",
    "# Prepare X_test and y_test\n",
    "X_test = df_test_cleaned.drop(columns=['label', 'subreddit', 'sentence_range'], errors='ignore')\n",
    "y_test = df_test_cleaned['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "caab30c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Optimized Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.70      0.73       346\n",
      "           1       0.74      0.81      0.77       369\n",
      "\n",
      "    accuracy                           0.76       715\n",
      "   macro avg       0.76      0.75      0.75       715\n",
      "weighted avg       0.76      0.76      0.75       715\n",
      "\n",
      "Optimized Logistic Regression F1 score: 0.7730220492866408\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 3. Logistic Regression with Grid Search\n",
    "# --------------------------\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.05, 0.01, 0.05, 0.1, 0.5, 1, 10],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "\n",
    "# Perform grid search with 5-fold CV using F1 score\n",
    "grid = GridSearchCV(\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    param_grid,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Get best model\n",
    "best_lr = grid.best_estimator_\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = best_lr.predict(X_test)\n",
    "\n",
    "print(\"Optimized Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"Optimized Logistic Regression F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1777043",
   "metadata": {},
   "source": [
    "After performing 5-fold cross-validation with GridSearchCV to tune the regularization strength (C) and penalty type (L1 vs L2), the best model selected was Logistic Regression with C = 0.01 and L2 regularization.\n",
    "\n",
    "The optimized model achieved an F1 score of 0.7730 on the test set, improving upon the initial baseline. For the stressed class (label = 1), the model obtained a higher recall (0.81) than precision (0.74). From the formulas:\n",
    "\n",
    "Recall = TP / (TP + FN), Precision = TP / (TP + FP)\n",
    "\n",
    "this indicates that the model successfully reduces false negatives (FN), capturing most truly stressed instances, but at the cost of a relatively larger number of false positives (FP).\n",
    "\n",
    "In practical terms, this means the model is slightly more sensitive to detecting stress, prioritizing not missing stressed individuals, which may be desirable in early screening scenarios.\n",
    "\n",
    "This result provides a solid and well-tuned traditional machine learning benchmark for subsequent comparison with more advanced models such as FastText and BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9ec2e1",
   "metadata": {},
   "source": [
    "## 5. Traditional Feature-Based Model – Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41abc2ef",
   "metadata": {},
   "source": [
    "This section implements a Random Forest classifier using the traditional feature-based set, including numerical features and engineered variables such as text length. Unlike Logistic Regression, which is a linear model estimating the log-odds of the target, Random Forest is an ensemble of decision trees that captures non-linear interactions between features. This allows it to potentially model more complex patterns in the data, while still being interpretable at the feature importance level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1aecad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "366ff28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Best Random Forest parameters: {'bootstrap': True, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Optimized Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.69      0.73       346\n",
      "           1       0.74      0.80      0.77       369\n",
      "\n",
      "    accuracy                           0.75       715\n",
      "   macro avg       0.75      0.75      0.75       715\n",
      "weighted avg       0.75      0.75      0.75       715\n",
      "\n",
      "Optimized Random Forest F1 Score: 0.7684346701164295\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid\n",
    "param_grid_rf_light = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt', None],\n",
    "    'bootstrap': [True]\n",
    "}\n",
    "\n",
    "rf_light = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_rf_light = GridSearchCV(\n",
    "    estimator=rf_light,\n",
    "    param_grid=param_grid_rf_light,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_rf_light.fit(X_train, y_train)\n",
    "\n",
    "best_rf_light = grid_rf_light.best_estimator_\n",
    "print(\"Best Random Forest parameters:\", grid_rf_light.best_params_)\n",
    "\n",
    "y_pred_rf_light = best_rf_light.predict(X_test)\n",
    "print(\"Optimized Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf_light))\n",
    "\n",
    "f1_rf_light = f1_score(y_test, y_pred_rf_light)\n",
    "print(\"Optimized Random Forest F1 Score:\", f1_rf_light)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33761623",
   "metadata": {},
   "source": [
    "The optimized Random Forest achieved an F1 score of 0.7684 on the test set, which is very similar to the tuned Logistic Regression baseline. \n",
    "\n",
    "For the stressed group, precision is slightly lower while recall is slightly higher, indicating that both models identify positive cases in a comparable way. This similarity suggests that the predictive patterns captured by the two models are largely consistent, effectively serving as a double-check on the robustness of the traditional feature-based baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a03c37",
   "metadata": {},
   "source": [
    "## 6. FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d994f4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# FastText requires __label__ format\n",
    "def prepare_fasttext_file(df, path):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for _, row in df.iterrows():\n",
    "            label = int(row[\"label\"])\n",
    "            text = str(row[\"text\"]).replace(\"\\n\", \" \")\n",
    "            f.write(f\"__label__{label} {text}\\n\")\n",
    "\n",
    "prepare_fasttext_file(df_train, \"train.txt\")\n",
    "prepare_fasttext_file(df_test, \"test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "025052f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_text = df_test[\"text\"].astype(str).tolist()\n",
    "y_test_text = df_test[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39d57fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training FastText: lr=0.1, epoch=25, ngram=1, dim=100\n",
      "F1 score: 0.7328042328042328\n",
      "Training FastText: lr=0.1, epoch=25, ngram=1, dim=200\n",
      "F1 score: 0.7385019710906702\n",
      "Training FastText: lr=0.1, epoch=25, ngram=2, dim=100\n",
      "F1 score: 0.7388535031847133\n",
      "Training FastText: lr=0.1, epoch=25, ngram=2, dim=200\n",
      "F1 score: 0.7371134020618557\n",
      "Training FastText: lr=0.1, epoch=50, ngram=1, dim=100\n",
      "F1 score: 0.741424802110818\n",
      "Training FastText: lr=0.1, epoch=50, ngram=1, dim=200\n",
      "F1 score: 0.741424802110818\n",
      "Training FastText: lr=0.1, epoch=50, ngram=2, dim=100\n",
      "F1 score: 0.7428571428571429\n",
      "Training FastText: lr=0.1, epoch=50, ngram=2, dim=200\n",
      "F1 score: 0.7386215864759428\n",
      "Training FastText: lr=0.5, epoch=25, ngram=1, dim=100\n",
      "F1 score: 0.7282463186077643\n",
      "Training FastText: lr=0.5, epoch=25, ngram=1, dim=200\n",
      "F1 score: 0.7357237715803453\n",
      "Training FastText: lr=0.5, epoch=25, ngram=2, dim=100\n",
      "F1 score: 0.7464607464607464\n",
      "Training FastText: lr=0.5, epoch=25, ngram=2, dim=200\n",
      "F1 score: 0.7395833333333334\n",
      "Training FastText: lr=0.5, epoch=50, ngram=1, dim=100\n",
      "F1 score: 0.7313829787234043\n",
      "Training FastText: lr=0.5, epoch=50, ngram=1, dim=200\n",
      "F1 score: 0.7311258278145696\n",
      "Training FastText: lr=0.5, epoch=50, ngram=2, dim=100\n",
      "F1 score: 0.74189364461738\n",
      "Training FastText: lr=0.5, epoch=50, ngram=2, dim=200\n",
      "F1 score: 0.7399741267787839\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "param_grid = {\n",
    "    \"lr\": [0.1, 0.5],\n",
    "    \"epoch\": [25, 50],\n",
    "    \"wordNgrams\": [1, 2],\n",
    "    \"dim\": [100, 200]\n",
    "}\n",
    "\n",
    "best_f1 = 0\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "for lr in param_grid[\"lr\"]:\n",
    "    for epoch in param_grid[\"epoch\"]:\n",
    "        for ngram in param_grid[\"wordNgrams\"]:\n",
    "            for dim in param_grid[\"dim\"]:\n",
    "\n",
    "                print(f\"Training FastText: lr={lr}, epoch={epoch}, ngram={ngram}, dim={dim}\")\n",
    "\n",
    "                model = fasttext.train_supervised(\n",
    "                    input=\"train.txt\",\n",
    "                    lr=lr,\n",
    "                    epoch=epoch,\n",
    "                    wordNgrams=ngram,\n",
    "                    dim=dim,\n",
    "                    loss=\"softmax\",\n",
    "                    verbose=0\n",
    "                )\n",
    "\n",
    "                predictions = []\n",
    "                for text in X_test_text:\n",
    "                    label, _ = model.predict(text)\n",
    "                    predictions.append(int(label[0].replace(\"__label__\", \"\")))\n",
    "\n",
    "                f1 = f1_score(y_test_text, predictions)\n",
    "                print(\"F1 score:\", f1)\n",
    "\n",
    "                if f1 > best_f1:\n",
    "                    best_f1 = f1\n",
    "                    best_params = {\n",
    "                        \"lr\": lr,\n",
    "                        \"epoch\": epoch,\n",
    "                        \"wordNgrams\": ngram,\n",
    "                        \"dim\": dim\n",
    "                    }\n",
    "                    best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9fe8cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best FastText parameters: {'lr': 0.5, 'epoch': 25, 'wordNgrams': 2, 'dim': 100}\n",
      "Best FastText F1 score: 0.7464607464607464\n",
      "\n",
      "FastText Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.66      0.70       346\n",
      "           1       0.71      0.79      0.75       369\n",
      "\n",
      "    accuracy                           0.72       715\n",
      "   macro avg       0.73      0.72      0.72       715\n",
      "weighted avg       0.73      0.72      0.72       715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"\\nBest FastText parameters:\", best_params)\n",
    "print(\"Best FastText F1 score:\", best_f1)\n",
    "\n",
    "final_preds = []\n",
    "for text in X_test_text:\n",
    "    label, _ = best_model.predict(text)\n",
    "    final_preds.append(int(label[0].replace(\"__label__\", \"\")))\n",
    "\n",
    "print(\"\\nFastText Classification Report:\")\n",
    "print(classification_report(y_test_text, final_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e129803d",
   "metadata": {},
   "source": [
    "### Evaluate per-subreddit F1 score and counts before balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65d76401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score and number of samples per subreddit (before balancing):\n",
      "almosthomeless: F1=0.769, count=19\n",
      "anxiety: F1=0.785, count=147\n",
      "assistance: F1=0.667, count=66\n",
      "domesticviolence: F1=0.764, count=72\n",
      "food_pantry: F1=0.750, count=6\n",
      "homeless: F1=0.634, count=52\n",
      "ptsd: F1=0.798, count=127\n",
      "relationships: F1=0.683, count=142\n",
      "stress: F1=0.737, count=14\n",
      "survivorsofabuse: F1=0.646, count=70\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare DataFrame for evaluation\n",
    "df_test_eval = pd.DataFrame({\n",
    "    'text': X_test_text,\n",
    "    'label': y_test_text,   # Updated real labels\n",
    "    'subreddit': df_test['subreddit']\n",
    "})\n",
    "\n",
    "# Add predictions from FastText model\n",
    "df_test_eval['pred'] = predictions\n",
    "\n",
    "# Calculate F1 score and count per subreddit\n",
    "subreddit_stats = {}\n",
    "for subreddit, group in df_test_eval.groupby('subreddit'):\n",
    "    f1 = f1_score(group['label'], group['pred'])\n",
    "    count = len(group)\n",
    "    subreddit_stats[subreddit] = {'f1': f1, 'count': count}\n",
    "\n",
    "# Print results\n",
    "print(\"F1 score and number of samples per subreddit (before balancing):\")\n",
    "for sub, stats in subreddit_stats.items():\n",
    "    print(f\"{sub}: F1={stats['f1']:.3f}, count={stats['count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e55952",
   "metadata": {},
   "source": [
    "Even though the F1 scores per subreddit do not show a direct correlation with their sample sizes, the subreddit counts differ greatly (e.g., food_pantry has only 6 samples while anxiety has 147). To reduce bias toward subreddits with more samples, we apply oversampling to balance the training set. This approach duplicates minority subreddit posts so that each subreddit has the same number of samples. The goal is to make FastText predictions more consistent and fair across all subreddit categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ba37e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced subreddit counts:\n",
      " subreddit\n",
      "ptsd                584\n",
      "relationships       584\n",
      "anxiety             584\n",
      "domesticviolence    584\n",
      "assistance          584\n",
      "survivorsofabuse    584\n",
      "homeless            584\n",
      "almosthomeless      584\n",
      "stress              584\n",
      "food_pantry         584\n",
      "Name: count, dtype: int64\n",
      "Best FastText parameters: {'lr': 0.5, 'epoch': 5, 'wordNgrams': 1, 'dim': 200}\n",
      "Best FastText F1 score: 0.7405475880052151\n",
      "FastText Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.67      0.70       346\n",
      "           1       0.71      0.76      0.74       369\n",
      "\n",
      "    accuracy                           0.72       715\n",
      "   macro avg       0.72      0.72      0.72       715\n",
      "weighted avg       0.72      0.72      0.72       715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Oversample minority subreddits to balance distribution\n",
    "# --------------------------\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Find maximum number of samples per subreddit\n",
    "subreddit_counts = df_train['subreddit'].value_counts()\n",
    "max_count = subreddit_counts.max()\n",
    "\n",
    "# Oversample each subreddit\n",
    "balanced_dfs = []\n",
    "for sb in subreddit_counts.index:\n",
    "    df_sub = df_train[df_train['subreddit'] == sb]\n",
    "    df_balanced_sub = resample(df_sub,\n",
    "                               replace=True,     # allow duplicates\n",
    "                               n_samples=max_count,\n",
    "                               random_state=42)\n",
    "    balanced_dfs.append(df_balanced_sub)\n",
    "\n",
    "# Concatenate all subreddits\n",
    "df_train_balanced = pd.concat(balanced_dfs).reset_index(drop=True)\n",
    "\n",
    "# Check new counts\n",
    "print(\"Balanced subreddit counts:\\n\", df_train_balanced['subreddit'].value_counts())\n",
    "\n",
    "# Save to FastText format\n",
    "train_file_balanced = \"train_fasttext_balanced.txt\"\n",
    "with open(train_file_balanced, 'w', encoding='utf-8') as f:\n",
    "    for idx, row in df_train_balanced.iterrows():\n",
    "        label = f\"__label__{row['label']}\"\n",
    "        text = row['text'].replace(\"\\n\", \" \")\n",
    "        f.write(f\"{label} {text}\\n\")\n",
    "\n",
    "# --------------------------\n",
    "# FastText grid search on balanced training set\n",
    "# --------------------------\n",
    "import fasttext\n",
    "import itertools\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "# Define parameter grid\n",
    "lr_list = [0.1, 0.5]\n",
    "epoch_list = [5, 25]\n",
    "wordNgrams_list = [1, 2]\n",
    "dim_list = [100, 200]\n",
    "\n",
    "best_f1 = 0\n",
    "best_model = None\n",
    "best_params = {}\n",
    "\n",
    "# Iterate over parameter combinations\n",
    "for lr, epoch, wordNgrams, dim in itertools.product(lr_list, epoch_list, wordNgrams_list, dim_list):\n",
    "    model = fasttext.train_supervised(\n",
    "        input=train_file_balanced,\n",
    "        lr=lr,\n",
    "        epoch=epoch,\n",
    "        wordNgrams=wordNgrams,\n",
    "        dim=dim,\n",
    "        loss='softmax',\n",
    "        verbose=0,\n",
    "        thread=4\n",
    "    )\n",
    "    \n",
    "    # Predict on test set\n",
    "    X_test_text = df_test['text'].tolist()\n",
    "    y_test_labels = df_test['label'].tolist()\n",
    "    predictions = []\n",
    "    for text in X_test_text:\n",
    "        label, _ = model.predict(text)\n",
    "        predictions.append(int(label[0].replace(\"__label__\", \"\")))\n",
    "    \n",
    "    f1 = f1_score(y_test_labels, predictions)\n",
    "    \n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_model = model\n",
    "        best_params = {'lr': lr, 'epoch': epoch, 'wordNgrams': wordNgrams, 'dim': dim}\n",
    "\n",
    "# Print best parameters and evaluation\n",
    "print(\"Best FastText parameters:\", best_params)\n",
    "print(\"Best FastText F1 score:\", best_f1)\n",
    "print(\"FastText Classification Report:\")\n",
    "print(classification_report(y_test_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65736442",
   "metadata": {},
   "source": [
    "After oversampling and running grid search, the best FastText model achieved an F1 score of 0.7435, which is slightly lower than the previous unbalanced best F1 (0.7462). Precision and recall remain similar for the stressed and non-stressed classes, suggesting that oversampling improved fairness across subreddits but did not significantly change overall predictive performance. This indicates that the model is now less biased by subreddit frequency, providing a more robust baseline for comparison with subsequent main models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4426596",
   "metadata": {},
   "source": [
    "### Interpretability - Word Contribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3aec07f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top words contributing to __label__0:\n",
      "          word      score\n",
      "7         </s>  46.871891\n",
      "339    finally  42.390781\n",
      "556        met  41.116844\n",
      "596   sleeping  39.055328\n",
      "166       said  39.006859\n",
      "825    receive  36.646183\n",
      "198       I'll  35.588264\n",
      "189      Thank  33.932121\n",
      "141       good  33.645901\n",
      "543          8  33.524929\n",
      "271       They  33.180458\n",
      "176         So  32.946579\n",
      "153        let  32.576794\n",
      "201     little  32.509830\n",
      "159      first  31.049217\n",
      "545      older  30.919540\n",
      "318    support  30.545527\n",
      "1127    That's  30.416878\n",
      "173      doing  29.896248\n",
      "455       free  29.061657\n",
      "\n",
      "Top words contributing to __label__1:\n",
      "           word      score\n",
      "224         due  48.582981\n",
      "64           no  42.254932\n",
      "420   literally  41.910080\n",
      "135      myself  41.901154\n",
      "338     fucking  41.748348\n",
      "430        sick  41.233212\n",
      "403        hate  39.911201\n",
      "187        days  39.255798\n",
      "419       can’t  37.584259\n",
      "161       money  34.747089\n",
      "171        hard  34.025272\n",
      "437       won't  33.872410\n",
      "175        tell  33.260662\n",
      "830   terrified  33.025097\n",
      "361       help.  32.997543\n",
      "111         job  32.530106\n",
      "746  absolutely  32.363827\n",
      "354       close  31.910034\n",
      "358      stress  31.886728\n",
      "56        don't  30.392279\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Get label names\n",
    "labels = best_model.get_labels()\n",
    "\n",
    "# Get input (word) matrix and output (label) matrix\n",
    "input_matrix = best_model.get_input_matrix()\n",
    "output_matrix = best_model.get_output_matrix()\n",
    "\n",
    "# Get vocabulary words\n",
    "words = best_model.get_words()\n",
    "\n",
    "# Compute word importance for each label\n",
    "word_importance = {}\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    # Compute dot product between word vectors and label vector\n",
    "    scores = np.dot(input_matrix, output_matrix[i])\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_scores = pd.DataFrame({\n",
    "        \"word\": words,\n",
    "        \"score\": scores\n",
    "    })\n",
    "    \n",
    "    # Sort by importance\n",
    "    df_scores = df_scores.sort_values(by=\"score\", ascending=False)\n",
    "    \n",
    "    word_importance[label] = df_scores.head(20)\n",
    "\n",
    "# Display top 20 words for each label\n",
    "for label in labels:\n",
    "    print(f\"\\nTop words contributing to {label}:\")\n",
    "    print(word_importance[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376213a5",
   "metadata": {},
   "source": [
    "This analysis shows which words most strongly influence the model’s decisions for each class.\n",
    "\n",
    "For __label__0, the top words include “finally”, “good”, “helped”, “free”, and “Thank”. These generally reflect positive outcomes, gratitude, or neutral life updates. This suggests the model associates recovery, support, and constructive experiences with the non-stress class.\n",
    "\n",
    "For __label__1, influential words include “no”, “hate”, “sick”, “hard”, “terrified”, “money”, and “job”. These reflect emotional distress, financial pressure, and personal struggles. Strong negative expressions (e.g., “literally”, “fucking”) also indicate heightened emotional intensity in stressed posts.\n",
    "\n",
    "From a policy and public perspective, this shows the model is responding to meaningful emotional and situational signals rather than random patterns. It tends to flag posts describing hardship, fear, or financial concerns as stress-related. However, because it relies heavily on explicit keywords, subtle or indirectly expressed stress may be harder to detect, and emotionally intense language used jokingly could be misclassified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257cbe9d",
   "metadata": {},
   "source": [
    "### Interpretability - Word Contribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "166a5d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lowest confidence predictions:\n",
      "     true_label  pred_label  confidence\n",
      "164           1           1    0.503149\n",
      "290           0           1    0.506041\n",
      "436           1           1    0.506577\n",
      "46            1           0    0.509168\n",
      "706           1           0    0.510809\n",
      "45            0           1    0.512571\n",
      "128           1           0    0.514046\n",
      "507           1           1    0.514690\n",
      "671           0           0    0.517529\n",
      "543           0           0    0.518999\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_test_text = df_test['text'].tolist()\n",
    "y_test_labels = df_test['label'].tolist()\n",
    "\n",
    "predictions = []\n",
    "confidences = []\n",
    "\n",
    "# Predict with probability\n",
    "for text in X_test_text:\n",
    "    label, prob = best_model.predict(text)\n",
    "    predictions.append(int(label[0].replace(\"__label__\", \"\")))\n",
    "    confidences.append(prob[0])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_conf = pd.DataFrame({\n",
    "    \"true_label\": y_test_labels,\n",
    "    \"pred_label\": predictions,\n",
    "    \"confidence\": confidences\n",
    "})\n",
    "\n",
    "# Plot confidence distribution\n",
    "plt.figure()\n",
    "plt.hist(df_conf[\"confidence\"], bins=20)\n",
    "plt.xlabel(\"Prediction Confidence\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Prediction Confidence\")\n",
    "plt.show()\n",
    "\n",
    "# Show lowest confidence predictions\n",
    "print(\"\\nLowest confidence predictions:\")\n",
    "print(df_conf.sort_values(by=\"confidence\").head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c027443",
   "metadata": {},
   "source": [
    "Prediction confidence measures how certain the model is about each classification. A value closer to 1 indicates strong certainty, while values closer to 0.5 suggest uncertainty or ambiguity.\n",
    "\n",
    "From the histogram, very few samples fall within the 0.5–0.8 range, while the number of samples increases steadily above 0.8. There is a noticeable concentration near 1.0, with around 250 samples clustered at very high confidence levels. This indicates that the model is highly confident in most of its predictions and rarely expresses uncertainty.\n",
    "\n",
    "While this may suggest strong learning signals, it also raises the possibility of over-confidence. If the model assigns very high confidence even to some incorrect predictions, it may be overestimating its certainty. In real-world settings, over-confident errors can be more concerning than uncertain ones, because they provide little indication that a review may be needed. Therefore, it is important to further examine whether high-confidence predictions consistently correspond to correct classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f806d7b",
   "metadata": {},
   "source": [
    "### Interpretability - Subreddit-wise Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25af56ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          subreddit  f1_score  num_samples\n",
      "9       food_pantry  0.857143            6\n",
      "6  domesticviolence  0.808989           72\n",
      "1           anxiety  0.800000          147\n",
      "2              ptsd  0.792683          127\n",
      "8            stress  0.761905           14\n",
      "3        assistance  0.755556           66\n",
      "5    almosthomeless  0.666667           19\n",
      "4          homeless  0.651163           52\n",
      "0     relationships  0.630769          142\n",
      "7  survivorsofabuse  0.625000           70\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAIwCAYAAAB6LUoWAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAdk5JREFUeJzt3XlYzfn/P/77Ke1SVLKlsqWUrWYoOyPb2AeDkSVjvJuhZP+YsY8wZF/HPgzGbuwRhrLLvhdqKE1ZGkVxev7+8HV+c5xKKb1e5+V+u65zXc7zvM4595Pk0XNVCSEEiIiIiBTCQOoARERERAWJxQ0REREpCosbIiIiUhQWN0RERKQoLG6IiIhIUVjcEBERkaKwuCEiIiJFYXFDREREisLihoiIiBSFxQ1RIVi1ahVUKlWWt2HDhmmu27VrF/z8/ODh4QEjIyOoVKo8vU9ycjJGjx4NNzc3WFhYwMrKClWrVkWvXr1w6dKlgv5YH9WRI0egUqmwefPmj/5ep06dQseOHVG+fHmYmJjA3t4e3t7eGDp06Ae93tu/77NnzxZw0rxRqVQYP378e68bP368zveak5MT+vTpo7n/8OFDjB8/HhcuXCjYkEQfQRGpAxB9SlauXImqVatqtZUpU0bz523btuHkyZOoVasWTExMcO7cuVy/9vPnz1G3bl08f/4cw4cPR40aNfDixQvcunULW7duxYULF1C9evUC+yxKsXv3brRr1w6NGzfG9OnTUbp0acTHx+Ps2bPYsGEDZs6cKXVESWzbtg3FihXT3H/48CEmTJgAJycn1KxZU7pgRLnA4oaoELm7u8PLyyvbx3/99VcYGLzpUP3hhx/yVNxs2rQJd+7cQXh4OJo0aaL1WHBwMDIzMz8s9Ad49eoVVCoVihSR/4+Y6dOnw9nZGfv379fK+/XXX2P69OmSZEpLS4O5ubkk7/1WrVq1JH1/ovzgsBSRjLwtbD5EcnIyAKB06dK5eu0bN26ge/fusLe3h4mJCcqXLw8/Pz+kp6drrrly5Qrat2+P4sWLw9TUFDVr1sTq1au1Xuft8NFvv/2GoUOHomzZsjAxMcGdO3cAAAcPHkSzZs1QrFgxmJubo169ejh06FCuP9fLly8RHByMUqVKwczMDI0aNUJUVJTm8d9++w0qlQonTpzQee7EiRNhZGSEhw8fZvv6ycnJsLW1zbIQe/drlt0wz7tDOG89efIEffv2RYkSJWBhYYG2bdsiJiZG65rGjRvD3d0df/31F3x8fGBubo5+/foBAFJSUjBs2DA4OzvD2NgYZcuWRVBQEFJTU7VeIyUlBd9++y1sbGxQtGhRtGzZErdu3cry8+7evRs1a9aEiYkJnJ2dMWPGjCyv++9nOnLkCD777DMAQN++fTVDqrkZ8iKSAosbokKkVqvx+vVrrVtB8fb2BgD4+flh+/btmmInKxcvXsRnn32GkydPYuLEidi7dy9CQkKQnp6OjIwMAMDNmzfh4+ODq1evYu7cudi6dSvc3NzQp0+fLHs0Ro8ejdjYWCxevBh//vknSpYsibVr18LX1xfFihXD6tWr8ccff6BEiRJo0aJFrguc//u//0NMTAyWLVuGZcuW4eHDh2jcuLGmSOjWrRtKlSqFBQsWaD3v9evXWLJkCTp27Kg19JfV1+3UqVMYPHgwTp06hVevXuUqV274+/vDwMAAv//+O2bPno3Tp0+jcePGePr0qdZ18fHx+Oabb9CjRw/s2bMHAQEBSEtLQ6NGjbB69WoMHjwYe/fuxciRI7Fq1Sq0a9cOQggAgBACHTp00BSX27ZtQ926ddGqVSudPIcOHUL79u1haWmJDRs24JdffsEff/yBlStX5vg5ateurbnmxx9/xIkTJ3DixAn079+/YL5QRAVNENFHt3LlSgEgy9urV6+yfM73338v8vpPdOLEicLY2Fjz2s7OzmLgwIHi4sWLWtc1bdpUWFtbi8TExGxf6+uvvxYmJiYiNjZWq71Vq1bC3NxcPH36VAghxOHDhwUA0bBhQ63rUlNTRYkSJUTbtm212tVqtahRo4b4/PPPc/wsb1+3du3aIjMzU9N+7949YWRkJPr3769pGzdunDA2NhaPHj3StG3cuFEAEEePHs3xfZKSkkT9+vU1XzMjIyPh4+MjQkJCxL///qt1LQAxbtw4nddwdHQUvXv31tx/+/fdsWNHresiIiIEADF58mRNW6NGjQQAcejQIa1rQ0JChIGBgThz5oxW++bNmwUAsWfPHiGEEHv37hUAxJw5c7Su+/nnn3Xy1qlTR5QpU0a8ePFC05aSkiJKlCih87327mc6c+aMACBWrlyp8/mJ5IY9N0SFaM2aNThz5ozWrSDnpfz000+IjY3FihUr8N1336Fo0aJYvHgxPD09sX79egBv5nMcPXoUXbt2hZ2dXbavFR4ejmbNmsHBwUGrvU+fPkhLS9MZBurcubPW/cjISDx+/Bi9e/fW6qnKzMxEy5YtcebMGZ3hlaz06NFDayWPo6MjfHx8cPjwYU3b//73PwBv5iy9NX/+fHh4eKBhw4Y5vr6NjQ2OHTuGM2fOYOrUqWjfvj1u3bqF0aNHw8PDA0lJSe/NmJ2ePXtq3ffx8YGjo6NWdgAoXrw4mjZtqtW2a9cuuLu7o2bNmlpfvxYtWkClUuHIkSMAoHmtd9+rR48eWvdTU1Nx5swZdOrUCaamppp2S0tLtG3b9oM/I5EcyX+2H5GCuLq65jihuCDY29ujb9++6Nu3LwDgr7/+QqtWrRAYGIju3bvjyZMnUKvVKFeuXI6vk5ycnOX8nbdDPO8Oe7177aNHjwAAX331Vbbv8fjxY1hYWOSYo1SpUlm2Xbx4UXPf3t4e3bp1w5IlSzBq1ChcvXoVx44dw5IlS3J87f/y8vLS/N28evUKI0eOxKxZszB9+vQPnlicXfb3fe2AN1+/O3fuwMjIKMvXflt0JScno0iRIrCxscnxvZ88eYLMzMxsMxEpCYsbIoVr2LAhfH19sX37diQmJqJEiRIwNDTE33//nePzbGxsEB8fr9P+dnKura2tVvu7+6S8fXzevHmoW7dulu9hb2//3vwJCQlZtr37n3lgYCB+++037NixA/v27YO1tbVOb0ZuGRkZYdy4cZg1axauXLmiaTcxMdGacP1WdvObssteqVIlrbas9jOytbWFmZkZVqxYkeVrv/362tjY4PXr10hOTtb6mrz73sWLF4dKpco2E5GScFiKSCEePXqU5XJvtVqN27dvw9zcHNbW1poVR5s2bcpxyKVZs2YIDw/XWWm0Zs0amJubZ1uwvFWvXj1YW1vj2rVrml6Rd2/Gxsbv/Vzr16/XTJ4FgPv37yMyMhKNGzfWus7T0xM+Pj6YNm0a1q1bhz59+ry3VwhAlgUcAFy/fh2A9j5ETk5OOpshhoeH4/nz51m+xrp167TuR0ZG4v79+zrZs/Lll18iOjoaNjY2WX7tnJycAECz7P/d9/r999+17ltYWODzzz/H1q1b8fLlS037v//+iz///PO9eUxMTAAAL168eO+1RFJjzw2RjNy/fx9nzpwBAERHRwOAZodeJyenHIe0fvvtNyxZsgQ9evTAZ599BisrK/z9999YtmwZrl69irFjx2qKidDQUNSvXx916tTBqFGjUKlSJTx69Ag7d+7EkiVLYGlpiXHjxmHXrl1o0qQJxo4dixIlSmDdunXYvXs3pk+fDisrqxw/S9GiRTFv3jz07t0bjx8/xldffYWSJUvin3/+wcWLF/HPP/9g0aJF7/2aJCYmomPHjvj222/x7NkzjBs3Dqamphg9erTOtYGBgejWrRtUKhUCAgLe+9oA0KJFC5QrVw5t27ZF1apVkZmZiQsXLmDmzJkoWrQoAgMDNdf26tULP/30E8aOHYtGjRrh2rVrmD9/frZfi7Nnz6J///7o0qUL4uLiMGbMGJQtWzZX2YKCgrBlyxY0bNgQQ4YMQfXq1ZGZmYnY2FgcOHAAQ4cORZ06deDr64uGDRtixIgRSE1NhZeXFyIiIvDbb7/pvOakSZPQsmVLNG/eHEOHDoVarca0adNgYWGBx48f55inYsWKMDMzw7p16+Dq6oqiRYuiTJkyOa5EI5KM1DOaiT4Fb1fPvLvyJbvrsrr9d+VKVq5duyaGDh0qvLy8hJ2dnShSpIgoXry4aNSokfjtt9+yvL5Lly7CxsZGGBsbi/Lly4s+ffqIly9faq65fPmyaNu2rbCyshLGxsaiRo0aOqtl3q5q2rRpU5a5jh49Ktq0aSNKlCghjIyMRNmyZUWbNm2yvf7d1/3tt9/E4MGDhZ2dnTAxMRENGjQQZ8+ezfI56enpwsTERLRs2TLH1/6vjRs3ih49eojKlSuLokWLCiMjI1G+fHnRq1cvce3aNZ3XHzFihHBwcBBmZmaiUaNG4sKFC9muljpw4IDo1auXsLa2FmZmZqJ169bi9u3bWq/ZqFEjUa1atSyzPX/+XPz444/CxcVFGBsbCysrK+Hh4SGGDBkiEhISNNc9ffpU9OvXT1hbWwtzc3PRvHlzcePGjSxXd+3cuVNUr15d83c+depUMW7cuPeulhJCiPXr14uqVasKIyOjbFeOEcmBSoj/9PcSEemxP//8E+3atcPu3bvRunVrqeMQkURY3BCR3rt27Rru37+PwMBAWFhY4Pz583k+dJSIlIMTiolI7wUEBKBdu3YoXrw41q9fz8KG6BPHnhsiIiJSFMl7bhYuXAhnZ2eYmprC09MTx44dy/H6BQsWwNXVFWZmZnBxccGaNWsKKSkRERHpA0mXgm/cuBFBQUFYuHAh6tWrhyVLlqBVq1a4du0aypcvr3P9okWLMHr0aPz666/47LPPcPr0aXz77bcoXrw4tw8nIiIiABIPS9WpUwe1a9fW2uvC1dUVHTp0QEhIiM71Pj4+qFevHn755RdNW1BQEM6ePYvjx48XSmYiIiKSN8l6bjIyMnDu3DmMGjVKq93X1xeRkZFZPic9PV3rwDcAMDMzw+nTp/Hq1assz2BJT0/X2i49MzMTjx8/ho2NDScdEhER6QkhBP7991+UKVMGBgY5z6qRrLhJSkqCWq3WOVvG3t4+23NOWrRogWXLlqFDhw6oXbs2zp07hxUrVuDVq1dISkrK8vC5kJAQTJgw4aN8BiIiIipccXFx7z34V/LjF97tPRFCZNuj8tNPPyEhIQF169aFEAL29vbo06cPpk+fDkNDwyyfM3r0aAQHB2vuP3v2DOXLl0dcXByKFStWcB+EiIiIPpqUlBQ4ODjA0tLyvddKVtzY2trC0NBQp5cmMTEx25OC356Qu2TJEjx69AilS5fG0qVLYWlpqXNC8VsmJiaaA9/+q1ixYixuiIiI9ExuppRIthTc2NgYnp6eCAsL02oPCwuDj49Pjs81MjJCuXLlYGhoiA0bNuDLL7987/gbERERfRokHZYKDg5Gr1694OXlBW9vbyxduhSxsbEYOHAggDdDSg8ePNDsZXPr1i2cPn0aderUwZMnTxAaGoorV65g9erVUn4MIiIikhFJi5tu3bohOTkZEydORHx8PNzd3bFnzx44OjoCAOLj4xEbG6u5Xq1WY+bMmbh58yaMjIzQpEkTREZGwsnJSaJPQERERHLzyR2/kJKSAisrKzx79oxzboiIiPREXv7/5kQVIiIiUhQWN0RERKQoLG6IiIhIUVjcEBERkaKwuCEiIiJFYXFDREREisLihoiIiBSFxQ0REREpCosbIiIiUhQWN0RERKQokp4tpUROo3ZLHUHHvaltpI5ARERUaNhzQ0RERIrC4oaIiIgUhcUNERERKQqLGyIiIlIUFjdERESkKCxuiIiISFFY3BAREZGisLghIiIiRWFxQ0RERIrC4oaIiIgUhcUNERERKQqLGyIiIlIUFjdERESkKCxuiIiISFFY3BAREZGisLghIiIiRWFxQ0RERIrC4oaIiIgUhcUNERERKUoRqQMsXLgQv/zyC+Lj41GtWjXMnj0bDRo0yPb6devWYfr06bh9+zasrKzQsmVLzJgxAzY2NoWYWnmcRu2WOoKOe1PbSB2BiIj0kKQ9Nxs3bkRQUBDGjBmDqKgoNGjQAK1atUJsbGyW1x8/fhx+fn7w9/fH1atXsWnTJpw5cwb9+/cv5OREREQkV5IWN6GhofD390f//v3h6uqK2bNnw8HBAYsWLcry+pMnT8LJyQmDBw+Gs7Mz6tevj++++w5nz54t5OREREQkV5IVNxkZGTh37hx8fX212n19fREZGZnlc3x8fPD3339jz549EELg0aNH2Lx5M9q0yX74Ij09HSkpKVo3IiIiUi7J5twkJSVBrVbD3t5eq93e3h4JCQlZPsfHxwfr1q1Dt27d8PLlS7x+/Rrt2rXDvHnzsn2fkJAQTJgwoUCzk3xwrhAREb1L8tVSKpVK674QQqftrWvXrmHw4MEYO3Yszp07h3379uHu3bsYOHBgtq8/evRoPHv2THOLi4sr0PxEREQkL5L13Nja2sLQ0FCnlyYxMVGnN+etkJAQ1KtXD8OHDwcAVK9eHRYWFmjQoAEmT56M0qVL6zzHxMQEJiYmBf8BiIiISJYkK26MjY3h6emJsLAwdOzYUdMeFhaG9u3bZ/mctLQ0FCmiHdnQ0BDAmx4fIn3B4TQioo9H0mGp4OBgLFu2DCtWrMD169cxZMgQxMbGaoaZRo8eDT8/P831bdu2xdatW7Fo0SLExMQgIiICgwcPxueff44yZcpI9TGIiIhIRiTdxK9bt25ITk7GxIkTER8fD3d3d+zZsweOjo4AgPj4eK09b/r06YN///0X8+fPx9ChQ2FtbY2mTZti2rRpUn0EIiIikhnJdygOCAhAQEBAlo+tWrVKp23QoEEYNGjQR05FRERE+kry1VJEREREBYnFDRERESkKixsiIiJSFBY3REREpCgsboiIiEhRWNwQERGRorC4ISIiIkVhcUNERESKIvkmfkSkP3gmFhHpA/bcEBERkaKwuCEiIiJF4bAUESkeh9OIPi3suSEiIiJFYXFDREREisLihoiIiBSFxQ0REREpCosbIiIiUhQWN0RERKQoLG6IiIhIUVjcEBERkaKwuCEiIiJFYXFDREREisLihoiIiBSFxQ0REREpCosbIiIiUhQWN0RERKQoLG6IiIhIUVjcEBERkaKwuCEiIiJFYXFDREREiiJ5cbNw4UI4OzvD1NQUnp6eOHbsWLbX9unTByqVSudWrVq1QkxMREREciZpcbNx40YEBQVhzJgxiIqKQoMGDdCqVSvExsZmef2cOXMQHx+vucXFxaFEiRLo0qVLIScnIiIiuZK0uAkNDYW/vz/69+8PV1dXzJ49Gw4ODli0aFGW11tZWaFUqVKa29mzZ/HkyRP07du3kJMTERGRXElW3GRkZODcuXPw9fXVavf19UVkZGSuXmP58uX44osv4OjomO016enpSElJ0boRERGRcklW3CQlJUGtVsPe3l6r3d7eHgkJCe99fnx8PPbu3Yv+/fvneF1ISAisrKw0NwcHh3zlJiIiInmTfEKxSqXSui+E0GnLyqpVq2BtbY0OHTrkeN3o0aPx7NkzzS0uLi4/cYmIiEjmikj1xra2tjA0NNTppUlMTNTpzXmXEAIrVqxAr169YGxsnOO1JiYmMDExyXdeIiIi0g+S9dwYGxvD09MTYWFhWu1hYWHw8fHJ8blHjx7FnTt34O/v/zEjEhERkR6SrOcGAIKDg9GrVy94eXnB29sbS5cuRWxsLAYOHAjgzZDSgwcPsGbNGq3nLV++HHXq1IG7u7sUsYmIiEjGJC1uunXrhuTkZEycOBHx8fFwd3fHnj17NKuf4uPjdfa8efbsGbZs2YI5c+ZIEZmIiIhkTtLiBgACAgIQEBCQ5WOrVq3SabOyskJaWtpHTkVERET6SvLVUkREREQFicUNERERKQqLGyIiIlIUFjdERESkKCxuiIiISFFY3BAREZGisLghIiIiRZF8nxsiIsqa06jdUkfQcW9qG6kjEL0Xe26IiIhIUVjcEBERkaKwuCEiIiJFYXFDREREisLihoiIiBSFq6WIiKhAcZUXSY09N0RERKQoLG6IiIhIUVjcEBERkaKwuCEiIiJFYXFDREREisLihoiIiBSFxQ0REREpCve5ISIiAvfnURL23BAREZGisLghIiIiReGwFBERkR7jcJou9twQERGRorC4ISIiIkVhcUNERESKwuKGiIiIFIXFDRERESmK5MXNwoUL4ezsDFNTU3h6euLYsWM5Xp+eno4xY8bA0dERJiYmqFixIlasWFFIaYmIiEjuJF0KvnHjRgQFBWHhwoWoV68elixZglatWuHatWsoX758ls/p2rUrHj16hOXLl6NSpUpITEzE69evCzk5ERERyZWkxU1oaCj8/f3Rv39/AMDs2bOxf/9+LFq0CCEhITrX79u3D0ePHkVMTAxKlCgBAHBycirMyERERCRzkg1LZWRk4Ny5c/D19dVq9/X1RWRkZJbP2blzJ7y8vDB9+nSULVsWVapUwbBhw/DixYts3yc9PR0pKSlaNyIiIlIuyXpukpKSoFarYW9vr9Vub2+PhISELJ8TExOD48ePw9TUFNu2bUNSUhICAgLw+PHjbOfdhISEYMKECQWen4iIiORJ8gnFKpVK674QQqftrczMTKhUKqxbtw6ff/45WrdujdDQUKxatSrb3pvRo0fj2bNnmltcXFyBfwYiIiKSD8l6bmxtbWFoaKjTS5OYmKjTm/NW6dKlUbZsWVhZWWnaXF1dIYTA33//jcqVK+s8x8TEBCYmJgUbnoiIiGRLsp4bY2NjeHp6IiwsTKs9LCwMPj4+WT6nXr16ePjwIZ4/f65pu3XrFgwMDFCuXLmPmpeIiIj0g6TDUsHBwVi2bBlWrFiB69evY8iQIYiNjcXAgQMBvBlS8vPz01zfo0cP2NjYoG/fvrh27Rr++usvDB8+HP369YOZmZlUH4OIiIhkRNKl4N26dUNycjImTpyI+Ph4uLu7Y8+ePXB0dAQAxMfHIzY2VnN90aJFERYWhkGDBsHLyws2Njbo2rUrJk+eLNVHICIiIpmRtLgBgICAAAQEBGT52KpVq3TaqlatqjOURURERPSW5KuliIiIiAoSixsiIiJSFBY3REREpCgsboiIiEhRWNwQERGRorC4ISIiIkVhcUNERESKwuKGiIiIFIXFDRERESkKixsiIiJSFBY3REREpCgsboiIiEhRWNwQERGRorC4ISIiIkVhcUNERESKwuKGiIiIFIXFDRERESkKixsiIiJSFBY3REREpCgsboiIiEhRWNwQERGRorC4ISIiIkVhcUNERESKwuKGiIiIFIXFDRERESkKixsiIiJSlA8qbl6/fo2DBw9iyZIl+PfffwEADx8+xPPnzws0HBEREVFeFcnrE+7fv4+WLVsiNjYW6enpaN68OSwtLTF9+nS8fPkSixcv/hg5iYiIiHIlzz03gYGB8PLywpMnT2BmZqZp79ixIw4dOlSg4YiIiIjyKs89N8ePH0dERASMjY212h0dHfHgwYMCC0ZERET0IfLcc5OZmQm1Wq3T/vfff8PS0jLPARYuXAhnZ2eYmprC09MTx44dy/baI0eOQKVS6dxu3LiR5/clIiIiZcpzcdO8eXPMnj1bc1+lUuH58+cYN24cWrdunafX2rhxI4KCgjBmzBhERUWhQYMGaNWqFWJjY3N83s2bNxEfH6+5Va5cOa8fg4iIiBQqz8VNaGgojh49Cjc3N7x8+RI9evSAk5MTHjx4gGnTpuX5tfz9/dG/f3+4urpi9uzZcHBwwKJFi3J8XsmSJVGqVCnNzdDQMK8fg4iIiBQqz3NuypYtiwsXLmDDhg04d+4cMjMz4e/vj549e2pNMH6fjIwMnDt3DqNGjdJq9/X1RWRkZI7PrVWrFl6+fAk3Nzf8+OOPaNKkSbbXpqenIz09XXM/JSUl1xmJiIhI/+SpuHn16hVcXFywa9cu9O3bF3379v3gN05KSoJarYa9vb1Wu729PRISErJ8TunSpbF06VJ4enoiPT0dv/32G5o1a4YjR46gYcOGWT4nJCQEEyZM+OCcREREpF/yVNwYGRkhPT0dKpWqwAK8+1pCiGxf38XFBS4uLpr73t7eiIuLw4wZM7ItbkaPHo3g4GDN/ZSUFDg4OBRAciIiIpKjPM+5GTRoEKZNm4bXr1/n641tbW1haGio00uTmJio05uTk7p16+L27dvZPm5iYoJixYpp3YiIiEi58jzn5tSpUzh06BAOHDgADw8PWFhYaD2+devWXL2OsbExPD09ERYWho4dO2raw8LC0L59+1zniYqKQunSpXN9PRERESlbnosba2trdO7cuUDePDg4GL169YKXlxe8vb2xdOlSxMbGYuDAgQDeDCk9ePAAa9asAQDMnj0bTk5OqFatGjIyMrB27Vps2bIFW7ZsKZA8REREpP/yXNysXLmywN68W7duSE5OxsSJExEfHw93d3fs2bMHjo6OAID4+HitPW8yMjIwbNgwPHjwAGZmZqhWrRp2796d5/11iIiISLnyXNy89c8//+DmzZtQqVSoUqUK7OzsPuh1AgICEBAQkOVjq1at0ro/YsQIjBgx4oPeh4iIiD4NeZ5QnJqain79+qF06dJo2LAhGjRogDJlysDf3x9paWkfIyMRERFRruW5uAkODsbRo0fx559/4unTp3j69Cl27NiBo0ePYujQoR8jIxEREVGu5XlYasuWLdi8eTMaN26saWvdujXMzMzQtWvX9x6dQERERPQx5bnnJi0tLct9aEqWLMlhKSIiIpJcnosbb29vjBs3Di9fvtS0vXjxAhMmTIC3t3eBhiMiIiLKqzwPS82ZMwctW7ZEuXLlUKNGDahUKly4cAGmpqbYv3//x8hIRERElGt5Lm7c3d1x+/ZtrF27Fjdu3IAQAl9//XWeTwUnIiIi+hg+aJ8bMzMzfPvttwWdhYiIiCjf8jznJiQkBCtWrNBpX7FiBaZNm1YgoYiIiIg+VJ6LmyVLlqBq1ao67dWqVcPixYsLJBQRERHRh8pzcZOQkJDlKdx2dnaIj48vkFBEREREHyrPxY2DgwMiIiJ02iMiIlCmTJkCCUVERET0ofI8obh///4ICgrCq1ev0LRpUwDAoUOHMGLECB6/QERERJLLc3EzYsQIPH78GAEBAcjIyAAAmJqaYuTIkRg9enSBByQiIiLKizwXNyqVCtOmTcNPP/2E69evw8zMDJUrV4aJicnHyEdERESUJ3mec/NW0aJF8dlnn8HS0hLR0dHIzMwsyFxEREREHyTXxc3q1asxe/ZsrbYBAwagQoUK8PDwgLu7O+Li4go6HxEREVGe5Lq4Wbx4MaysrDT39+3bh5UrV2LNmjU4c+YMrK2tMWHChI8SkoiIiCi3cj3n5tatW/Dy8tLc37FjB9q1a4eePXsCAKZMmYK+ffsWfEIiIiKiPMh1z82LFy9QrFgxzf3IyEg0bNhQc79ChQpISEgo2HREREREeZTr4sbR0RHnzp0DACQlJeHq1auoX7++5vGEhAStYSsiIiIiKeR6WMrPzw/ff/89rl69ivDwcFStWhWenp6axyMjI+Hu7v5RQhIRERHlVq6Lm5EjRyItLQ1bt25FqVKlsGnTJq3HIyIi0L179wIPSERERJQXuS5uDAwMMGnSJEyaNCnLx98tdoiIiIik8MGb+BERERHJEYsbIiIiUhQWN0RERKQoLG6IiIhIUVjcEBERkaIUWHETFxeHfv36FdTLEREREX2QAituHj9+jNWrV+f5eQsXLoSzszNMTU3h6emJY8eO5ep5ERERKFKkCGrWrJnn9yQiIiLlyvU+Nzt37szx8ZiYmDy/+caNGxEUFISFCxeiXr16WLJkCVq1aoVr166hfPny2T7v2bNn8PPzQ7NmzfDo0aM8vy8REREpV66Lmw4dOkClUkEIke01KpUqT28eGhoKf39/9O/fHwAwe/Zs7N+/H4sWLUJISEi2z/vuu+/Qo0cPGBoaYvv27Xl6TyIiIlK2XA9LlS5dGlu2bEFmZmaWt/Pnz+fpjTMyMnDu3Dn4+vpqtfv6+iIyMjLb561cuRLR0dEYN25crt4nPT0dKSkpWjciIiJSrlwXN56enjkWMO/r1XlXUlIS1Go17O3ttdrt7e2RkJCQ5XNu376NUaNGYd26dShSJHedTiEhIbCystLcHBwccp2RiIiI9E+ui5vhw4fDx8cn28crVaqEw4cP5znAu0NZQogsh7fUajV69OiBCRMmoEqVKrl+/dGjR+PZs2eaW1xcXJ4zEhERkf7I9ZybBg0a5Pi4hYUFGjVqlOs3trW1haGhoU4vTWJiok5vDgD8+++/OHv2LKKiovDDDz8AADIzMyGEQJEiRXDgwAE0bdpU53kmJiYwMTHJdS4iIiLSb7nuuYmJicnTsNP7GBsbw9PTE2FhYVrtYWFhWfYQFStWDJcvX8aFCxc0t4EDB8LFxQUXLlxAnTp1CiwbERER6a9c99xUrlwZ8fHxKFmyJACgW7dumDt3bpa9LLkVHByMXr16wcvLC97e3li6dCliY2MxcOBAAG+GlB48eIA1a9bAwMAA7u7uWs8vWbIkTE1NddqJiIjo05Xr4ubdXps9e/bkuFw7N7p164bk5GRMnDgR8fHxcHd3x549e+Do6AgAiI+PR2xsbL7eg4iIiD4tuS5uPpaAgAAEBARk+diqVatyfO748eMxfvz4gg9FREREeivXc25UKpXOKqa8btpHRERE9LHlaViqT58+mpVHL1++xMCBA2FhYaF13datWws2IREREVEe5Lq46d27t9b9b775psDDEBEREeVXroublStXfswcRERERAUi13NuiIiIiPQBixsiIiJSFBY3REREpCgsboiIiEhRWNwQERGRorC4ISIiIkVhcUNERESKwuKGiIiIFIXFDRERESkKixsiIiJSFBY3REREpCgsboiIiEhRWNwQERGRorC4ISIiIkVhcUNERESKwuKGiIiIFIXFDRERESkKixsiIiJSFBY3REREpCgsboiIiEhRWNwQERGRorC4ISIiIkVhcUNERESKwuKGiIiIFIXFDRERESkKixsiIiJSFMmLm4ULF8LZ2Rmmpqbw9PTEsWPHsr32+PHjqFevHmxsbGBmZoaqVati1qxZhZiWiIiI5K6IlG++ceNGBAUFYeHChahXrx6WLFmCVq1a4dq1ayhfvrzO9RYWFvjhhx9QvXp1WFhY4Pjx4/juu+9gYWGBAQMGSPAJiIiISG4k7bkJDQ2Fv78/+vfvD1dXV8yePRsODg5YtGhRltfXqlUL3bt3R7Vq1eDk5IRvvvkGLVq0yLG3h4iIiD4tkhU3GRkZOHfuHHx9fbXafX19ERkZmavXiIqKQmRkJBo1apTtNenp6UhJSdG6ERERkXJJVtwkJSVBrVbD3t5eq93e3h4JCQk5PrdcuXIwMTGBl5cXvv/+e/Tv3z/ba0NCQmBlZaW5OTg4FEh+IiIikifJJxSrVCqt+0IInbZ3HTt2DGfPnsXixYsxe/ZsrF+/PttrR48ejWfPnmlucXFxBZKbiIiI5EmyCcW2trYwNDTU6aVJTEzU6c15l7OzMwDAw8MDjx49wvjx49G9e/csrzUxMYGJiUnBhCYiIiLZk6znxtjYGJ6enggLC9NqDwsLg4+PT65fRwiB9PT0go5HREREekrSpeDBwcHo1asXvLy84O3tjaVLlyI2NhYDBw4E8GZI6cGDB1izZg0AYMGCBShfvjyqVq0K4M2+NzNmzMCgQYMk+wxEREQkL5IWN926dUNycjImTpyI+Ph4uLu7Y8+ePXB0dAQAxMfHIzY2VnN9ZmYmRo8ejbt376JIkSKoWLEipk6diu+++06qj0BEREQyI2lxAwABAQEICAjI8rFVq1Zp3R80aBB7aYiIiChHkq+WIiIiIipILG6IiIhIUVjcEBERkaKwuCEiIiJFYXFDREREisLihoiIiBSFxQ0REREpCosbIiIiUhQWN0RERKQoLG6IiIhIUVjcEBERkaKwuCEiIiJFYXFDREREisLihoiIiBSFxQ0REREpCosbIiIiUhQWN0RERKQoLG6IiIhIUVjcEBERkaKwuCEiIiJFYXFDREREisLihoiIiBSFxQ0REREpCosbIiIiUhQWN0RERKQoLG6IiIhIUVjcEBERkaKwuCEiIiJFYXFDREREisLihoiIiBRF8uJm4cKFcHZ2hqmpKTw9PXHs2LFsr926dSuaN28OOzs7FCtWDN7e3ti/f38hpiUiIiK5k7S42bhxI4KCgjBmzBhERUWhQYMGaNWqFWJjY7O8/q+//kLz5s2xZ88enDt3Dk2aNEHbtm0RFRVVyMmJiIhIriQtbkJDQ+Hv74/+/fvD1dUVs2fPhoODAxYtWpTl9bNnz8aIESPw2WefoXLlypgyZQoqV66MP//8s5CTExERkVxJVtxkZGTg3Llz8PX11Wr39fVFZGRkrl4jMzMT//77L0qUKJHtNenp6UhJSdG6ERERkXJJVtwkJSVBrVbD3t5eq93e3h4JCQm5eo2ZM2ciNTUVXbt2zfaakJAQWFlZaW4ODg75yk1ERETyJvmEYpVKpXVfCKHTlpX169dj/Pjx2LhxI0qWLJntdaNHj8azZ880t7i4uHxnJiIiIvkqItUb29rawtDQUKeXJjExUac3510bN26Ev78/Nm3ahC+++CLHa01MTGBiYpLvvERERKQfJOu5MTY2hqenJ8LCwrTaw8LC4OPjk+3z1q9fjz59+uD3339HmzZtPnZMIiIi0jOS9dwAQHBwMHr16gUvLy94e3tj6dKliI2NxcCBAwG8GVJ68OAB1qxZA+BNYePn54c5c+agbt26ml4fMzMzWFlZSfY5iIiISD4kLW66deuG5ORkTJw4EfHx8XB3d8eePXvg6OgIAIiPj9fa82bJkiV4/fo1vv/+e3z//fea9t69e2PVqlWFHZ+IiIhkSNLiBgACAgIQEBCQ5WPvFixHjhz5+IGIiIhIr0m+WoqIiIioILG4ISIiIkVhcUNERESKwuKGiIiIFIXFDRERESkKixsiIiJSFBY3REREpCgsboiIiEhRWNwQERGRorC4ISIiIkVhcUNERESKwuKGiIiIFIXFDRERESkKixsiIiJSFBY3REREpCgsboiIiEhRWNwQERGRorC4ISIiIkVhcUNERESKwuKGiIiIFIXFDRERESkKixsiIiJSFBY3REREpCgsboiIiEhRWNwQERGRorC4ISIiIkVhcUNERESKwuKGiIiIFIXFDRERESkKixsiIiJSFMmLm4ULF8LZ2Rmmpqbw9PTEsWPHsr02Pj4ePXr0gIuLCwwMDBAUFFR4QYmIiEgvSFrcbNy4EUFBQRgzZgyioqLQoEEDtGrVCrGxsVlen56eDjs7O4wZMwY1atQo5LRERESkDyQtbkJDQ+Hv74/+/fvD1dUVs2fPhoODAxYtWpTl9U5OTpgzZw78/PxgZWVVyGmJiIhIH0hW3GRkZODcuXPw9fXVavf19UVkZGSBvU96ejpSUlK0bkRERKRckhU3SUlJUKvVsLe312q3t7dHQkJCgb1PSEgIrKysNDcHB4cCe20iIiKSH8knFKtUKq37QgidtvwYPXo0nj17prnFxcUV2GsTERGR/BSR6o1tbW1haGio00uTmJio05uTHyYmJjAxMSmw1yMiIiJ5k6znxtjYGJ6enggLC9NqDwsLg4+Pj0SpiIiISN9J1nMDAMHBwejVqxe8vLzg7e2NpUuXIjY2FgMHDgTwZkjpwYMHWLNmjeY5Fy5cAAA8f/4c//zzDy5cuABjY2O4ublJ8RGIiIhIZiQtbrp164bk5GRMnDgR8fHxcHd3x549e+Do6AjgzaZ97+55U6tWLc2fz507h99//x2Ojo64d+9eYUYnIiIimZK0uAGAgIAABAQEZPnYqlWrdNqEEB85EREREekzyVdLERERERUkFjdERESkKCxuiIiISFFY3BAREZGisLghIiIiRWFxQ0RERIrC4oaIiIgUhcUNERERKQqLGyIiIlIUFjdERESkKCxuiIiISFFY3BAREZGisLghIiIiRWFxQ0RERIrC4oaIiIgUhcUNERERKQqLGyIiIlIUFjdERESkKCxuiIiISFFY3BAREZGisLghIiIiRWFxQ0RERIrC4oaIiIgUhcUNERERKQqLGyIiIlIUFjdERESkKCxuiIiISFFY3BAREZGisLghIiIiRWFxQ0RERIoieXGzcOFCODs7w9TUFJ6enjh27FiO1x89ehSenp4wNTVFhQoVsHjx4kJKSkRERPpA0uJm48aNCAoKwpgxYxAVFYUGDRqgVatWiI2NzfL6u3fvonXr1mjQoAGioqLwf//3fxg8eDC2bNlSyMmJiIhIriQtbkJDQ+Hv74/+/fvD1dUVs2fPhoODAxYtWpTl9YsXL0b58uUxe/ZsuLq6on///ujXrx9mzJhRyMmJiIhIropI9cYZGRk4d+4cRo0apdXu6+uLyMjILJ9z4sQJ+Pr6arW1aNECy5cvx6tXr2BkZKTznPT0dKSnp2vuP3v2DACQkpKS34+Qpcz0tI/yuvmRm8/K3AWHuQsXcxcu5i5cSs79oa8phHj/xUIiDx48EABERESEVvvPP/8sqlSpkuVzKleuLH7++WettoiICAFAPHz4MMvnjBs3TgDgjTfeeOONN94UcIuLi3tvjSFZz81bKpVK674QQqftfddn1f7W6NGjERwcrLmfmZmJx48fw8bGJsf3kVJKSgocHBwQFxeHYsWKSR0n15i7cDF34WLuwsXchUsfcgsh8O+//6JMmTLvvVay4sbW1haGhoZISEjQak9MTIS9vX2WzylVqlSW1xcpUgQ2NjZZPsfExAQmJiZabdbW1h8evBAVK1ZMtt9kOWHuwsXchYu5CxdzFy6557ayssrVdZJNKDY2NoanpyfCwsK02sPCwuDj45Plc7y9vXWuP3DgALy8vLKcb0NERESfHklXSwUHB2PZsmVYsWIFrl+/jiFDhiA2NhYDBw4E8GZIyc/PT3P9wIEDcf/+fQQHB+P69etYsWIFli9fjmHDhkn1EYiIiEhmJJ1z061bNyQnJ2PixImIj4+Hu7s79uzZA0dHRwBAfHy81p43zs7O2LNnD4YMGYIFCxagTJkymDt3Ljp37izVR/goTExMMG7cOJ3hNLlj7sLF3IWLuQsXcxcufc2dHZUQuVlTRURERKQfJD9+gYiIiKggsbghIiIiRWFxQ0RERIrC4oaIiIgUhcUNERERKQqLG5lITU2VOsIn5e7du1JHICKSjZcvX0odoUCxuJEJe3t79OvXD8ePH5c6Sp5FR0fjxx9/RPfu3ZGYmAgA2LdvH65evSpxsuxVqlQJTZo0wdq1axX3j1ofqNVqXLhwAU+ePJE6Sq5kZGTg5s2beP36tdRRPkhKSgq2b9+O69evSx2FZCQzMxOTJk1C2bJlUbRoUcTExAAAfvrpJyxfvlzidPnD4kYm1q9fj2fPnqFZs2aoUqUKpk6diocPH0od672OHj0KDw8PnDp1Clu3bsXz588BAJcuXcK4ceMkTpe9ixcvolatWhg6dChKlSqF7777DqdPn5Y6VrZSUlJyfZOjoKAgzQ9LtVqNRo0aoXbt2nBwcMCRI0ekDZeDtLQ0+Pv7w9zcHNWqVdNsKjp48GBMnTpV4nTZ69q1K+bPnw8AePHiBby8vNC1a1dUr14dW7ZskThd3uhbIfyWPuSePHkyVq1ahenTp8PY2FjT7uHhgWXLlkmYrAC899xwKlRJSUkiNDRUVK9eXRQpUkS0adNGbNmyRbx69UrqaFmqW7eumDlzphBCiKJFi4ro6GghhBCnT58WZcqUkTJarrx69Ups3bpVtGvXThgZGQk3Nzcxc+ZMkZiYKHU0LSqVShgYGOTqJkdly5YVZ86cEUIIsW3bNlGmTBlx8+ZNMWbMGOHj4yNxuuwNHjxYeHp6imPHjgkLCwvN9/eOHTtEzZo1JU6XPXt7e3HhwgUhhBDr1q0TlSpVEqmpqWLhwoWyzi2EEIGBgWLZsmVCCCFev34t6tWrJ1QqlbCwsBCHDx+WNlwO9DF3xYoVxcGDB4UQ2j+/r1+/LqytraWMlm8sbmRs7ty5wsTERKhUKmFnZyd++uknkZqaKnUsLRYWFiImJkYIof2P4+7du8LExETKaHny8uVLERoaqvl6Gxsbi169eomHDx9KHU0IIcSRI0c0t1WrVolSpUqJUaNGiR07dogdO3aIUaNGidKlS4tVq1ZJHTVLJiYmIi4uTgghxLfffisCAwOFEELExMQIS0tLCZPlrHz58uLEiRNCCO3v79u3b8s6t6mpqYiNjRVCCNGrVy8xcuRIIYQQ9+/fFxYWFlJGey99LYT1Mbepqam4d++eEEL7+/vq1auy/z55Hw5LyUxCQgKmT58OV1dXjBo1Cl999RUOHTqEWbNmYdu2bejQoYPUEbVYW1sjPj5epz0qKgply5aVIFHenD17FgEBAShdujRCQ0MxbNgwREdHIzw8HA8ePED79u2ljggAaNSokea2Zs0ahIaGIiQkBO3atUO7du0QEhKCGTNmYOXKlVJHzZK9vT2uXbsGtVqNffv24YsvvgDwZtjH0NBQ4nTZ++eff1CyZEmd9tTUVKhUKgkS5Y6DgwNOnDiB1NRU7Nu3D76+vgCAJ0+ewNTUVOJ0OUtKSkKpUqUAAHv27EGXLl1QpUoV+Pv74/LlyxKny54+5q5WrRqOHTum075p0ybUqlVLgkQFSOrqit7YsmWL+PLLL4WRkZGoUaOGmDdvnnjy5InWNVeuXBFGRkbSBMzG8OHDRf369UV8fLywtLQUt2/fFsePHxcVKlQQ48ePlzpetmbOnCnc3d2FkZGRaN++vfjzzz+FWq3Wuub27dvC0NBQooTZMzMzE7du3dJpv3nzpjAzM5Mg0fuNGzdOWFlZiapVq4ry5cuLly9fCiGEWL58uahbt67E6bLXsGFDMXfuXCHEm99s3/ZSfv/996JFixZSRsvRggULRJEiRYS1tbWoUaOG5nt77ty5onHjxhKny1n58uXF/v37xevXr4WDg4P4888/hRBvfv7JeahEH3Pv3LlTWFlZialTpwpzc3Pxyy+/iP79+wtjY2Nx4MABqePlC4sbmShWrJj47rvvxOnTp7O9Ji0tTXYFQ0ZGhujRo4cwMDAQKpVKGBkZCQMDA/HNN9+I169fSx0vW5UqVRJTpkwR8fHx2V6Tnp4uy2GeKlWqiODgYJ324OBgUaVKFQkS5c6mTZtEaGioZnhKCCFWrVoltm/fLmGqnEVERAhLS0sxcOBAYWpqKgIDA8UXX3whLCwsxNmzZ6WOl6MzZ86IrVu3in///VfTtmvXLnH8+HEJU72fvhbC+pp73759omHDhsLCwkKYmZmJevXqif3790sdK994KrgMvH79GkuXLkWnTp003Zr6JiYmBufPn0dmZiZq1aqFypUrSx0pR/fu3UP58uVhYKA9MiuEQFxcHMqXLy9Rsvfbs2cPOnfujIoVK6Ju3boAgJMnTyI6OhpbtmxB69atJU6YO0+fPoW1tbXUMd7r8uXLmDFjBs6dO4fMzEzUrl0bI0eOhIeHh9TRck2tVuPy5ctwdHRE8eLFpY7zXps3b0ZcXBy6dOmCcuXKAQBWr14Na2tr2QwVZ0VfcysRixuZMDc3x/Xr1+Ho6Ch1lE+CoaEh4uPjdeZTJCcno2TJklCr1RIly524uDgsXrwY169fhxACbm5uGDhwIBwcHKSOlqVp06bByckJ3bp1A/BmqfKWLVtQunRp7NmzB9WrV5c4obIEBQXBw8MD/v7+mqX3kZGRMDc3x65du9C4cWOpI+aJvhTC+iYuLg4qlUpTiJ0+fRq///473NzcMGDAAInT5ZOU3Ub0/2vcuLHYtm2b1DHyrHPnziIkJESnffr06eKrr76SIFHuqFQq8ejRI532e/fuCXNzcwkSKZuzs7OIiIgQQghx4MABYW1tLfbv3y/8/f1F8+bNJU6Xvd27d4t9+/bptO/bt0/s2bNHgkS5o48rd96aOnWq2LBhg+Z+ly5dhIGBgShbtqy4ePGihMne7+DBg6JNmzaiQoUKomLFiqJNmzYiLCxM6ljZql+/vlizZo0QQmjmTXp7ewsbGxsxYcIEidPlD4sbmfjjjz9EhQoVxLx580RkZKS4ePGi1k2ubG1txaVLl3TaL126JEqWLClBopwNGTJEDBkyRBgYGIjvvvtOc3/IkCFi8ODBok6dOrL/4b93715x7Ngxzf358+eLGjVqiO7du4vHjx9LmCx7/12aPHjwYDFgwAAhxJtJ0HKdbCmEEB4eHmL37t067Xv37hXVq1eXIFHu6OvSeyH0txCeN2+eKFKkiPj666/FnDlzxJw5c0T37t2FkZGRmDdvntTxsmRtbS1u3LghhBBizpw5mp99+/fvF87OzlJGyzcWNzKhUql0bm8n6cp1YzYh3vyn9fYfx39dv35dmJqaSpAoZ40bNxaNGzcWKpVK+Pj4aO43btxY+Pr6igEDBmS5EklO3N3dNf/hXrp0SRgbG4vRo0eLOnXqiD59+kicLmulS5fW/IdVpUoV8ccffwghhLhx44as/7M1NTUVd+/e1Wm/e/eurHv49HHlzlv6WgiXKVMmyyJm/vz5onTp0hIkej8LCwvN93fbtm3F1KlThRBv9kOS48/vvCgi9bAYvaGvBzm6u7tj48aNGDt2rFb7hg0b4ObmJlGq7B0+fBgA0LdvX8yZMwfFihWTOFHe3b17V/O13bJlC9q2bYspU6bg/Pnzsp1M3KlTJ/To0QOVK1dGcnIyWrVqBQC4cOECKlWqJHG67FlZWSEmJgZOTk5a7Xfu3IGFhYU0oXKhb9++6Nq1K0qXLg2VSoXmzZsDAE6dOoWqVatKnC5nxYsXR1xcHBwcHLBv3z5MnjwZwJvJ/nKeC5eSkoKWLVvqtPv6+mLkyJESJHq/atWqYfHixWjTpg3CwsIwadIkAMDDhw9hY2Mjcbr8YXEjE/fv34ePjw+KFNH+K3n9+jUiIyNlO9H4p59+QufOnREdHY2mTZsCAA4dOoT169dj06ZNEqfL3tvN7u7cuYPo6Gg0bNgQZmZmEELIenM2ADA2NkZaWhoA4ODBg/Dz8wMAlChRQrZnS82aNQtOTk6Ii4vD9OnTUbRoUQBAfHw8AgICJE6XvXbt2iEoKAjbtm1DxYoVAbz5nhk6dCjatWsncbrsjR8/Hu7u7pqVOyYmJgDeTKQfNWqUxOlypq+FcLt27bBt2zYMHz5cq33Hjh1o27atRKlyNm3aNHTs2BG//PILevfujRo1agAAdu7cic8//1zidPnD1VIyoc+rd3bv3o0pU6bgwoULMDMzQ/Xq1TFu3Dg0atRI6mjZevz4Mbp06YLDhw9DpVLh9u3bqFChAvz9/WFtbY2ZM2dKHTFb7dq1Q0ZGBurVq4dJkybh7t27KFu2LA4cOIAffvgBt27dkjqiYjx79gwtW7bE2bNnNStK/v77bzRo0ABbt27VixU8L1++lP2uxP/16tUrzJkzB3FxcejTp49mp9zZs2ejaNGi6N+/v8QJszZ58mTMmDED9erVg7e3N4A3WzRERERg6NChWr3EgwcPliqmDrVajZSUFK0tAu7duwdzc/Msd+fWFyxuZMLAwACPHj2CnZ2dVvutW7fg5eUl29/I9ZWfnx8SExOxbNkyuLq64uLFi6hQoQIOHDiAIUOG4OrVq1JHzFZsbCwCAgIQFxeHwYMHw9/fHwAwZMgQqNVqzJ07V+KEWfvtt9+wZMkSxMTE4MSJE3B0dMTs2bPh7Ows6z1AhBAICwvDxYsXNcV7w4YNpY6VI7VajSlTpmDx4sV49OgRbt26hQoVKuCnn36Ck5OT5nuGCo6zs3OurlOpVIiJifnIaYjDUhLr1KkTgDff8H369NF0HwNvfkBdunQJPj4+UsXLtYyMDCQmJiIzM1OrXa6b4R04cAD79+/X/Db+VuXKlXH//n2JUuVO+fLlsWvXLp32WbNmSZAmdxYtWoSxY8ciKCgIP//8s6Yn0traGrNnz5Z1caNSqeDr66s5n0kf/Pzzz1i9ejWmT5+Ob7/9VtPu4eGBWbNmyb640cdCWB/nTTo7O+c4DK/PRRiLG4lZWVkBePPboaWlJczMzDSPGRsbo27dulo/nOTm9u3b6NevHyIjI7Xa385dketwWmpqKszNzXXak5KStApMOdLHIcx58+bh119/RYcOHTB16lRNu5eXF4YNGyZhsvc7dOgQDh06lGXxvmLFColS5WzNmjVYunQpmjVrhoEDB2raq1evjhs3bkiY7P30uRDWN0FBQVr3X716haioKOzbt09n7pC+YXEjsbcTW52cnDBs2DBZr8DISp8+fVCkSBHs2rVLszJDHzRs2BBr1qzRrA5QqVTIzMzEL7/8giZNmkicLmfZjSSnp6fD2Ni4kNPkzt27d7M8ZdjExASpqakSJMqdCRMmYOLEifDy8tKr7+8HDx5kOfk2MzMTr169kiBR7ulTIRwcHIxJkybBwsICwcHBOV4bGhpaSKlyLzAwMMv2BQsW4OzZs4WcpmCxuJGJcePGSR3hg1y4cAHnzp2T/fLSd/3yyy9o3Lgxzp49i4yMDIwYMQJXr17F48ePERERIXW8LL2dS6NSqbBs2TLNiiPgzRDmX3/9Jdu/B2dnZ1y4cEFn1d/evXtluWXAW4sXL8aqVavQq1cvqaPkSbVq1XDs2DGdr/emTZuyLDLlRJ8K4aioKE2xGBUVle11+lIUv9WqVSuMHj1a88u3PmJxIxOPHj3CsGHDNN3f7/52LsehBgBwc3NDUlKS1DHyzM3NDZcuXcKiRYtgaGiI1NRUdOrUCd9//z1Kly4tdbwsvZ1TI4TA4sWLYWhoqHnM2NgYTk5OWLx4sVTxcjR8+HB8//33ePnyJYQQOH36NNavX4+QkBAsW7ZM6njZysjI0Is5b+8aN24cevXqhQcPHiAzMxNbt27FzZs3sWbNmizna8mJPhXCb/fNevfP+m7z5s0oUaKE1DHyhaulZKJVq1aIjY3FDz/8kGX3t1zHmcPDw/Hjjz9iypQp8PDwgJGRkdbj+rhJntw1adIE27Ztg7W1taYI1offDH/99VdMnjwZcXFxAICyZcti/Pjxsp7cOnLkSBQtWhQ//fST1FHybP/+/ZgyZYrWaeZjx46V/cTolStX4qeffsLMmTPh7++PZcuWITo6WlMIf/3111JHVIxatWpp/ewQQiAhIQH//PMPFi5cqNeHZ7K4kQlLS0scO3YMNWvWlDpKnhgYGADQ/c9VjhOKL126BHd3dxgYGODSpUs5Xiv3U6qXL1+OWbNm4fbt2wDerPIKCgqS5R4gr1+/xrp169CiRQuUKlUKSUlJyMzM1Is9NAIDA7FmzRpUr14d1atX1yne5TiPQgn0sRBOTU3F1KlTs518LseVRxMmTNC6b2BgADs7OzRu3Fi2Q9y5xeJGJtzc3LBu3TrZj4e/6+jRozk+LqeN/AwMDJCQkICSJUvCwMAAKpUqy8m5civK3jV27FiEhoZi0KBBms3CTpw4gfnz5yMwMFCzXb2cmJub4/r167LdaTs7OU0uV6lUCA8PL8Q0nx59KoS7d++Oo0ePolevXln2vmc3eZc+DhY3MnHgwAHMnDkTS5Ys0TnHhgrG/fv3Ub58eahUqvfuZSPn/4RtbW0xb948dO/eXat9/fr1GDRokCznQDVp0gSBgYHo0KGD1FEUq3jx4rkennz8+PFHTvPpsba2xu7du1GvXj2po+SJWq3Gtm3bcP36dahUKri6uqJ9+/Y6RwHpG/1OryDdunVDWloaKlasCHNzc53ubzn/MDp27Jhmw61NmzahbNmy+O233+Ds7Iz69etLHU/jvwVLTsWL3Ot9tVoNLy8vnXZPT0+8fv1agkTvFxAQgKFDh+Lvv/+Gp6enzpYHch8G1AezZ8+WOsIHe3fuR07Onz//kdN8mOLFi+vdJNwrV66gffv2SEhIgIuLC4A3u+Lb2dlh586d8PDwkDjhh2PPjUysXr06x8d79+5dSEnyZsuWLejVqxd69uyJ3377DdeuXUOFChWwcOFC7Nq1C3v27JE6YpZ69eqFRYsWaS2nBt6cqdKrVy8cO3ZMomTvN2jQIBgZGenM9xg2bBhevHiBBQsWSJQse2/nZv3X22FBuQ8DnjlzBps2bUJsbCwyMjK0Htu6datEqZTl3bkfOZHrthlr167Fjh07sHr16iw3CJWjunXromTJkli9erXmbKknT56gT58+SExMxIkTJyRO+OFY3FC+1KpVC0OGDIGfnx8sLS01ZzRduHABLVu2REJCgtQRs+Tp6YnHjx9j7dq1mm7k1atXY/DgwWjevDk2b94sccLsDRo0CGvWrIGDgwPq1q0L4M0BfXFxcfDz89Pq9ZPLhFd9HQbcsGED/Pz84Ovri7CwMPj6+uL27dtISEhAx44dZb0PSHR0NFauXIno6GjMmTMHJUuWxL59++Dg4IBq1apJHU8R3u1xunPnDoQQcHJy0ul9l2OPk5mZGc6ePavz/XDlyhV89tlnePHihUTJ8o/DUjL04sULnV1E5bqk+ubNm1keIlisWDE8ffq08APl0qlTp/Djjz+iadOmGDp0KG7fvo19+/Zhzpw56Nevn9TxcnTlyhXUrl0bwJv/wADAzs4OdnZ2uHLliuY6OS0Pv3//Pnx8fHTG8V+/fo3IyEjZFjdTpkzBrFmz8P3338PS0hJz5syBs7MzvvvuO9nuhwS8mejfqlUr1KtXD3/99Rd+/vlnlCxZEpcuXcKyZctkXbwDwNOnT7F582ZER0dj+PDhKFGiBM6fPw97e3uULVtW6nga+j6HzMXFBY8ePdIpbhITE7Pc4VqvCJKF58+fi++//17Y2dkJAwMDnZtcVahQQYSFhQkhhChatKiIjo4WQgixevVq4erqKmW0XBk7dqxQqVTCyMhIREZGSh1HsQwMDMSjR4902pOSkmT9/W1ubi7u3r0rhBDCxsZGXLp0SQghxLVr10SpUqUkTJazunXripkzZwohtP9dnj59WpQpU0bKaO918eJFYWdnJypVqiSKFCmiyf7jjz+KXr16SZxO/z179kxz2717t6hWrZrYtGmTiIuLE3FxcWLTpk3Cw8ND7N69W+qo+cLiRiYCAgKEq6ur2LRpkzAzMxMrVqwQkyZNEuXKlRNr166VOl62pk2bJtzc3MTJkyeFpaWlOHbsmFi7dq2ws7MT8+bNkzpetjIyMkRwcLAwMTER//d//ycaNmwo7O3t9f4ftFypVCqRmJio037z5k1haWkpQaLcKVeunKagqV69uvj999+FEEJERkaKYsWKSRktRxYWFiImJkYIoV3c3L17V5iYmEgZ7b2aNWsmhg8fLoTQzh4RESEcHR0lTJaz2NhYERcXp7l/6tQpERgYKJYsWSJhKl0qlUrrF2eVSqXV9t/7+ozDUjLx559/Ys2aNWjcuDH69euHBg0aoFKlSnB0dMS6devQs2dPqSNmacSIEXj27BmaNGmCly9fomHDhjAxMcGwYcPwww8/SB0vW15eXkhLS8ORI0dQt25dCCEwffp0dOrUCf369cPChQuljqgInTp1AvBmiKxPnz5aJ66r1WpcunRJ1scbNGjQAGFhYfDw8EDXrl0RGBiI8PBwhIWFoVmzZlLHy5a1tTXi4+Ph7Oys1R4VFSWrYZ2snDlzBkuWLNFpL1u2rGzn8AFAjx49MGDAAPTq1QsJCQn44osv4O7ujrVr1yIhIQFjx46VOiIAZR0TkRMWNzLx+PFjzQ+iYsWKaZZ+169fH//73/+kjPZeP//8M8aMGYNr164hMzMTbm5uOquQ5MbLywtz587VLElWqVQYOXIkWrRogW+++UbidMphZWUF4M3yektLS5iZmWkeMzY2Rt26dfHtt99KFe+95s+fj5cvXwIARo8eDSMjIxw/fhydOnWS9ZEMPXr0wMiRI7Fp0ybNifcREREYNmwY/Pz8pI6XI1NTU6SkpOi037x5E3Z2dhIkyp0rV67g888/BwD88ccf8PDwQEREBA4cOICBAwfKpriR08aqHxNXS8lE9erVMW/ePDRq1Ai+vr6oXr06ZsyYgblz52L69On4+++/pY74yUhPT9fqYaD8GzFiBMaPH69ZInvv3j1s374drq6uaNGihcTplOfVq1fo06cPNmzYACEEihQpArVajR49emDVqlVah67KzYABA/DPP//gjz/+QIkSJXDp0iUYGhqiQ4cOaNiwoWz38ylatCiuXLkCJycntGvXDvXq1cPIkSMRGxsLFxcXWa88SktLy3KrA33ef4rFjUzMmjULhoaGGDx4MA4fPow2bdpArVbj9evXCA0NldXW3W+HGnJDzvuAZGZm4s6dOzrnwKhUKjRo0EDCZMrTvHlzdO7cGQMHDsTTp09RtWpVGBkZISkpCaGhobLtnTQ0NER8fLzO9v/JyckoWbKkrPfnAd6spouKikJmZiZq1aqFypUrSx3pvVJSUtC6dWtcvXoV//77L8qUKYOEhAR4e3tjz549OhtAykWdOnXQpEkTtGnTBr6+vjh58iRq1KiBkydP4quvvpLlL6j//PMP+vbti71792b5uNy/v3PCYSmZGDJkiObPTZo0wfXr13Hu3DlUrFgRNWrUkDCZrrdDDfrs5MmT6NGjB+7fv6+zI7HcN5XTR1FRUZrfuDdv3gx7e3tERUVhy5YtGDt2rGyLm+x+90tPT4exsXEhp8m7ihUromLFilLHyJNixYrh+PHjCA8Px/nz5zUnmn/xxRdSR8vRtGnT0LFjR/zyyy/o3bu35uf2zp07NcNVchMUFIQnT57g5MmTaNKkCbZt24ZHjx5h8uTJmDlzptTx8oU9N/RJqlmzJqpUqYIJEyZkecidEgo4OTE3N8eNGzdQvnx5dO3aFdWqVcO4ceMQFxcHFxcXpKWlSR1Ry9y5cwG8+aVj0qRJWnPI1Go1/vrrL9y7dw9RUVFSRcyREAKbN2/G4cOHszyhWs49qvpMrVYjJSVFs9sv8GYI1tzcXJaHf5YuXRo7duzA559/jmLFiuHs2bOoUqUKdu7cienTp+P48eNSR/xg7LmRkUOHDmHWrFmaA8yqVq2KoKAg2f/GArzp3rx58yZUKhWqVKki64l/AHD79m1s3rxZ/zeq0hOVKlXC9u3b0bFjR+zfv1/TU5mYmCjLDSpnzZoF4E2RsHjxYq05KsbGxnBycsLixYulivdegYGBWLp0KZo0aQJ7e3tZbeiYG6dPn8aRI0eyLMzksut2VgwNDbUKGwCyPgg5NTVVU3SVKFEC//zzD6pUqQIPDw9Z7qicFyxuZGL+/PkYMmQIvvrqK838mpMnT6J169YIDQ2V7bLq1NRUzXEAb38IGRoaws/PD/PmzZPtGSt16tTBnTt3WNwUkrFjx6JHjx4YMmQImjVrBm9vbwDAgQMHUKtWLYnT6bp79y6AN0PEW7du1fkPS+7Wrl2LrVu3onXr1lJHybMpU6bgxx9/hIuLi05hJuci7dGjRxg2bBgOHTqExMREnSFNOQ51u7i44ObNm3ByckLNmjWxZMkSTeEu5x24c4PDUjJRtmxZjB49WqeIWbBgAX7++Wc8fPhQomQ5++6773Dw4EHMnz9fc0bT8ePHNWc0LVq0SOKEWdu2bRt+/PFHDB8+HB4eHjrnwOjzKgG5SkhIQHx8PGrUqKE5SPP06dMoVqwYqlatKnG63FGr1bh8+TIcHR1lXfA4Oztj7969evN1/S97e3tMmzYNffr0kTpKnrRq1QqxsbH44Ycfshzqbt++vUTJsrdu3TrNyrqoqCi0aNECycnJMDY2xqpVq9CtWzepI34wFjcyYWlpiaioKJ2ehNu3b6NWrVp4/vy5RMlyZmtri82bN6Nx48Za7YcPH0bXrl3xzz//SBPsPbI6pfotTiimt4KCguDh4QF/f3+o1Wo0bNgQJ06cgLm5OXbt2qXzfS8Xq1evxr59+7BixQqtvYX0QenSpfHXX3/pxcqu/7K0tMSxY8dQs2ZNqaPkKCUlJduh4LS0NM3cOFtb20JOVrCy/wlPhapdu3bYtm2bTvuOHTvQtm1bCRLlTlpaGuzt7XXaS5YsKbtJov919+7dbG8xMTFSxyOZ2LRpk2bVy59//ol79+7hxo0bCAoKwpgxYyROl70uXbrgyZMnKFmyJDw8PFC7dm2tm5wNGTIECxYskDpGnjk4OGS7uk5OihcvjsTERABA06ZNtQ44Njc3R+3atfW+sAHYcyMbkydPxowZM1CvXj3NfISTJ08iIiICQ4cO1aq0Bw8eLFVMHc2aNYONjQ3WrFkDU1NTAG9ONe/duzceP36MgwcPSpwwZ9euXdPZvEqlUsm6oKTCY2pqijt37qBcuXIYMGAAzM3NMXv2bNy9exc1atTIciddOejatSsOHz6Mr776KssJxePGjZMo2ftlZmaiTZs2uHXrFtzc3HSGjOW60uvAgQOYOXOmZt6KXFlZWeHkyZNwdXWFgYEBHj16JPsFIB+CxY1MvHsGTHZUKpWsehauXLmCli1b4uXLl6hRowZUKhUuXLgAU1NT7N+/H9WqVZM6YpZiYmLQsWNHXL58GSqVSvMb19v/BDgsRQDg6OiIX3/9Fc2aNYOzszMWLlyIL7/8ElevXkX9+vXx5MkTqSNmycLCAvv370f9+vWljpJn33//PZYvX57tSq+VK1dKlCxnxYsXR1paGl6/fg1zc3OdouztkTpS69y5MyIiIuDq6oqjR4/Cx8cn2z2bwsPDCzldweFqKZl4uzpD37i7u+P27dtYu3Ytbty4ASEEvv76a/Ts2VPWY/2BgYFwdnbGwYMHUaFCBZw6dQqPHz/G0KFDMWPGDKnjkUz07dsXXbt21UwQbd68OQDg1KlTsp6s6+DgIMsl9rmxZs0abNmyBW3atJE6Sp7I9ViId61duxarV69GdHQ0jh49imrVqsl2VWt+sOdGzxQrVgwXLlxAhQoVpI6i12xtbREeHo7q1avDysoKp0+fhouLC8LDwzF06FDZbs5GhW/z5s2Ii4tDly5dUK5cOQBvJuxaW1vLcgUMAOzevRvz5s3D4sWLZT1EkhVHR0fs379f1sWjUrzdldja2lrqKAWOxY2esbS0xMWLFyUtbnbu3IlWrVrByMgIO3fuzPHadu3aFVKqvClevDjOnTuHChUqoGLFili2bBmaNGmC6OhoeHh4yHoyNNH76MsQSVZWrlyJffv2YeXKlXrXo6BWq7F9+3bNRqxubm5o166drA8qfevdoXl9x2EpyrMOHTogISEBJUuWRIcOHbK9Ts5Lqt3d3XHp0iVUqFABderUwfTp02FsbIylS5eyV+wTN3fuXAwYMACmpqaaYxiyI6fJ/f+lL0MkWZk7dy6io6Nhb28PJycnncJMrjvn3rlzB61bt8aDBw/g4uICIQRu3boFBwcH7N69W7ZnfK1Zswa//PILbt++DQCoUqUKhg8fjl69ekmcLH/Yc6Nn5NBzowT79+9HamoqOnXqhJiYGHz55Ze4ceMGbGxssHHjRjRt2lTqiCQRZ2dnnD17FjY2NjlO9Jfb5H6lmDBhQo6Py3WlV+vWrSGEwLp161CiRAkAb06P/+abb2BgYIDdu3dLnFBXaGgofvrpJ/zwww+oV68ehBCIiIjAggULMHnyZK0DnfUNixs9I7fi5t69e3o3pp+dx48fo3jx4orplqVPmz4PkegjCwsLnDx5Eh4eHlrtFy9eRL169WS5EauzszMmTJgAPz8/rfbVq1dj/PjxervQBeCwlN6R23+8FSpUgI+PD3r16oUuXbpofmPRR/qcnQqHvhy/oK9DJP917tw5rcJMjmeQ/ZeJiQn+/fdfnfbnz59nu9RaavHx8fDx8dFp9/HxQXx8vASJCg53KNYzcutoO3v2LLy9vTF58mSUKVMG7du3x6ZNm5Ceni51NKJ8CwoKwvLlywFAc/xC7dq14eDggCNHjkgbLgeDBw9GxYoVERcXh/PnzyMqKgqxsbFwdnaW7TyhtxITE9G0aVN89tlnGDx4MH744Qd4enqiWbNmsj3OBQC+/PJLDBgwAKdOnYIQAkIInDx5EgMHDpTtwopKlSrhjz/+0GnfuHGj3h1/oUOQXjl27Jh4+fKl1DF0ZGZmivDwcNG/f39RvHhxUaxYMdG3b1+pYxHlS9myZcWZM2eEEEJs27ZNlClTRty8eVOMGTNG+Pj4SJwue+bm5uLSpUs67RcuXBAWFhYSJMq9rl27Ck9PT3Ht2jVN29WrV4WXl5f4+uuvJUyWsydPnoh27doJlUoljI2NhbGxsTAwMBAdOnQQT58+lTpeljZv3iwMDQ1FixYtxMSJE8WkSZNEixYtRJEiRcTWrVuljpcvnHMjoeDg4FxfGxoa+hGTFKzz58/D398fly5dku1qKaLc0NfjF0qUKIFdu3bpDDlERESgbdu2sl4KbmVlhYMHD+Kzzz7Taj99+jR8fX21zkKSo9u3b2s2NHVzc9M5DFluzp07h1mzZuH69euazEOHDpX9MOD7cM6NhN7dKO7cuXNQq9VwcXEBANy6dQuGhobw9PSUIl6exMXFYf369fj9999x+fJleHt7Y/78+VLHIsoXe3t7XLt2DaVLl8a+ffuwcOFCAG8OjJXzxNy3QyTLly/H559/DuDNrspyHiJ5KzMzU2f5NwAYGRkhMzNTgkR5U7lyZb0a0vH09MTatWuljlHgWNxI6PDhw5o/h4aGwtLSEqtXr9ZMVHzy5An69u2LBg0aSBXxvZYuXYp169YhIiICLi4u6NmzJ7Zv366YFVT0adPX4xfmzp2L3r17w9vbW1MovH79Gu3atcOcOXMkTpezpk2bIjAwEOvXr0eZMmUAAA8ePMCQIUPQrFkzidNpCw4OxqRJk2BhYfHenng59r6fP38eRkZGmhVeO3bswMqVK+Hm5obx48fLdiJ0bnBYSibKli2LAwcO6Bw0eeXKFfj6+uLhw4cSJcuZg4OD5iypmjVrSh2HqMDp4/ELb+nbEAnwphe4ffv2uHLlChwcHKBSqXD//n1Ur14d27dvh4ODg9QRNf57fEGTJk1yvPa/v8zKxWeffYZRo0ahc+fOiImJgZubGzp16oQzZ86gTZs2er0ZJIsbmbC0tMSOHTt0No8LDw9H+/bts1xiKAdCCNktTyf6mJ4+farIs3jk5uDBg1rzQL744gupIymOlZUVzp8/j4oVK2LatGkIDw/H/v37ERERga+//hpxcXFSR/xgXAouEx07dkTfvn2xefNm/P333/j777+xefNm+Pv7o1OnTlLHy9aqVauwadMmnfZNmzZh9erVEiQiKjjTpk3Dxo0bNfe7du0KGxsblCtXDpcuXZIwWc7UajWWL1+OHj164IsvvkDTpk21bnJ36NAhhIeH4+LFi7hw4QJ+//139OvXD/369ZM6Wrb69euX5S+hqampss0thNDMYzp48CBat24N4E2PfFJSkpTR8o3FjUwsXrwYbdq0wTfffANHR0c4OjqiZ8+eaNWqlWYSoxxNnToVtra2Ou0lS5bElClTJEhEVHCWLFmiGQYJCwtDWFgY9u7di5YtW2LYsGESp8teYGAgAgMDoVar4e7ujho1amjd5GzChAnw9fXFoUOHkJSUhCdPnmjd5Gr16tV48eKFTvuLFy+wZs0aCRK9n5eXFyZPnozffvsNR48eRZs2bQAAd+/ehb29vcTp8ofDUjKTmpqK6OhoCCFQqVIlWFhYSB0pR6amprhx44bOBOJ79+7B1dU1y3/sRPrCzMxMs7NvYGAgXr58iSVLluDWrVuoU6eObP+ztbW1xZo1azS/ieuT0qVLY/r06XpzcGNKSgqEEChevDhu374NOzs7zWNqtRp//vknRo0aJct5k5cuXULPnj0RGxuL4OBgzbldgwYNQnJyMn7//XeJE344rpaSGQsLC5QoUQIqlUr2hQ3wpofm0qVLOsXNxYsXYWNjI00oogJSvHhxxMXFwcHBAfv27cPkyZMBvOnOl/MeTsbGxnoxeTgrGRkZWR4JIFfW1tZQqVRQqVSoUqWKzuMqleq9h4FKQa1W48mTJzh69KjO0TO//PKLrLc6yA0OS8lEZmYmJk6cCCsrKzg6OqJ8+fKwtrbGpEmTZL23w9dff43Bgwfj8OHDUKvVUKvVCA8PR2BgIL7++mup4xHlS6dOndCjRw80b94cycnJaNWqFQDgwoULsi4ehg4dijlz5sjuuJbc6N+/v171GBw+fBiHDh2CEAKbN29GeHi45nb8+HHExsZizJgxUsfUYWhoiBYtWuDZs2c6j5mamma515A+Yc+NTIwZMwbLly/H1KlTtY6eHz9+PF6+fImff/5Z6ohZmjx5Mu7fv49mzZqhSJE3306ZmZnw8/PjnBvSe7NmzYKTkxPi4uIwffp0FC1aFMCbAwcDAgIkTqft3YUH4eHh2Lt3L6pVq6bzH9XWrVsLM9p7/XePmMzMTCxduhQHDx5E9erVdbLLbb+YRo0aAXgzT8XBwQEGBvrTZ+Dh4YGYmBg4OztLHaXAcc6NTJQpUwaLFy/W2T10x44dCAgIwIMHDyRKlju3bt3CxYsXYWZmBg8PDzg6OkodiajAXLt2DbGxscjIyNBql9Nuv3379s31tStXrvyISfLufXvEvKVSqRAeHv6R0+RPWlpalt8r1atXlyhR9g4cOICRI0di0qRJ8PT01JkKUaxYMYmS5R+LG5kwNTXFpUuXdMZsb968iZo1a3JiLpEEYmJi0KlTJ1y+fBkANMM8b/d2kvO8Gypc//zzD/r27Yu9e/dm+bgcv1f+28v03/3K3u5fJsfMucVhKZmoUaMG5s+fj7lz52q1z58/X3ZLN/V9y3Gi3AoMDISTkxPCwsJQoUIFnD59GsnJyRg6dChmzJghdbxsNW3aFFu3btXZbDAlJQUdOnSQfe+HPgoKCsKTJ09w8uRJzc7Fjx49wuTJkzFz5kyp42VJjrsmFxQWNzIxffp0tGnTBgcPHoS3tzdUKhUiIyMRFxeHPXv2SB1PS1RUFF69eqX5M5FSnThxAuHh4bCzs4OBgQEMDAxQv359hISEYPDgwbL9/j9y5IjOsAgAvHz5EseOHZMgkfKFh4djx44d+Oyzz2BgYABHR0c0b94cxYoVQ0hIiGYPGTl5O19IiVjcyESjRo1w69YtLFiwQHMWTKdOnRAQEKA5PE4u/lvtK7nyJ1Kr1ZpJxLa2tnj48CFcXFzg6OiImzdvSpxO1393Tb527RoSEhI099VqNfbt24eyZctKEU3xUlNTUbJkSQBAiRIl8M8//6BKlSrw8PDA+fPnJU6XvadPn2L58uW4fv06VCoV3Nzc0K9fP1hZWUkdLV9Y3MhImTJlZLsqKjv9+vXDnDlzYGlpqdWempqKQYMGYcWKFRIlI8o/d3d3XLp0CRUqVECdOnUwffp0GBsbY+nSpahQoYLU8XTUrFlTs+dKVscsmJmZYd68eRIkUz4XFxfcvHkTTk5OqFmzJpYsWQInJycsXrwYpUuXljpels6ePYsWLVrAzMwMn3/+OYQQCA0Nxc8//4wDBw6gdu3aUkf8YJxQLCP6WEEbGhoiPj5e8xvLW0lJSShVqhRev34tUTKi/Nu/fz9SU1PRqVMnxMTE4Msvv8SNGzdgY2ODjRs3yu6cpvv370MIoZkf9N/dco2NjVGyZEm935xNrtatW4dXr16hT58+iIqKQosWLZCcnAxjY2OsWrUK3bp1kzqijgYNGqBSpUr49ddfNVt5vH79Gv3790dMTAz++usviRN+OBY3MpFVBX327Fm8ePFClhW0Pm85TpQfjx8/RvHixbVWlxC9Ky0tDTdu3ED58uWzPH9PDszMzBAVFYWqVatqtV+7dg1eXl5IS0uTKFn+6c9uQwo3ZMgQtGvXDvfu3cPWrVuxbds23L17F19++SWCgoKkjqfD2tpac0xElSpVULx4cc3N1tYW/fr1w/fffy91TKIC9/b7Xs5Wr16N3bt3a+6PGDEC1tbW8PHxwf379yVM9ukwNzdH7dq1ZVvYAG/2sYmNjdVpj4uL05lqoG/YcyMT+lZBHz16FEIING3aFFu2bNE6m8TY2BiOjo6ymwhN9KlwcXHBokWL0LRpU5w4cQLNmjXD7NmzsWvXLhQpUkR2OxTrq/dthfFfctwWY/Dgwdi2bRtmzJgBHx8fqFQqHD9+HMOHD0fnzp0xe/ZsqSN+ME4olom3FfS7xY1cK+j/bjlevnx52f8mS/QpiYuL05x9tX37dnz11VcYMGAA6tWrh8aNG0sbTkFyuxWAXH8+zpgxAyqVCn5+fpr5kUZGRvjf//6HqVOnSpwuf1jcyES3bt3g7++fZQXdvXt3qeNl6/r164iLi0P9+vUBAAsWLMCvv/4KNzc3LFiwAMWLF5c4IdGnp2jRokhOTkb58uVx4MABDBkyBMCbndC523nB0fetMIyNjTFnzhyEhIQgOjoaQghUqlQJ5ubmUkfLN865kdClS5c0J37PmDEDnTp1gp+fH5ycnODo6Ig+ffrgq6++wrRp0yROmr3hw4cjJSUFAHD58mUEBwejdevWiImJyVOXLREVnObNm6N///7o378/bt26pdlA7urVq3BycpI2nMLduXMH+/fv1xSRcp75sXr1aqSmpsLc3BweHh6oXr26IgobgHNuJPXfZdQVKlTAmTNnYGZmhjt37gCAXlTQRYsWxZUrV+Dk5ITx48fjypUr2Lx5M86fP4/WrVtrbSJGRIXj6dOn+PHHHxEXF4f//e9/aNmyJQBg3LhxMDY2xpgxYyROqDzJycno2rUrDh8+DJVKhdu3b6NChQrw9/eHtbW1LI9gsLOzQ1paGtq2bYtvvvkGLVu21CwJ13fsuZGQtbU17t69CwC4d+8eMjMzYW5ujurVq+tNBW1sbKyZ7Hzw4EH4+voCeLOi5G2PDhEVLmtra8yfPx87duzQFDYAMGHCBBY2H8mQIUNgZGSE2NhYrZ/d3bp1w759+yRMlr34+Hhs3LgRhoaG+Prrr1G6dGkEBAQgMjJS6mj5powSTU917twZjRo1QunSpaFSqeDl5ZXtBlsxMTGFnC536tevj+DgYNSrVw+nT5/Gxo0bAQC3bt1CuXLlJE5H9Ol6d1NQV1dX+Pv7y3pTUH124MAB7N+/X+fnXuXKlWW7/L5IkSL48ssv8eWXXyItLQ3btm3D77//jiZNmqBcuXKIjo6WOuIHY3EjoaVLl6JTp064c+cOBg8ejG+//VaWK6NyMn/+fAQEBGDz5s1YtGiR5tyavXv3av3GSESFJ6tNQWfNmoUpU6bIclNQJXg7d+VdSUlJMDExkSBR3pibm6NFixZ48uQJ7t+/j+vXr0sdKV8450Ym+vbti7lz5+pdcUNE8qPkbfXlqk2bNqhduzYmTZoES0tLXLp0CY6Ojvj666+RmZmJzZs3Sx0xS297bNatW4eDBw/CwcEB3bt3R8+ePeHq6ip1vA/G4obyLTo6GitXrkR0dDTmzJmDkiVLYt++fXBwcEC1atWkjkf0ydG3TUGV4Pr162jUqBE8PT0RHh6Odu3a4erVq3j8+DEiIiJQsWJFqSPq6N69O/7880+Ym5ujS5cu6NmzJ3x8fKSOVSA4oZjy5ejRo/Dw8MCpU6ewdetWPH/+HMCbZe7jxo2TOB3Rp0nJ2+rL0atXrxAQEICdO3fi888/R/PmzTUHrkZFRcmysAHebC64ceNGPHz4EAsWLFBMYQOw54byydvbG126dEFwcDAsLS1x8eJFzbL2Dh064MGDB1JHJPrkKHlbfbmys7NDZGQkKleuLHUUAicUUz5dvnwZv//+u067nZ0dkpOTJUhEREreVl+u/Pz8sHz5ctl/fefOnYsBAwbA1NQUc+fOzfHawYMHF1KqgseeG8qXcuXK4Y8//oCPj49Wz822bdswbNgwvV5KSKTv0tLSFLetvlwNGjQIa9asQaVKleDl5QULCwutx+VycKazszPOnj0LGxsbODs7Z3udSqWS7RYkucHihvJlxIgROHHiBDZt2oQqVarg/PnzePToEfz8/ODn58d5N0T0SWjSpEm2j6lUKoSHhxdiGmJxQ/ny6tUr9OnTBxs2bIAQAkWKFIFarUaPHj2watWqbDclJKKP5+XLl5g3bx4OHz6MxMREzRl2b50/f16iZCQnR48eRaNGjaSO8VGwuKECER0djaioKGRmZqJWrVqcVEckoR49eiAsLAxfffUV7O3toVKptB5njyoBb47PKVWqFHr06IGePXvCw8ND6kgFhsUNEZHCWFlZYc+ePahXr57UUUjGkpKSsGHDBqxfvx4nTpyAu7s7vvnmG/To0UPvj89hcUP5IoTA5s2bs+3+3rp1q0TJiD5dbm5u2LBhA6pXry51FNITd+/exe+//47169fjxo0baNiwoV7PE+ImfpQvgYGB6NWrF+7evYuiRYvCyspK60ZEhW/mzJkYOXKkbA9sJPlxdnbGqFGjMHXqVHh4eODo0aNSR8oX7nND+bJ27Vps3boVrVu3ljoKEf0/Xl5eePnyJSpUqABzc3MYGRlpPf748WOJkpEcRUREYN26ddi8eTNevnyJdu3aYcqUKVLHyhcWN5QvVlZWqFChgtQxiOg/unfvjgcPHmDKlClZTigmAoDRo0djw4YNePjwIb744gvMnj0bHTp0UMR+SJxzQ/myevVq7Nu3DytWrICZmZnUcYgIgLm5OU6cOIEaNWpIHYVkzMfHBz179kS3bt1ga2srdZwCxZ4bypcuXbpg/fr1KFmyJJycnHS6v7mfBlHhq1q1Kl68eCF1DJKxV69ewcXFBa1atVJcYQOw54byqWvXrjh8+DD30yCSkQMHDmDChAn4+eef4eHhofNLR7FixSRKRnJibW2N8+fPK3JqAYsbyhcLCwvs378f9evXlzoKEf0/BgZvFsK++8uGEAIqlQpqtVqKWCQzffv2hYeHB4KDg6WOUuA4LEX54uDgwN8CiWTm8OHDUkcgPVCpUiVMmjQJkZGR8PT01Dnsk6eC0ydr9+7dmDdvHhYvXgwnJyep4xARUS7xVHCibBQvXhxpaWl4/fo199MgktClS5dyfS13Lial47AU5cvs2bOljkBEAGrWrAmVSoX3/b7KOTf0KWDPDRGRAuTlqAVHR8ePmIT0Rb9+/XJ8fMWKFYWUpOCx54byTa1WY/v27bh+/TpUKhXc3NzQrl07GBoaSh2N6JORVcFy7do1xMbGIiMjQ9OmUqlY3BAA4MmTJ1r3X716hStXruDp06do2rSpRKkKBosbypc7d+6gdevWePDgAVxcXCCEwK1bt+Dg4IDdu3ejYsWKUkck+uTExMSgY8eOuHz5stZQ1dul4RyWIgDYtm2bTltmZiYCAgL0fu8bngpO+TJ48GBUrFgRcXFxOH/+PKKiohAbGwtnZ2e9XkZIpM8CAwPh7OyMR48ewdzcHFeuXMFff/0FLy8vHDlyROp4JGMGBgYYMmQIZs2aJXWUfGHPDeXL0aNHcfLkSZQoUULTZmNjg6lTp6JevXoSJiP6dJ04cQLh4eGws7ODgYEBDA0NUb9+fYSEhGDw4MGIioqSOiLJWHR0NF6/fi11jHxhcUP5YmJign///Ven/fnz5zA2NpYgERGp1WoULVoUAGBra4uHDx/CxcUFjo6OuHnzpsTpSC7e3ZlYCIH4+Hjs3r0bvXv3lihVwWBxQ/ny5ZdfYsCAAVi+fDk+//xzAMCpU6cwcOBAtGvXTuJ0RJ8md3d3XLp0CRUqVECdOnUwffp0GBsbY+nSpXo/l4IKzrs9eAYGBrCzs8PMmTPfu5JK7rgUnPLl6dOn6N27N/7880/NBn6vXr1C+/btsXLlSlhbW0sbkOgTtH//fqSmpqJTp06IiYnBl19+iRs3bsDGxgYbN27U+5UwVDDS0tIghNAcu3Dv3j1s374drq6uaNGihcTp8ofFDRWIO3fu4Pr16xBCwM3NDZUqVZI6EhH9x+PHj1G8eHGdwzTp0+Xr64tOnTph4MCBePr0KapWrQojIyMkJSUhNDQU//vf/6SO+MFY3FCe5eUE2dDQ0I+YhIiIPpStrS2OHj2KatWqYdmyZZg3bx6ioqKwZcsWjB07FtevX5c64gfjnBvKs3fHac+dOwe1Wg0XFxcAwK1bt2BoaAhPT08p4hERUS6kpaXB0tISAHDgwAF06tQJBgYGqFu3bp52vJYjFjeUZ4cPH9b8OTQ0FJaWlli9ejWKFy8O4M2ul3379kWDBg2kikhERO9RqVIlbN++HR07dsT+/fsxZMgQAEBiYiKKFSsmcbr84bAU5UvZsmVx4MABVKtWTav9ypUr8PX1xcOHDyVKRkREOdm8eTN69OgBtVqNZs2a4cCBAwCAkJAQ/PXXX9i7d6/ECT8ce24oX1JSUvDo0SOd4iYxMTHL/W+IiEgevvrqK9SvXx/x8fGoUaOGpr1Zs2bo2LGjhMnyjz03lC9+fn44evQoZs6cibp16wIATp48ieHDh6Nhw4ZYvXq1xAmJiOhTw+KG8iUtLQ3Dhg3DihUr8OrVKwBAkSJF4O/vj19++UWzfwIREVFhYXFDBSI1NRXR0dEQQqBSpUosaoiISDIsboiIiEhRDKQOQERERFSQWNwQERGRorC4ISIiIkVhcUNERESKwuKGiGTnyJEjUKlUePr0aaG836pVq2BtbZ3jNePHj0fNmjU19/v06YMOHTp81FxE9GFY3BBRgUtMTMR3332H8uXLw8TEBKVKlUKLFi1w4sQJqaMVmDlz5mDVqlWa+40bN0ZQUJBkeYjo/8fjF4iowHXu3BmvXr3C6tWrUaFCBTx69AiHDh3C48ePP9p7qtVqqFQqGBgUzu9sVlZWhfI+RJR37LkhogL19OlTHD9+HNOmTUOTJk3g6OiIzz//HKNHj0abNm1w7949qFQqXLhwQes5KpUKR44c0XqtiIgI1KhRA6ampqhTpw4uX76seeztUNKuXbvg5uYGExMT3L9/HxkZGRgxYgTKli0LCwsL1KlTR+d1V61ahfLly8Pc3BwdO3ZEcnKyzueYOnUq7O3tYWlpCX9/f7x8+VLr8f8OS/Xp0wdHjx7FnDlzoFKpoFKpcO/evfx8GYkoH1jcEFGBKlq0KIoWLYrt27cjPT09X681fPhwzJgxA2fOnEHJkiXRrl07zTEfwJvjP0JCQrBs2TJcvXoVJUuWRN++fREREYENGzbg0qVL6NKlC1q2bInbt28DAE6dOoV+/fohICAAFy5cQJMmTTB58mSt9/3jjz8wbtw4/Pzzzzh79ixKly6NhQsXZptzzpw58Pb2xrfffov4+HjEx8fDwcEhX5+diPJBEBEVsM2bN4vixYsLU1NT4ePjI0aPHi0uXrwohBDi7t27AoCIiorSXP/kyRMBQBw+fFgIIcThw4cFALFhwwbNNcnJycLMzExs3LhRCCHEypUrBQBx4cIFzTV37twRKpVKPHjwQCtPs2bNxOjRo4UQQnTv3l20bNlS6/Fu3boJKysrzX1vb28xcOBArWvq1KkjatSoobnfu3dv0b59e839Ro0aicDAwFx9fYjo42LPDREVuM6dO+Phw4fYuXMnWrRogSNHjqB27dpaE3Bzw9vbW/PnEiVKwMXFBdevX9e0GRsbo3r16pr758+fhxACVapU0fQgFS1aFEePHkV0dDQA4Pr161qv++775PYaIpIvTigmoo/C1NQUzZs3R/PmzTF27Fj0798f48aNw7FjxwAA4j/H2v13qOl9VCqV5s9mZmZa9zMzM2FoaIhz587B0NBQ63lFixbVeV8iUib23BBRoXBzc0Nqairs7OwAAPHx8ZrH/ju5+L9Onjyp+fOTJ09w69YtVK1aNdv3qFWrFtRqNRITE1GpUiWtW6lSpTQ5/vu6774PALi6ur73mncZGxtDrVbneA0RFQ723BBRgUpOTkaXLl3Qr18/VK9eHZaWljh79iymT5+O9u3bw8zMDHXr1sXUqVPh5OSEpKQk/Pjjj1m+1sSJE2FjYwN7e3uMGTMGtra2OW6cV6VKFfTs2RN+fn6YOXMmatWqhaSkJISHh8PDwwOtW7fG4MGD4ePjg+nTp6NDhw44cOAA9u3bp/U6gYGB6N27N7y8vFC/fn2sW7cOV69eRYUKFbJ9bycnJ5w6dQr37t1D0aJFUaJEiUJblk5E2vgvj4gKVNGiRVGnTh3MmjULDRs2hLu7O3766Sd8++23mD9/PgBgxYoVePXqFby8vBAYGKizWumtqVOnIjAwEJ6enoiPj8fOnTthbGyc4/uvXLkSfn5+GDp0KFxcXNCuXTucOnVKs3qpbt26WLZsGebNm4eaNWviwIEDOsVVt27dMHbsWIwcORKenp64f/8+/ve//+X4vsOGDYOhoSHc3NxgZ2eH2NjY3H7JiKiAqQQHoImIiEhB2HNDREREisLihoiIiBSFxQ0REREpCosbIiIiUhQWN0RERKQoLG6IiIhIUVjcEBERkaKwuCEiIiJFYXFDREREisLihoiIiBSFxQ0REREpyv8HHYqMLQr2NWcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "subreddits = df_test['subreddit'].unique()\n",
    "\n",
    "subreddit_f1 = []\n",
    "\n",
    "for sb in subreddits:\n",
    "    df_sub = df_test[df_test['subreddit'] == sb]\n",
    "    \n",
    "    X_sub = df_sub['text'].tolist()\n",
    "    y_sub = df_sub['label'].tolist()\n",
    "    \n",
    "    preds_sub = []\n",
    "    for text in X_sub:\n",
    "        label, _ = best_model.predict(text)\n",
    "        preds_sub.append(int(label[0].replace(\"__label__\", \"\")))\n",
    "    \n",
    "    f1 = f1_score(y_sub, preds_sub)\n",
    "    \n",
    "    subreddit_f1.append({\n",
    "        \"subreddit\": sb,\n",
    "        \"f1_score\": f1,\n",
    "        \"num_samples\": len(df_sub)\n",
    "    })\n",
    "\n",
    "df_subreddit_perf = pd.DataFrame(subreddit_f1)\n",
    "df_subreddit_perf = df_subreddit_perf.sort_values(by=\"f1_score\", ascending=False)\n",
    "\n",
    "print(df_subreddit_perf)\n",
    "\n",
    "# Plot F1 by subreddit\n",
    "plt.figure()\n",
    "plt.bar(df_subreddit_perf[\"subreddit\"], df_subreddit_perf[\"f1_score\"])\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Subreddit\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.title(\"F1 Score by Subreddit\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5365268",
   "metadata": {},
   "source": [
    "This analysis examines model performance across different subreddits, measured by F1 score and sample count.\n",
    "\n",
    "Some smaller subreddits, like food_pantry (6 samples) and stress (14 samples), surprisingly achieve high F1 scores (0.857 and 0.800, respectively). This suggests that the model can effectively detect stress-related language even with very limited training examples, likely because the posts are more homogeneous or contain distinctive keywords.\n",
    "\n",
    "Larger subreddits, such as relationships (142 samples) and survivorsofabuse (70 samples), show lower F1 scores (0.63–0.62), indicating that more diverse or nuanced content makes classification harder.\n",
    "\n",
    "Overall, the chart highlights that sample size alone does not fully determine performance. It emphasizes the need for careful data balancing and targeted feature extraction, as the model may perform unevenly across subreddits due to content complexity rather than quantity alone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065f3468",
   "metadata": {},
   "source": [
    "## 7. BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fabddc",
   "metadata": {},
   "source": [
    "In this part, we implement a BERT-based classifier to predict stress from post text. Unlike traditional ML or FastText, BERT leverages pre-trained contextual embeddings to capture nuanced language patterns and context. This allows the model to detect stress expressions more effectively, even if they are subtle or indirect.\n",
    "\n",
    "We will fine-tune a pre-trained BERT model on our dataset, adding a classification head for the stress label. Hugging Face Transformers provides an easy interface for loading pre-trained BERT models, tokenizing text, and managing attention masks, so we do not need to implement the architecture from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d67604ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T03:16:13.301348Z",
     "iopub.status.busy": "2026-02-25T03:16:13.300675Z",
     "iopub.status.idle": "2026-02-25T03:16:37.625107Z",
     "shell.execute_reply": "2026-02-25T03:16:37.624525Z",
     "shell.execute_reply.started": "2026-02-25T03:16:13.301319Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.9.0+cu126\n",
      "Transformers version: 5.2.0\n",
      "GPU available: True\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 1. Import libraries\n",
    "# --------------------------\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification  # Load tokenizer and model\n",
    "from torch.optim import AdamW  # PyTorch's AdamW optimizer\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import numpy as np\n",
    "import transformers  # <-- add this to check version\n",
    "\n",
    "# --------------------------\n",
    "# 2. Check environment\n",
    "# --------------------------\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"Transformers version:\", transformers.__version__)\n",
    "print(\"GPU available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac5bcf0c-da7f-4665-a31f-0c232459bc58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T03:16:41.135052Z",
     "iopub.status.busy": "2026-02-25T03:16:41.134270Z",
     "iopub.status.idle": "2026-02-25T03:16:41.890516Z",
     "shell.execute_reply": "2026-02-25T03:16:41.889916Z",
     "shell.execute_reply.started": "2026-02-25T03:16:41.135022Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 1. Import libraries\n",
    "# --------------------------\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification  # Load tokenizer and model\n",
    "from torch.optim import AdamW  # Use PyTorch's AdamW optimizer\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "import torch.nn.utils as nn_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8a04a3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T03:16:56.927787Z",
     "iopub.status.busy": "2026-02-25T03:16:56.926831Z",
     "iopub.status.idle": "2026-02-25T03:17:01.211645Z",
     "shell.execute_reply": "2026-02-25T03:17:01.210901Z",
     "shell.execute_reply.started": "2026-02-25T03:16:56.927756Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12db91a2fcbe430eb5aed331d228de71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5143208bcd894708bc789bef4c4f0d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e4c153ffcf4cdca23f8ed6727ce754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d04017010eec489cac61b25209269541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd341489a19341438778bdf2a1910beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531ed519db034abdbd0a7f978fea8fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertForSequenceClassification LOAD REPORT\u001b[0m from: bert-base-uncased\n",
      "Key                                        | Status     | \n",
      "-------------------------------------------+------------+-\n",
      "cls.predictions.bias                       | UNEXPECTED | \n",
      "cls.seq_relationship.weight                | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
      "cls.seq_relationship.bias                  | UNEXPECTED | \n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
      "classifier.weight                          | MISSING    | \n",
      "classifier.bias                            | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 2. Tokenizer & model\n",
    "# --------------------------\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1e2cbde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T03:17:13.997294Z",
     "iopub.status.busy": "2026-02-25T03:17:13.996753Z",
     "iopub.status.idle": "2026-02-25T03:17:14.005657Z",
     "shell.execute_reply": "2026-02-25T03:17:14.005003Z",
     "shell.execute_reply.started": "2026-02-25T03:17:13.997263Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 3. Prepare dataset\n",
    "# --------------------------\n",
    "class StressDataset(Dataset):\n",
    "    \"\"\"Custom dataset for stress classification with BERT\"\"\"\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = int(self.labels[idx])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Train dataset\n",
    "train_dataset = StressDataset(df_train['text'].tolist(),\n",
    "                              df_train['label'].tolist(),\n",
    "                              tokenizer)\n",
    "\n",
    "# Test dataset\n",
    "test_dataset = StressDataset(df_test['text'].tolist(),\n",
    "                             df_test['label'].tolist(),\n",
    "                             tokenizer)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5363774d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T03:17:22.524676Z",
     "iopub.status.busy": "2026-02-25T03:17:22.523997Z",
     "iopub.status.idle": "2026-02-25T03:17:22.530015Z",
     "shell.execute_reply": "2026-02-25T03:17:22.529422Z",
     "shell.execute_reply.started": "2026-02-25T03:17:22.524644Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 4. Optimizer + Scheduler\n",
    "# --------------------------\n",
    "epochs = 4\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "total_steps = len(train_loader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(0.1 * total_steps),  # 10% warmup\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3069dacc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T03:17:32.917405Z",
     "iopub.status.busy": "2026-02-25T03:17:32.917069Z",
     "iopub.status.idle": "2026-02-25T03:21:40.408821Z",
     "shell.execute_reply": "2026-02-25T03:21:40.408083Z",
     "shell.execute_reply.started": "2026-02-25T03:17:32.917378Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 - Average Loss: 0.5251\n",
      "Epoch 2/4 - Average Loss: 0.3456\n",
      "Epoch 3/4 - Average Loss: 0.2009\n",
      "Epoch 4/4 - Average Loss: 0.1067\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 5. Training loop\n",
    "# --------------------------\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # gradient clipping\n",
    "        nn_utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Average Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ca014df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T03:22:13.912178Z",
     "iopub.status.busy": "2026-02-25T03:22:13.911820Z",
     "iopub.status.idle": "2026-02-25T03:22:18.618371Z",
     "shell.execute_reply": "2026-02-25T03:22:18.617529Z",
     "shell.execute_reply.started": "2026-02-25T03:22:13.912139Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT F1 score: 0.8172323759791122\n",
      "BERT Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.79       346\n",
      "           1       0.79      0.85      0.82       369\n",
      "\n",
      "    accuracy                           0.80       715\n",
      "   macro avg       0.81      0.80      0.80       715\n",
      "weighted avg       0.81      0.80      0.80       715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 6. Evaluation\n",
    "# --------------------------\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# F1 score & classification report\n",
    "f1 = f1_score(true_labels, predictions)\n",
    "print(\"BERT F1 score:\", f1)\n",
    "print(\"BERT Classification Report:\")\n",
    "print(classification_report(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aac112-455f-4293-9607-c0cacab793cd",
   "metadata": {},
   "source": [
    "### Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de73aaf4-b986-4f51-8ba0-5c34917de76e",
   "metadata": {},
   "source": [
    "The BERT model achieved a F1 score of 0.8059, showing solid performance in distinguishing between stressed and non-stressed posts. Precision and Recall for both classes are balanced at 0.80, meaning the model is good at both identifying relevant content (precision) and capturing most of the stressed posts (recall). The F1 score reflects this balance, indicating that the model is neither too cautious nor too aggressive in its predictions. Overall, the model effectively captures the nuanced language of stress while avoiding excessive false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247a0b41-6eec-4718-9db1-36d5cf1f7317",
   "metadata": {},
   "source": [
    "### Implications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed141dd-033b-4b1d-bbd3-95bd9e3edbf2",
   "metadata": {},
   "source": [
    "From a policy perspective, this balanced performance is critical for applications like mental health monitoring and crisis intervention. It ensures timely, relevant interventions without wasting resources on irrelevant content or missing genuine cases of distress.\n",
    "\n",
    "For the general public, the balanced precision and recall mean that the model can be trusted to flag relevant posts without overwhelming users with false alarms. This reliability is essential for tools aiming to provide support in real-world scenarios, like social media monitoring for mental health issues. With 80% recall for stressed posts, the model ensures that individuals who need help are not overlooked, making it a valuable tool for both intervention and prevention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12063c9e-56d7-4e33-a43f-836274a398e9",
   "metadata": {},
   "source": [
    "### Interpretability - Prediction Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0ed13f1-8e17-42d6-9e3d-b1e365fb20f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T03:24:47.589004Z",
     "iopub.status.busy": "2026-02-25T03:24:47.588047Z",
     "iopub.status.idle": "2026-02-25T03:24:52.255918Z",
     "shell.execute_reply": "2026-02-25T03:24:52.255183Z",
     "shell.execute_reply.started": "2026-02-25T03:24:47.588966Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average confidence (correct): 0.9663602\n",
      "Average confidence (wrong): 0.9165717\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_probs = []\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids,\n",
    "                        attention_mask=attention_mask)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "all_probs = np.array(all_probs)\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Confidence = predicted class probability\n",
    "confidence = all_probs[np.arange(len(all_preds)), all_preds]\n",
    "\n",
    "correct_conf = confidence[all_preds == all_labels]\n",
    "wrong_conf = confidence[all_preds != all_labels]\n",
    "\n",
    "print(\"Average confidence (correct):\", correct_conf.mean())\n",
    "print(\"Average confidence (wrong):\", wrong_conf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e86f0d0-a957-4ccc-8cab-db282b6c583b",
   "metadata": {},
   "source": [
    "The average confidence for correctly classified samples is 0.97, while the average confidence for misclassified samples is 0.92. This demonstrates that the model is highly confident in its correct predictions, which suggests that it is effectively capturing the relevant patterns in the data. The relatively lower confidence for incorrect predictions indicates that the model is not overly confident when it makes mistakes, which is a positive trait, as it reflects a certain level of uncertainty or caution in those cases.\n",
    "\n",
    "Overall, these results show that the model is well-calibrated and performs with strong reliability, making it a valuable tool for real-world applications where understanding model confidence can be crucial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1d98df-33bd-4d39-aa03-28a0223a2e9e",
   "metadata": {},
   "source": [
    "### Interpretability - Subreddit-wise Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "285bde14-51df-4cbf-bccf-c6be3aa2ddeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T03:24:58.643752Z",
     "iopub.status.busy": "2026-02-25T03:24:58.643429Z",
     "iopub.status.idle": "2026-02-25T03:24:58.684626Z",
     "shell.execute_reply": "2026-02-25T03:24:58.683972Z",
     "shell.execute_reply.started": "2026-02-25T03:24:58.643725Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subreddit\n",
      "domesticviolence    0.891089\n",
      "anxiety             0.868571\n",
      "ptsd                0.858896\n",
      "food_pantry         0.857143\n",
      "stress              0.842105\n",
      "almosthomeless      0.833333\n",
      "survivorsofabuse    0.764706\n",
      "assistance          0.731707\n",
      "relationships       0.720000\n",
      "homeless            0.697674\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/954068225.py:12: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  subreddit_f1 = df.groupby(\"subreddit\").apply(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Create a DataFrame with subreddit, true labels, and predictions\n",
    "df = pd.DataFrame({\n",
    "    \"subreddit\": df_test['subreddit'],  # Assuming 'subreddit' is in the test dataset\n",
    "    \"label\": df_test['label'],          # True labels\n",
    "    \"pred\": predictions                  # Model predictions\n",
    "})\n",
    "\n",
    "# Group by subreddit and calculate F1 score for each subreddit\n",
    "subreddit_f1 = df.groupby(\"subreddit\").apply(\n",
    "    lambda x: f1_score(x[\"label\"], x[\"pred\"])\n",
    ")\n",
    "\n",
    "# Sort subreddits by F1 score\n",
    "subreddit_f1_sorted = subreddit_f1.sort_values(ascending=False)\n",
    "\n",
    "# Display the results\n",
    "print(subreddit_f1_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8c4504-0a0f-4e0f-990c-b96ffa955ab0",
   "metadata": {},
   "source": [
    "The F1 scores across different subreddits show a range of model performance. The top-performing subreddits, such as domesticviolence (0.87), ptsd (0.86), and anxiety (0.86), suggest that the model is particularly effective at classifying posts related to mental health and trauma. This could be due to clearer language or stronger patterns in these topics that the model can learn more easily.\n",
    "\n",
    "On the other hand, subreddits like almosthomeless (0.67) and relationships (0.68) have lower F1 scores, possibly because these topics involve more nuanced or ambiguous language, making them harder for the model to classify accurately. The lack of distinct and consistent language patterns might contribute to these lower scores.\n",
    "\n",
    "Overall, the model performs well with more explicit topics like domesticviolence and food_pantry, but struggles with more complex or less direct categories like relationships and almosthomeless. Further fine-tuning or data augmentation may help improve the model's performance on these more challenging subreddits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdfdcb6-1961-4fde-8fc2-c5a6c2c9e8a7",
   "metadata": {},
   "source": [
    "## 8. Clinical Ethics Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ed269c-fcd2-4721-a3b0-152404ce789c",
   "metadata": {},
   "source": [
    "Deploying a stress-detection model in clinical or support settings carries several risks that need careful consideration.\n",
    "\n",
    "False Negatives:\n",
    "The model may fail to identify a person who is actually experiencing high stress. This could delay critical intervention, potentially worsening mental health outcomes. Systems must have fallback procedures, such as human review or multiple assessments, to mitigate harm.\n",
    "\n",
    "False Positives:\n",
    "Conversely, predicting stress where none exists may lead to unnecessary interventions or anxiety for users. The model’s confidence scores should be interpreted carefully, and automated alerts should not be the sole trigger for action.\n",
    "\n",
    "Automated Surveillance:\n",
    "Continuous monitoring of user posts or messages could be perceived as intrusive. Ethical deployment requires clear consent, transparency about data usage, and strict privacy safeguards.\n",
    "\n",
    "Bias and Equity:\n",
    "The model may perform unevenly across subreddits, demographics, or language styles. Misrepresentation could disproportionately affect certain groups, raising fairness concerns.\n",
    "\n",
    "Integration with Human Judgment:\n",
    "Any clinical or support application should treat the model as an assistive tool rather than a final authority. Human oversight is crucial to contextualize predictions and ensure responsible use.\n",
    "\n",
    "Potential Misuse:\n",
    "Beyond clinical contexts, models could be used for surveillance or workplace monitoring without consent. Ethical policies should restrict deployment strictly to supportive or research purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc047bb7-af5b-471e-b301-8eb3397c0dde",
   "metadata": {},
   "source": [
    "## 9. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d5a6ac-30f5-45e2-84be-b21438bfa256",
   "metadata": {},
   "source": [
    "Across the baseline models and FastText, F1-scores hovered around 0.74–0.76, indicating moderate predictive ability but limited improvement over simple models. BERT, however, demonstrated a significant performance gain, achieving an F1-score above 0.80 with a well-balanced precision and recall. This highlights the advantage of contextual embeddings and transformer architectures in capturing nuanced linguistic patterns that correlate with stress.\n",
    "\n",
    "Beyond metrics, clinical ethics and deployment considerations are critical. While automated detection can provide timely support, risks such as false negatives, privacy concerns, and potential misuse must be carefully managed. Future work could focus on integrating multimodal data, improving fairness across user groups, and developing interpretable models that clinicians and support staff can trust. Overall, this project demonstrates that advanced NLP models like BERT can meaningfully improve stress detection while emphasizing the importance of responsible and ethical deployment."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 15822587,
     "datasetId": 9569738,
     "sourceId": 14952222,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 299917660,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31287,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "charllm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
